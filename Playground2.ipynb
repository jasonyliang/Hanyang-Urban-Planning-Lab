{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/jhajhajhajha1/Desktop/Hanyang Data/data_playaround.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.iloc[:, 0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "      <th>H_ZONE</th>\n",
       "      <th>H_ZONE_X</th>\n",
       "      <th>H_ZONE_Y</th>\n",
       "      <th>W_ZONE_X</th>\n",
       "      <th>W_ZONE_Y</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.453952</td>\n",
       "      <td>126.716877</td>\n",
       "      <td>36.115620</td>\n",
       "      <td>126.792747</td>\n",
       "      <td>810.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>439000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.465845</td>\n",
       "      <td>126.717234</td>\n",
       "      <td>37.335447</td>\n",
       "      <td>126.677584</td>\n",
       "      <td>855.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>441000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.229621</td>\n",
       "      <td>127.284122</td>\n",
       "      <td>36.975082</td>\n",
       "      <td>127.436894</td>\n",
       "      <td>363.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.623500</td>\n",
       "      <td>127.083187</td>\n",
       "      <td>36.847868</td>\n",
       "      <td>127.414170</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>457000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.469676</td>\n",
       "      <td>126.644354</td>\n",
       "      <td>37.967527</td>\n",
       "      <td>124.717824</td>\n",
       "      <td>852.0</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>441000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  job_type  \\\n",
       "0       0    4.0         4.0      1.0        5.0     1.0  41.0  1.0       4.0   \n",
       "1       0    3.0         3.0      2.0        3.0     1.0  36.0  1.0       4.0   \n",
       "2       0    3.0         3.0      2.0        2.0     1.0  70.0  1.0       9.0   \n",
       "3       0    5.0         4.0      1.0        5.0     1.0  32.0  1.0       4.0   \n",
       "4       0    2.0         2.0      4.0        3.0     1.0  55.0  1.0       4.0   \n",
       "\n",
       "   house_lat   house_lon   work_lat    work_lon  H_ZONE  H_ZONE_X  H_ZONE_Y  \\\n",
       "0  37.453952  126.716877  36.115620  126.792747   810.0  175000.0  439000.0   \n",
       "1  37.465845  126.717234  37.335447  126.677584   855.0  175000.0  441000.0   \n",
       "2  37.229621  127.284122  36.975082  127.436894   363.0  225000.0  415000.0   \n",
       "3  37.623500  127.083187  36.847868  127.414170  1181.0  207000.0  457000.0   \n",
       "4  37.469676  126.644354  37.967527  124.717824   852.0  169000.0  441000.0   \n",
       "\n",
       "   W_ZONE_X  W_ZONE_Y    0  \n",
       "0       0.0       0.0  0.0  \n",
       "1       0.0       0.0  0.0  \n",
       "2       0.0       0.0  0.0  \n",
       "3       0.0       0.0  0.0  \n",
       "4       0.0       0.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.115620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.335447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.975082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.847868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.967527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  job_type  \\\n",
       "0       0    4.0         4.0      1.0        5.0     1.0  41.0  1.0       4.0   \n",
       "1       0    3.0         3.0      2.0        3.0     1.0  36.0  1.0       4.0   \n",
       "2       0    3.0         3.0      2.0        2.0     1.0  70.0  1.0       9.0   \n",
       "3       0    5.0         4.0      1.0        5.0     1.0  32.0  1.0       4.0   \n",
       "4       0    2.0         2.0      4.0        3.0     1.0  55.0  1.0       4.0   \n",
       "\n",
       "    work_lat  \n",
       "0  36.115620  \n",
       "1  37.335447  \n",
       "2  36.975082  \n",
       "3  36.847868  \n",
       "4  37.967527  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# not calculating distance, simply using latitude\n",
    "x = data.iloc[:, 0:12]\n",
    "x = x.drop([\"house_lat\", \"house_lon\"], axis= 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W_ZONE          0\n",
       "no_hh         180\n",
       "no_hh_chil    180\n",
       "hh_type       180\n",
       "hh_income     180\n",
       "no_car        180\n",
       "age           180\n",
       "sex           180\n",
       "job_type      180\n",
       "work_lat      180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(x.iloc[:, 1:10])\n",
    "# x.iloc[:, 1:10] = imputer.transform(x.iloc[:, 1:10])\n",
    "x = x.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W_ZONE        0\n",
       "no_hh         0\n",
       "no_hh_chil    0\n",
       "hh_type       0\n",
       "hh_income     0\n",
       "no_car        0\n",
       "age           0\n",
       "sex           0\n",
       "job_type      0\n",
       "work_lat      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category values: hh_type, hh_income (this one is fine because of the levels)\n",
    "# Encoding categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.453952</td>\n",
       "      <td>126.716877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.465845</td>\n",
       "      <td>126.717234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.229621</td>\n",
       "      <td>127.284122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.623500</td>\n",
       "      <td>127.083187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.469676</td>\n",
       "      <td>126.644354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_lat   house_lon\n",
       "0  37.453952  126.716877\n",
       "1  37.465845  126.717234\n",
       "2  37.229621  127.284122\n",
       "3  37.623500  127.083187\n",
       "4  37.469676  126.644354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:, [\"house_lat\", \"house_lon\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_lat    180\n",
       "house_lon    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(y)\n",
    "# y = imputer.transform(y)\n",
    "y = y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we do feature scaling?\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 6, kernel_initializer = 'normal', activation = 'relu', input_dim = 10))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "regressor.add(Dense(units = 6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "regressor.add(Dense(units = 6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37342/37342 [==============================] - 7s 182us/step - loss: 3353.2419 - mean_absolute_error: 41.7173\n",
      "Epoch 2/100\n",
      "37342/37342 [==============================] - 5s 142us/step - loss: 2204.5419 - mean_absolute_error: 29.7168\n",
      "Epoch 3/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 2107.8204 - mean_absolute_error: 28.0521\n",
      "Epoch 4/100\n",
      "37342/37342 [==============================] - 5s 142us/step - loss: 2048.4880 - mean_absolute_error: 26.7412\n",
      "Epoch 5/100\n",
      "37342/37342 [==============================] - 6s 149us/step - loss: 1988.8324 - mean_absolute_error: 25.4955\n",
      "Epoch 6/100\n",
      "37342/37342 [==============================] - ETA: 0s - loss: 1974.7047 - mean_absolute_error: 24.8695- ETA: 2s - - 5s 143us/step - loss: 1975.4221 - mean_absolute_error: 24.8762\n",
      "Epoch 7/100\n",
      "37342/37342 [==============================] - 6s 150us/step - loss: 1926.3719 - mean_absolute_error: 24.1666\n",
      "Epoch 8/100\n",
      "37342/37342 [==============================] - 6s 153us/step - loss: 1968.5188 - mean_absolute_error: 24.2094\n",
      "Epoch 9/100\n",
      "37342/37342 [==============================] - 6s 151us/step - loss: 1921.3443 - mean_absolute_error: 23.7590\n",
      "Epoch 10/100\n",
      "37342/37342 [==============================] - 5s 144us/step - loss: 1929.8226 - mean_absolute_error: 23.5658\n",
      "Epoch 11/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1914.2330 - mean_absolute_error: 23.2364\n",
      "Epoch 12/100\n",
      "37342/37342 [==============================] - 5s 129us/step - loss: 1916.3893 - mean_absolute_error: 23.0612\n",
      "Epoch 13/100\n",
      "37342/37342 [==============================] - 6s 149us/step - loss: 1912.8141 - mean_absolute_error: 22.8169\n",
      "Epoch 14/100\n",
      "37342/37342 [==============================] - 6s 157us/step - loss: 1911.9830 - mean_absolute_error: 22.6254\n",
      "Epoch 15/100\n",
      "37342/37342 [==============================] - 6s 152us/step - loss: 1888.6403 - mean_absolute_error: 22.2181\n",
      "Epoch 16/100\n",
      "37342/37342 [==============================] - 5s 144us/step - loss: 1847.1464 - mean_absolute_error: 21.7101\n",
      "Epoch 17/100\n",
      "37342/37342 [==============================] - 6s 149us/step - loss: 1922.9944 - mean_absolute_error: 22.1202\n",
      "Epoch 18/100\n",
      "37342/37342 [==============================] - 6s 148us/step - loss: 1891.3013 - mean_absolute_error: 21.6345\n",
      "Epoch 19/100\n",
      "37342/37342 [==============================] - 5s 145us/step - loss: 1855.5637 - mean_absolute_error: 21.3099\n",
      "Epoch 20/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 1848.5065 - mean_absolute_error: 21.1843\n",
      "Epoch 21/100\n",
      "37342/37342 [==============================] - 5s 142us/step - loss: 1860.8719 - mean_absolute_error: 21.2205\n",
      "Epoch 22/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1871.7117 - mean_absolute_error: 21.2248\n",
      "Epoch 23/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1798.9872 - mean_absolute_error: 20.5073\n",
      "Epoch 24/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1856.7485 - mean_absolute_error: 20.8502\n",
      "Epoch 25/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1833.7734 - mean_absolute_error: 20.6120\n",
      "Epoch 26/100\n",
      "37342/37342 [==============================] - 5s 147us/step - loss: 1798.3936 - mean_absolute_error: 20.2887\n",
      "Epoch 27/100\n",
      "37342/37342 [==============================] - 6s 148us/step - loss: 1814.8482 - mean_absolute_error: 20.2719\n",
      "Epoch 28/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1790.3238 - mean_absolute_error: 20.0043\n",
      "Epoch 29/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1829.7590 - mean_absolute_error: 20.2049\n",
      "Epoch 30/100\n",
      "37342/37342 [==============================] - 5s 133us/step - loss: 1790.9384 - mean_absolute_error: 19.8399\n",
      "Epoch 31/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1785.7253 - mean_absolute_error: 19.6676\n",
      "Epoch 32/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1777.9659 - mean_absolute_error: 19.5024\n",
      "Epoch 33/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1765.2400 - mean_absolute_error: 19.2559\n",
      "Epoch 34/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1808.2921 - mean_absolute_error: 19.4588\n",
      "Epoch 35/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1800.0141 - mean_absolute_error: 19.3601\n",
      "Epoch 36/100\n",
      "37342/37342 [==============================] - 5s 142us/step - loss: 1791.2000 - mean_absolute_error: 19.1903\n",
      "Epoch 37/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1785.8456 - mean_absolute_error: 18.9931\n",
      "Epoch 38/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1772.8035 - mean_absolute_error: 18.7903\n",
      "Epoch 39/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1765.8943 - mean_absolute_error: 18.6640\n",
      "Epoch 40/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1784.1806 - mean_absolute_error: 18.6346\n",
      "Epoch 41/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1775.7301 - mean_absolute_error: 18.4880\n",
      "Epoch 42/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1768.0154 - mean_absolute_error: 18.3262\n",
      "Epoch 43/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1773.3096 - mean_absolute_error: 18.2937\n",
      "Epoch 44/100\n",
      "37342/37342 [==============================] - 6s 158us/step - loss: 1759.3189 - mean_absolute_error: 18.0769 2s - loss\n",
      "Epoch 45/100\n",
      "37342/37342 [==============================] - 5s 146us/step - loss: 1774.0753 - mean_absolute_error: 18.0513\n",
      "Epoch 46/100\n",
      "37342/37342 [==============================] - 6s 160us/step - loss: 1749.7279 - mean_absolute_error: 17.7268\n",
      "Epoch 47/100\n",
      "37342/37342 [==============================] - 7s 182us/step - loss: 1746.0179 - mean_absolute_error: 17.6425\n",
      "Epoch 48/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 1796.5222 - mean_absolute_error: 17.8757\n",
      "Epoch 49/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1722.6098 - mean_absolute_error: 17.1595\n",
      "Epoch 50/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1740.7452 - mean_absolute_error: 17.1847\n",
      "Epoch 51/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1746.9122 - mean_absolute_error: 17.1515 1s - loss: 1748.6\n",
      "Epoch 52/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1720.7874 - mean_absolute_error: 16.7997\n",
      "Epoch 53/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1750.6334 - mean_absolute_error: 16.9627\n",
      "Epoch 54/100\n",
      "37342/37342 [==============================] - 6s 151us/step - loss: 1758.0177 - mean_absolute_error: 16.8995\n",
      "Epoch 55/100\n",
      "37342/37342 [==============================] - 5s 139us/step - loss: 1744.3892 - mean_absolute_error: 16.6175\n",
      "Epoch 56/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 1760.5521 - mean_absolute_error: 16.6892\n",
      "Epoch 57/100\n",
      "37342/37342 [==============================] - 5s 141us/step - loss: 1749.6025 - mean_absolute_error: 16.5433\n",
      "Epoch 58/100\n",
      "37342/37342 [==============================] - 5s 147us/step - loss: 1735.0190 - mean_absolute_error: 16.4390\n",
      "Epoch 59/100\n",
      "37342/37342 [==============================] - 5s 145us/step - loss: 1755.3434 - mean_absolute_error: 16.6108\n",
      "Epoch 60/100\n",
      "37342/37342 [==============================] - 5s 139us/step - loss: 1739.4767 - mean_absolute_error: 16.4716\n",
      "Epoch 61/100\n",
      "37342/37342 [==============================] - 5s 145us/step - loss: 1761.0393 - mean_absolute_error: 16.6381\n",
      "Epoch 62/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1744.0101 - mean_absolute_error: 16.4680\n",
      "Epoch 63/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1754.9365 - mean_absolute_error: 16.5583\n",
      "Epoch 64/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1747.8975 - mean_absolute_error: 16.5285\n",
      "Epoch 65/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1756.7437 - mean_absolute_error: 16.6317\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 5s 138us/step - loss: 1766.7285 - mean_absolute_error: 16.6479\n",
      "Epoch 67/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1753.7515 - mean_absolute_error: 16.5427\n",
      "Epoch 68/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1783.7716 - mean_absolute_error: 16.7961\n",
      "Epoch 69/100\n",
      "37342/37342 [==============================] - 5s 139us/step - loss: 1734.4551 - mean_absolute_error: 16.3887\n",
      "Epoch 70/100\n",
      "37342/37342 [==============================] - 5s 142us/step - loss: 1748.4572 - mean_absolute_error: 16.5353\n",
      "Epoch 71/100\n",
      "37342/37342 [==============================] - 6s 165us/step - loss: 1755.4376 - mean_absolute_error: 16.6207\n",
      "Epoch 72/100\n",
      "37342/37342 [==============================] - 6s 149us/step - loss: 1744.3186 - mean_absolute_error: 16.4856 2s - \n",
      "Epoch 73/100\n",
      "37342/37342 [==============================] - 7s 176us/step - loss: 1745.6039 - mean_absolute_error: 16.4845\n",
      "Epoch 74/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1762.3287 - mean_absolute_error: 16.6772\n",
      "Epoch 75/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1768.2991 - mean_absolute_error: 16.6766\n",
      "Epoch 76/100\n",
      "37342/37342 [==============================] - 5s 145us/step - loss: 1711.6847 - mean_absolute_error: 16.1917\n",
      "Epoch 77/100\n",
      "37342/37342 [==============================] - 6s 149us/step - loss: 1763.9229 - mean_absolute_error: 16.6546\n",
      "Epoch 78/100\n",
      "37342/37342 [==============================] - 5s 144us/step - loss: 1728.3820 - mean_absolute_error: 16.4210\n",
      "Epoch 79/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1765.0715 - mean_absolute_error: 16.6580\n",
      "Epoch 80/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1790.2033 - mean_absolute_error: 16.8384\n",
      "Epoch 81/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1750.3766 - mean_absolute_error: 16.5347\n",
      "Epoch 82/100\n",
      "37342/37342 [==============================] - 5s 140us/step - loss: 1770.2511 - mean_absolute_error: 16.7027 1s - loss: 1765.2304 - me\n",
      "Epoch 83/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 1763.3293 - mean_absolute_error: 16.6281\n",
      "Epoch 84/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1755.8561 - mean_absolute_error: 16.5916\n",
      "Epoch 85/100\n",
      "37342/37342 [==============================] - 5s 138us/step - loss: 1736.9017 - mean_absolute_error: 16.4254\n",
      "Epoch 86/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1751.0372 - mean_absolute_error: 16.5282\n",
      "Epoch 87/100\n",
      "37342/37342 [==============================] - 5s 132us/step - loss: 1746.5053 - mean_absolute_error: 16.4854\n",
      "Epoch 88/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1764.7074 - mean_absolute_error: 16.6638\n",
      "Epoch 89/100\n",
      "37342/37342 [==============================] - 5s 145us/step - loss: 1731.1923 - mean_absolute_error: 16.3931\n",
      "Epoch 90/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1765.2130 - mean_absolute_error: 16.6627\n",
      "Epoch 91/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1739.5084 - mean_absolute_error: 16.4609\n",
      "Epoch 92/100\n",
      "37342/37342 [==============================] - 5s 141us/step - loss: 1740.8133 - mean_absolute_error: 16.4584\n",
      "Epoch 93/100\n",
      "37342/37342 [==============================] - 5s 143us/step - loss: 1760.1139 - mean_absolute_error: 16.5720\n",
      "Epoch 94/100\n",
      "37342/37342 [==============================] - 5s 141us/step - loss: 1727.5401 - mean_absolute_error: 16.3253\n",
      "Epoch 95/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1753.3816 - mean_absolute_error: 16.5940\n",
      "Epoch 96/100\n",
      "37342/37342 [==============================] - 5s 136us/step - loss: 1734.7849 - mean_absolute_error: 16.3909\n",
      "Epoch 97/100\n",
      "37342/37342 [==============================] - 5s 137us/step - loss: 1750.2359 - mean_absolute_error: 16.5074\n",
      "Epoch 98/100\n",
      "37342/37342 [==============================] - 5s 135us/step - loss: 1758.7782 - mean_absolute_error: 16.5605\n",
      "Epoch 99/100\n",
      "37342/37342 [==============================] - 5s 134us/step - loss: 1741.1359 - mean_absolute_error: 16.4108\n",
      "Epoch 100/100\n",
      "37342/37342 [==============================] - 5s 139us/step - loss: 1771.8730 - mean_absolute_error: 16.7044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10d052940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25714    37.607582\n",
       "34775    37.594757\n",
       "24939    37.514340\n",
       "4528     37.469662\n",
       "3767     37.440188\n",
       "11108    37.385096\n",
       "46482    37.912409\n",
       "20047    37.460825\n",
       "14641    37.475657\n",
       "16879    37.523178\n",
       "27266    37.493795\n",
       "46081    37.838948\n",
       "42812    37.679916\n",
       "8419     37.397581\n",
       "16327    37.493598\n",
       "25043    37.530751\n",
       "36207    37.549963\n",
       "20421    37.749822\n",
       "14062    37.450040\n",
       "13306    37.418681\n",
       "23689    37.545318\n",
       "32726    37.583815\n",
       "38064    37.644207\n",
       "7475     37.307777\n",
       "18934    37.504791\n",
       "32618    37.609579\n",
       "39769    37.564923\n",
       "20480    37.530761\n",
       "6621     37.336192\n",
       "29367    37.570487\n",
       "           ...    \n",
       "21754    37.607640\n",
       "13547    37.355379\n",
       "29863    37.565967\n",
       "43421    37.713303\n",
       "8993     37.456590\n",
       "8909     37.363864\n",
       "7908     37.282592\n",
       "42875    37.684006\n",
       "32466    37.490396\n",
       "14941    37.473398\n",
       "5328     37.285488\n",
       "32918    37.322478\n",
       "39964    37.592115\n",
       "25850    37.529057\n",
       "24236    37.304044\n",
       "8559     37.345046\n",
       "13787    37.346248\n",
       "46254    37.902971\n",
       "46619    37.911602\n",
       "36029    37.576847\n",
       "5999     37.212255\n",
       "32010    37.277574\n",
       "37511    37.601166\n",
       "6825     37.368903\n",
       "12122    37.438612\n",
       "34151    37.587410\n",
       "30373    37.597902\n",
       "33508    37.562894\n",
       "33100    37.559479\n",
       "8045     37.346115\n",
       "Name: house_lat, Length: 9336, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_lat            37.594757\n",
       "house_lon           127.153212\n",
       "house_lat (pred)     29.992231\n",
       "house_lon (pred)    101.573112\n",
       "Name: 34775, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test.iloc[:, 0],'house_lon':y_test.iloc[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247192.11779807045"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy based on distance\n",
    "def accuracy(pred):\n",
    "    sum_error = 0\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        sum_error += error\n",
    "    return sum_error\n",
    "\n",
    "accuracy(prediction)\n",
    "# first try: 248072.10955363105\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot?\n",
    "plt.scatter(y_test.iloc[:, 0], y_test.iloc[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
