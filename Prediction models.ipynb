{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/jhajhajhajha1/Desktop/Hanyang Data/data_playaround.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.iloc[:, 0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "      <th>H_ZONE</th>\n",
       "      <th>H_ZONE_X</th>\n",
       "      <th>H_ZONE_Y</th>\n",
       "      <th>W_ZONE_X</th>\n",
       "      <th>W_ZONE_Y</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.511534</td>\n",
       "      <td>126.902390</td>\n",
       "      <td>37.031954</td>\n",
       "      <td>127.077127</td>\n",
       "      <td>954.0</td>\n",
       "      <td>191000.0</td>\n",
       "      <td>445000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.000396</td>\n",
       "      <td>127.106922</td>\n",
       "      <td>37.034933</td>\n",
       "      <td>127.078710</td>\n",
       "      <td>50.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.195733</td>\n",
       "      <td>127.034267</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>287.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>411000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.067362</td>\n",
       "      <td>127.056343</td>\n",
       "      <td>37.037719</td>\n",
       "      <td>127.077653</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.151695</td>\n",
       "      <td>127.078077</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>218.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.053694</td>\n",
       "      <td>127.047655</td>\n",
       "      <td>37.038303</td>\n",
       "      <td>127.082699</td>\n",
       "      <td>105.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.102160</td>\n",
       "      <td>127.021462</td>\n",
       "      <td>37.036618</td>\n",
       "      <td>127.077674</td>\n",
       "      <td>173.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>401000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.037146</td>\n",
       "      <td>127.029241</td>\n",
       "      <td>37.035418</td>\n",
       "      <td>127.074294</td>\n",
       "      <td>86.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.076516</td>\n",
       "      <td>127.064009</td>\n",
       "      <td>37.036774</td>\n",
       "      <td>127.072348</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.989866</td>\n",
       "      <td>127.090719</td>\n",
       "      <td>37.037373</td>\n",
       "      <td>127.088846</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  \\\n",
       "1000      88    4.0         3.0      1.0        5.0     1.0  40.0  1.0   \n",
       "1001      88    3.0         3.0      4.0        2.0     2.0  61.0  1.0   \n",
       "1002      88    5.0         3.0      1.0        4.0     1.0  46.0  1.0   \n",
       "1003      88    4.0         4.0      2.0        6.0     1.0  49.0  1.0   \n",
       "1004      88    4.0         2.0      1.0        3.0     1.0  37.0  1.0   \n",
       "1005      88    3.0         3.0      1.0        5.0     1.0  56.0  1.0   \n",
       "1006      88    3.0         3.0      4.0        6.0     1.0  55.0  1.0   \n",
       "1007      88    4.0         4.0      2.0        5.0     1.0  41.0  1.0   \n",
       "1008      88    1.0         1.0      2.0        4.0     1.0  49.0  1.0   \n",
       "1009      88    3.0         3.0      1.0        5.0     1.0  43.0  1.0   \n",
       "\n",
       "      job_type  house_lat   house_lon   work_lat    work_lon  H_ZONE  \\\n",
       "1000       4.0  37.511534  126.902390  37.031954  127.077127   954.0   \n",
       "1001       6.0  37.000396  127.106922  37.034933  127.078710    50.0   \n",
       "1002       4.0  37.195733  127.034267  37.039019  127.077925   287.0   \n",
       "1003       6.0  37.067362  127.056343  37.037719  127.077653   130.0   \n",
       "1004       4.0  37.151695  127.078077  37.039019  127.077925   218.0   \n",
       "1005       6.0  37.053694  127.047655  37.038303  127.082699   105.0   \n",
       "1006       6.0  37.102160  127.021462  37.036618  127.077674   173.0   \n",
       "1007       6.0  37.037146  127.029241  37.035418  127.074294    86.0   \n",
       "1008       6.0  37.076516  127.064009  37.036774  127.072348   130.0   \n",
       "1009       6.0  36.989866  127.090719  37.037373  127.088846    35.0   \n",
       "\n",
       "      H_ZONE_X  H_ZONE_Y  W_ZONE_X  W_ZONE_Y             0  \n",
       "1000  191000.0  445000.0  207000.0  393000.0  25940.567472  \n",
       "1001  209000.0  389000.0  207000.0  393000.0  25940.567472  \n",
       "1002  203000.0  411000.0  207000.0  393000.0  25940.567472  \n",
       "1003  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1004  207000.0  405000.0  207000.0  393000.0  25940.567472  \n",
       "1005  205000.0  395000.0  207000.0  393000.0  25940.567472  \n",
       "1006  201000.0  401000.0  207000.0  393000.0  25940.567472  \n",
       "1007  203000.0  393000.0  207000.0  393000.0  25940.567472  \n",
       "1008  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1009  209000.0  387000.0  207000.0  393000.0  25940.567472  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.115620</td>\n",
       "      <td>126.792747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.335447</td>\n",
       "      <td>126.677584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.975082</td>\n",
       "      <td>127.436894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.847868</td>\n",
       "      <td>127.414170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.967527</td>\n",
       "      <td>124.717824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  job_type  \\\n",
       "0       0    4.0         4.0      1.0        5.0     1.0  41.0  1.0       4.0   \n",
       "1       0    3.0         3.0      2.0        3.0     1.0  36.0  1.0       4.0   \n",
       "2       0    3.0         3.0      2.0        2.0     1.0  70.0  1.0       9.0   \n",
       "3       0    5.0         4.0      1.0        5.0     1.0  32.0  1.0       4.0   \n",
       "4       0    2.0         2.0      4.0        3.0     1.0  55.0  1.0       4.0   \n",
       "\n",
       "    work_lat    work_lon  \n",
       "0  36.115620  126.792747  \n",
       "1  37.335447  126.677584  \n",
       "2  36.975082  127.436894  \n",
       "3  36.847868  127.414170  \n",
       "4  37.967527  124.717824  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# not calculating distance, simply using latitude\n",
    "x = data.iloc[:, 0:13]\n",
    "x = x.drop([\"house_lat\", \"house_lon\"], axis= 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W_ZONE          0\n",
       "no_hh         180\n",
       "no_hh_chil    180\n",
       "hh_type       180\n",
       "hh_income     180\n",
       "no_car        180\n",
       "age           180\n",
       "sex           180\n",
       "job_type      180\n",
       "work_lat      180\n",
       "work_lon      180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(x.iloc[:, 1:10])\n",
    "# x.iloc[:, 1:10] = imputer.transform(x.iloc[:, 1:10])\n",
    "x = x.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1326</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15391</td>\n",
       "      <td>15422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>732</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3594</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>648</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3210</td>\n",
       "      <td>3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1120</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6152</td>\n",
       "      <td>6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>246</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>567</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car  age  sex  \\\n",
       "hh_type                                                                    \n",
       "1.0        1326      8           8        1          8       2   66    2   \n",
       "2.0         732      7           7        1          8       2   62    2   \n",
       "3.0         648      6           6        1          8       2   58    2   \n",
       "4.0        1120      7           6        1          8       2   60    2   \n",
       "5.0         246      6           5        1          7       2   50    2   \n",
       "6.0          93      6           5        1          6       2   47    2   \n",
       "\n",
       "         job_type  work_lat  work_lon  \n",
       "hh_type                                \n",
       "1.0             9     15391     15422  \n",
       "2.0             8      3594      3605  \n",
       "3.0             9      3210      3214  \n",
       "4.0             7      6152      6173  \n",
       "5.0             7       567       566  \n",
       "6.0             6       123       123  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()\n",
    "x.groupby('hh_type').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original data\n",
    "x_original = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category values: hh_type, hh_income (this one is fine because of the levels)\n",
    "# Encoding categorical data\n",
    "# encode variable: hh_type, sex, job_type, W_Zone\n",
    "\n",
    "# make X a numpy array of x\n",
    "X_W = x.iloc[:, 0]\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# W_Zone\n",
    "labelencoder_X_W = LabelEncoder()\n",
    "X_W = labelencoder_X_W.fit_transform(X_W)\n",
    "onehotencoder_X_W = OneHotEncoder(categorical_features = [0])\n",
    "X_W = onehotencoder_X_W.fit_transform(X_W.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_W = X_W[:, 1:]\n",
    "# print(len(X_W[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_type\n",
    "X_hh = x.iloc[:, 3]\n",
    "labelencoder_X_hh = LabelEncoder()\n",
    "X_hh = labelencoder_X_hh.fit_transform(X_hh)\n",
    "onehotencoder_hh = OneHotEncoder(categorical_features = [0])\n",
    "X_hh = onehotencoder_hh.fit_transform(X_hh.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_hh = X_hh[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_type\n",
    "X_job = x.iloc[:, 8]\n",
    "labelencoder_X_job = LabelEncoder()\n",
    "X_job = labelencoder_X_job.fit_transform(X_job)\n",
    "onehotencoder_X_job = OneHotEncoder(categorical_features = [0])\n",
    "X_job = onehotencoder_X_job.fit_transform(X_job.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_job = X_job[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the variables: \n",
    "X = x.values\n",
    "# for i, x1 in enumerate(X[0]):\n",
    "#     print(\"column %s\" %i, x1)\n",
    "# take out the three columns\n",
    "X = np.delete(X, 0, axis = 1)\n",
    "X = np.delete(X, 2, axis = 1)\n",
    "X = np.delete(X, 6, axis = 1)\n",
    "X = np.append(X, X_W, axis = 1)\n",
    "X = np.append(X, X_hh, axis = 1)\n",
    "X = np.append(X, X_job, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummary:\\ncolumn 0: no_hh\\ncolumn 1: no_hh_chil\\ncolumn 2: hh_income\\ncolumn 3: no_car\\ncolumn 4: age\\ncolumn 5: sex\\ncolumn 6: work_lat\\ncolumn 7: work_lon\\ncolumn 8~1570: W_ZONE\\ncolumn 1571~1575: hh_type\\ncolumn 1576~1584: job_type\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Summary:\n",
    "column 0: no_hh\n",
    "column 1: no_hh_chil\n",
    "column 2: hh_income\n",
    "column 3: no_car\n",
    "column 4: age\n",
    "column 5: sex\n",
    "column 6: work_lat\n",
    "column 7: work_lon\n",
    "column 8~1570: W_ZONE\n",
    "column 1571~1575: hh_type\n",
    "column 1576~1584: job_type\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher Dimensions\n",
    "# higher dimensions for continuous variables: hh_income, age, no_car, no_hh\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# no_hh\n",
    "X_no_hh = X[:, 0]\n",
    "poly_reg_no_hh = PolynomialFeatures(degree = 4)\n",
    "X_no_hh = poly_reg_no_hh.fit_transform(X_no_hh.reshape(-1, 1))\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_hh, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1585~1587: poly no_hh\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "column 1585~1587: poly no_hh\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_income\n",
    "X_hh_income = X[:, 2]\n",
    "poly_reg_hh_income = PolynomialFeatures(degree = 4)\n",
    "X_hh_income = poly_reg_hh_income.fit_transform(X_hh_income.reshape(-1, 1))\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_hh_income, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1588~1590: poly hh_income\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1588~1590: poly hh_income\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "X_age = X[:, 4]\n",
    "poly_reg_age = PolynomialFeatures(degree = 4)\n",
    "X_age = poly_reg_age.fit_transform(X_age.reshape(-1, 1))\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_age, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1591~1593: poly X_age\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1591~1593: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_car\n",
    "X_no_car = X[:, 3]\n",
    "poly_reg_car = PolynomialFeatures(degree = 4)\n",
    "X_no_car = poly_reg_car.fit_transform(X_no_car.reshape(-1, 1))\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_car, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1594~1596: poly X_age\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1594~1596: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.453952</td>\n",
       "      <td>126.716877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.465845</td>\n",
       "      <td>126.717234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.229621</td>\n",
       "      <td>127.284122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.623500</td>\n",
       "      <td>127.083187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.469676</td>\n",
       "      <td>126.644354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_lat   house_lon\n",
       "0  37.453952  126.716877\n",
       "1  37.465845  126.717234\n",
       "2  37.229621  127.284122\n",
       "3  37.623500  127.083187\n",
       "4  37.469676  126.644354"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:, [\"house_lat\", \"house_lon\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_lat    180\n",
       "house_lon    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(y)\n",
    "# y = imputer.transform(y)\n",
    "y = y.dropna()\n",
    "Y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set (original dataset for random forest and SVM)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_original, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Standardization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# Normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "# Fitting the Random Forest Regression Model to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy based on distance\n",
    "def accuracy(pred):\n",
    "    sum_error = 0\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        sum_error += error\n",
    "    return sum_error\n",
    "\n",
    "def ind_diff(pred):\n",
    "    diff = []\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        diff.append(error)\n",
    "    return pd.DataFrame({'Difference': diff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836.4854723538451"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "Svr = SVR(kernel = 'rbf')\n",
    "regressor = MultiOutputRegressor(Svr)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910.4894551538027"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Difference\n",
       "0    0.136940\n",
       "1    0.100117\n",
       "2    0.046069\n",
       "3    0.328629\n",
       "4    0.223993"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXGWd7/vPr6vTCdXhlibMS4ipjoogJBCgtxtEj2jUyTDIiCNqqGTCRSKdo7LnAgP0ni1nvyZsOHB0s8XAKyqEoXtH5uAgOgMqIGxBRXfgRK6Ry6S7E0CSdASSNCHp7t/5Y63qrqpeq7qq69aX7/v1Wq9UrVpr1bO6YP3Ws57n+T3m7oiIiIxXQ70LICIik5sCiYiIlEWBREREyqJAIiIiZVEgERGRsiiQiIhIWRRIRCYpM7vazL5b73KImMaRyHRmZt3AnwCDwB7gJ8BX3H1PPcslMpmoRiICn3b32cBi4GTgqkp/gZklKn1MkYlCgUQk5O5/AH5KEFAws5lmdqOZ9ZrZ62Z2q5kdlNnezK4ws9fM7FUz+5KZuZm9L/xsvZndYmb3mdle4GOFjmdmR5jZv5rZG2a2y8weNbOG8LO/N7NXzGy3mf3ezJaE668xs86s8pxjZs+Gx3jEzD6Q9Vm3mf2dmT1lZm+a2V1mNqsGf1aZBhRIREJmNg/4M+ClcNV1wPsJAsv7gKOB/xJuuxT4G+AT4WdnRhzyfGANcDDwWKHjAX8LbAPmEjxquxpwMzsW+ArwH9z9YOBPge6Isr8f2AD8p/AY9wE/NrOmrM0+DywFFgAnAhcU9YcRGYMCiQj80Mx2A1uB7cDXzcyAVcBfu/sud98NXAt8Mdzn88Dt7v6su/cD10Qc9153/6W7DwHvjHG8A8C7gJS7H3D3Rz1owBwEZgLHm9kMd+9295cjvusLwL+5+wPufgC4ETgI+FDWNv/D3V91913AjwlrXiLlUiARgc+Ed/tnAscBRxDc1SeBJ8JHRW8QNMTPDfc5iiDwZGS/jlo31vFuIKgJ/czM/t3MrgRw95cIahnXANvN7PtmdlTEdx0F9GTehMFrK0GtJ+MPWa/7gdkRxxEpmQKJSMjd/xewnuBufifwNnCCux8WLoeGjfIArwHzsnZ/d9Qhs14XPJ6773b3v3X39wDnAH+TaQtx9//p7h8GUuExr4/4rlfDzwEIa1TvBl4p7a8gUjoFEpFc/x34JLAI+A7wTTM7EsDMjjazPw23+2fgQjP7gJklgX8odNCwhhB7PDM728zeFwaANwkeaQ2Z2bFm9nEzmwnsIwhGQxFf8c/An5vZEjObQdDm8g7wq/H/KUSKo0AiksXddwD/RNAI/vcEj5seN7O3gAeBY8Pt7gf+B/BwZpvwEO8UOHzs8YBjwvd7gF8Da939YYL2kesIajR/AI4konuyu/8eWA58K9z20wTdmveX/EcQKZEGJIpUQNjV9hlgprsP1Ls8IrWkGonIOJnZueHYkMMJ2i1+rCAi05ECicj4fZmgu/DLBG0a7fUtjkh96NGWiIiURTUSEREpS2O9C1ALRxxxhLe2tta7GCIik8oTTzyx093njrXdtAgkra2tbNy4sd7FEBGZVMysZ+yt9GhLRETKpEAiIiJlUSAREZGyTIs2kigHDhxg27Zt7Nu3r95FmTJmzZrFvHnzmDFjRr2LIiI1NG0DybZt2zj44INpbW0lyJMn5XB3+vr62LZtGwsWLKh3cUSkhqbto619+/bR0tKiIFIhZkZLS4tqeCLT0LStkQBjB5G+PnjlFdi/H5qa4OijoaWlNoWbhBSURaanaR1ICurrg54eGAqnfti/P3gPCiYiIlmm7aOtMb3yykgQyRgaCtZX0A9/+EPMjM2bNxfcbv369bz66qvj/p5HHnmEs88+e9z7i4jEUSCJsz9mPqC49eO0YcMGPvzhD7Nhw4aC25UbSEREqkWBJE5TU+77+++HT38aPvhBaG2Frq6yv2LPnj089thjfO973+P73//+8Prrr7+eRYsWcdJJJ3HllVdy9913s3HjRtLpNIsXL+btt9+mtbWVnTt3ArBx40bOPPNMAH77299y+umnc/LJJ/OhD32I3//+92WXU0SkELWRxDn66JE2kvvvh2uvhUyPpJ4eWLUqeJ1Oj/sr7r33XpYuXcr73/9+WlpaeOKJJ9i+fTv33nsvv/nNb0gmk+zatYs5c+Zw8803c+ONN9LW1lbwmMcddxyPPvoojY2NPPjgg1x99dX84Ac/GHcZRUTGokASJ9Og/sorsHbtSBDJ6O+Hjo6yAsmGDRu47LLLAPjiF7/Ihg0bcHcuvPBCkskkAHPmzCnpmG+++SYrV67kxRdfxMw4cODAuMsnIlIMBZJCWlqC5fXXoz/v7R33oXft2sXPf/5znn76acyMwcFBzIzzzjuvqP0bGxsZCjsDZI/d+Id/+Ac+9rGPcc8999Dd3T38yEtEpFrURlKM+fNLW1+Eu+++mxUrVtDT00N3dzdbt25lwYIFHHroodx+++309/cDQcABOPjgg9m9e/fw/q2trTzxxBMAOY+u3nzzTY4++mggaKAXEak2BZJirFkD4aOmYclksH6cNmzYwLnnnpuz7i//8i957bXXOOecc2hra2Px4sXceOONAFxwwQVceumlw43tX//617nssstoa2sjkUgMH+OKK67gqquu4uSTT2ZgYGDc5RMRKda0mLO9ra3N8ye2ev755/nABz5Q/EG6uoI2kd7eoCayZk1Z7SNTVcl/VxGZsMzsCXcv3MMHtZEUL51W4BARiaBHWyIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgqaNEIsHixYtZuHAh55133vAgxPHIThP/ox/9iOuuuy522zfeeIO1a9cOv3/11Vf53Oc+N+7vFpHprWqBxMxuM7PtZvZM1robzGyzmT1lZveY2WHh+hlmdoeZPW1mz5vZVTHHXG9mW8xsU7gsrlb5a+Gggw5i06ZNPPPMMzQ1NXHrrbfmfO7uw2lQSnHOOedw5ZVXxn6eH0iOOuoo7r777pK/R0QEqlsjWQ8szVv3ALDQ3U8EXgAyAeM8YKa7LwJOBb5sZq0xx73c3ReHy6aKlzpGV1eQPb6hoWJZ5HN85CMf4aWXXqK7u5tjjz2Wv/qrv2LhwoVs3bqVn/3sZ5x++umccsopnHfeeezZsweAn/zkJxx33HGccsop/Mu//MvwsdavX89XvvIVAF5//XXOPfdcTjrpJE466SR+9atfceWVV/Lyyy+zePFiLr/8crq7u1m4cCEQ5O268MILWbRoESeffDIPP/zw8DE/+9nPsnTpUo455hiuuOKKyv4BRGTSqlogcfdfALvy1v3M3TN5Ox4H5mU+AprNrBE4CNgPvFWtspWqqyvIGt/TA+4jWeQrFUwGBga4//77WbRoEQAvvvgiq1ev5tlnn6W5uZl//Md/5MEHH+TJJ5+kra2Nb3zjG+zbt49LLrmEH//4xzzxxBP84Q9/iDz21772NT760Y/yu9/9jieffJITTjiB6667jve+971s2rSJG264IWf7b3/725gZTz/9NBs2bGDlypXDSSE3bdrEXXfdxdNPP81dd93F1q1bK/MHEJFJrZ5tJBcB94ev7wb2Aq8BvcCN7r4rZr814aOxb5rZzLiDm9kqM9toZht37NhRVkE7OoKs8dkyWeTL8fbbb7N48WLa2tqYP38+F198MQCpVIrTTjsNgMcff5znnnuOM844g8WLF3PHHXfQ09PD5s2bWbBgAccccwxmxvLlyyO/4+c//znt7e1A0CZz6KGHFizTY489Nnys4447jlQqxQsvvADAkiVLOPTQQ5k1axbHH388PZk57EVkWqtLihQz6wAGgMw9/QeBQeAo4HDgUTN70N3/PW/Xq4A/AE3AOuDvgf8a9R3uvi7chra2trISisVliy8jizww0kaSr7m5efi1u/PJT35y1FS8UftV28yZI3E7kUgoKaSIAHWokZjZBcDZQNpHMkaeD/zE3Q+4+3bgl8CoRGHu/poH3gFuJwhAVVeFLPJFO+200/jlL3/JSy+9BMDevXt54YUXOO644+ju7ubll18GiJ3zfcmSJdxyyy0ADA4O8uabb45KSZ/tIx/5CF3hM7sXXniB3t5ejj322EqflohMITUNJGa2FLgCOMfdsx8W9QIfD7dpBk4DNkfs/67wXwM+AzyTv001VCGLfNHmzp3L+vXrWbZsGSeeeCKnn346mzdvZtasWaxbt44///M/55RTTuHII4+M3P+mm27i4YcfZtGiRZx66qk899xztLS0cMYZZ7Bw4UIuv/zynO1Xr17N0NAQixYt4gtf+ALr16/PqYmIiOSrWhp5M9sAnAkcAbwOfJ3g0dRMoC/c7HF3v9TMZhPUMI4HDLjd3W8Ij3Mf8CV3f9XMfg7MDbfZBFzq7nvGKksl0sgri3xxlEZeZOqoexp5d18Wsfp7MdvuIegCHPXZWVmvP16Z0pVOWeRFRKJpZLuIiJRlWgeS6TA7ZC3p7ykyPU3bQDJr1iz6+vp08asQd6evr49Zs2bVuygiUmPTdqrdefPmsW3bNsodrCgjZs2axbx588beUESmlGkbSGbMmMGCBQvqXQwRkUlv2j7aEhGRylAgERGRsiiQiIhIWRRIRESkLAokIiJSFgUSEREpiwKJiIiURYFERETKokAiIiJlUSAREZGyKJCIiEhZFEhERKQsCiQiIlIWBRIRESmLAomIiJRFgURERMqiQCIiImVRIBERkbIokIiISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgERGRsiiQiIhIWaoaSMzsNjPbbmbPZK27wcw2m9lTZnaPmR0Wrp9hZneY2dNm9ryZXRVzzAVm9hsze8nM7jKzpmqeg4iIFFbtGsl6YGneugeAhe5+IvACkAkY5wEz3X0RcCrwZTNrjTjm9cA33f19wB+BiytfbBERKVZVA4m7/wLYlbfuZ+4+EL59HJiX+QhoNrNG4CBgP/BW9r5mZsDHgbvDVXcAn6lO6UVEpBj1biO5CLg/fH03sBd4DegFbnT3XXnbtwBvZAWibcDRtSioiIhEq1sgMbMOYADoCld9EBgEjgIWAH9rZu8p4/irzGyjmW3csWNH2eUVEZFodQkkZnYBcDaQdncPV58P/MTdD7j7duCXQFvern3AYeHjLwgei70S9R3uvs7d29y9be7cuRU/BxERCdQ8kJjZUuAK4Bx378/6qJeg/QMzawZOAzZn7xsGnYeBz4WrVgL3VrvMIiISr9rdfzcAvwaONbNtZnYxcDNwMPCAmW0ys1vDzb8NzDazZ4H/Ddzu7k+Fx7nPzI4Kt/t74G/M7CWCNpPvVfMcRESkMBt5sjR1tbW1+caNG+tdDBGRScXMnnD3/CaGUerda0tERCY5BRIRESmLAomIiJRFgURERMqiQCIiImVRIBERkbIokIiISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgEZHKOeEEMBtZTjih3iWSGlAgEZHKOOEEeO653HXPPadgMg0okIhIrq4uaG2Fhobg366u4vbLDyJjrZcpo3HsTURk2ujqglWroD+cBbunJ3gPkE7Xr1wyoalGIjJFjadi0XXZb2jtf5YGBmllC10sC4JKR8fYx2dZhc9AJgsFEpEpKFOx6OkB97BisaKfLksHV/3Vq3OjwOrVdB3xNVb1/Td6aMVpoIdWVvGdIED09o59fPtedDA5/vjyT2Y8j9qkdtx9yi+nnnqqi0wbnZ2eSmz14BKfuyQ44Magp9jinSzL+TDFlsh9Umxxb2nJ+YpUavR24J5q3DZ6ZXt7WefiyWTu8ZLJYL1UHbDRi7jGqkYiMknk35hnVyqOOCJYGsxpXfERegaPijzGII3DtY0VdLKab9HFMlrZQg+pyH16mT96XW/EhkDvwLtGr7zllqCw49HRMdJekxHzqE3qx4KgM7W1tbX5xo0b610MkXHLbwMfizFEcfeJQzQyyAAzCmzjpOhhTWfrcHt7a2vwOCtfim66WTD6g0QCBgaG33Z1BbGgtxfmz4c1a2La8hsagnpIPjMYGip0YlIBZvaEu7eNtZ1qJCKTQNSNeSFBECnmJrFhjCACYPTQykUXhbWeBtizB5qacrdKspc1XB19iMHB4SpUl6VZtaI/t31lVUzTx/zRtaGC66UuFEhEJrJwpHhvz3juvq2iRdm/H/r6got/X19QwWhpAcNJJbaxjktIsyH+ALfcAj09dLCGfk/mfBT7tGrNGkjmbksyGayXCUPjSEQmqqyR4vPppYfW+pYnz9AQsG8fQ8mWkqpLUW0uENPuknneVdRzMKkX1UhEJqqsEeFruJoke+tYmGh9e2dCf/9wg70xSCMHMAY5gu0cwfbcMSkEQTHKnDkxX5JOQ3d3ELm6uxVEJiAFEpFJ4iD6Cdo9nGbeooH99S4SAKv5Fqv4TlhjamCQRqCBPubSx9zhXmIXcTtHsJ0e5hPVfvPWWxoiMlkpkIhMQF1d0MoWGsI7+wu5jT7mErR7GE6CL7OOFN0YQ6RS0Nxcj5Iat7Kafsb+8v3MDM+hgaj2mwMHYOXKyRlMhrtmm9PauG1k4OdkPJlxKCqQmNlnzexFM3vTzN4ys91m9la1CycyHQ2PGg9HmPcxlwPMytmmn2bu42y6WcAQCbq7Ydas6ONVWyWHow0OFujBNRF1dQUZAZbvDXqhYfQMzmMV6+jq+dAkO5nxK2ociZm9BHza3Z+vfpEqT+NIZDKJG6Mx2hBOAoCuTmf58mqWqrZSqaA5ZEILI35r/7ORHSGGx9RMipOJVulxJK9P1iAiMtnEjRqP0sUyuo76u+EEvaWZuIORS/kb1DIXV85XrfwoXf1/Ed8LLbO+pJOZnIoNJBvN7C4zWxY+5vqsmX22qiUTmabmz9lT5JYNfJlbWfnadSUNVgw4xyc2Y1RydLgTH5yGCnw2WtHjDSOzR5b5OCkmMI36qsF5rOI7zKEv+hwyvdOmweDJYgPJIUA/8Cng0+FydrUKJTJtdXWx5q2vFt3Vdy8HM+iJkr5iBvto59t0D86vaPtGih4sNlgYxQ6QLGm8YSVycX3iE7nTAy9fnhuYli+Ho4+O/qqwk0H+7zU8yn+6DJ4sJrPjeBbgNmA78EzWuhuAzcBTwD3AYeH6NLApaxkCFkcc8xrglaztziqmLMr+K5NGmFa3k2WeYosbg57gQGSm3fEvQ+FSuWMm2TNc5vjvLFwmY9BTia3e2f7o2H+nzs74FMRZSzvfCv9+Q55IRCQiXrKk6JM0BiM/MgZzfq9UQ693cn5QvkmepZgis/8WGxTmhRf+7eHyA2DeGPv8H8ApeYHkU0Bj+Pp64PqI/RYBL8cc8xrg74opc/aiQCKThtmoK1Unyyp+4a9kUMpOSd/JMk+yp8QgknecsdLER6WWjwkiUd/d3Dxy+JwAEJFaP3uJTbOf2Br8blMgcOSrdCB5ALiQIKVKI3AB8EAR+7VmB5K8z84FuiLWXwusidlHgUSmtpi77LiLYvzdf/UDT6YWElVWY2BcZRg+ZipV8t8ofylUk0smg9pJftCLO6fhIGl7Rx1nisWOHJUOJJuKWRexTaFA8mNgecT6l4GFMftcA3SHj8ZuAw4v8N2rgI3Axvnz51f67ytSHQXutkceHY39mKjaQQSGvIXtDkOesAEnvKNfknjIiXkEVOySYktwhx8notYWtYz375BiS+yHnZzvqdSUrYCMUmwgKbalrc/MlptZIlyWQ0xXhSKYWQcwAHTlrf+PQL+7PxOz6y3Ae4HFwGvA/xP3He6+zt3b3L1t7ty54y2qSG2l07BuXTD2wCz4t70dUinS9n26U2eSmrW93qUEbHikfdDYH6RBeWjw45SbMKOH+YV7Oo3RCyqT92u8Mt12M8fJzhWWTv1yJO3Xmi7SHa2aAhiKrpGkgB8BOwjaSH4IvLuI/VrJq5EQPBb7NZCM2P6bwNVFlmnUseMWPdqSqWTsJoKJ2p5S7DLkqZbd8Xf7Y9TaRrfRlLZk2koiH3tlOgJMkymAqeSjrcgd4T8VsU3OxR5YCjwHzI3YtoGgR9Z7ChzvXVmv/xr4fjFlVSCRCS3TAynzvKS93cd6fjLSaSk6aMT1MKp3gChl+9jrcmdnMId8Jng0XeAp66lID7cZM0YdPjfIpMIyxE5an4oo8ORVi0DSO8bnGwgePx0AtgEXAy8BWxnpvntr1vZnAo9HHOe7QFv4+k7gaYI2kh9lB5ZCiwKJTFjF9EAqcKcbHzAGh9swJlYNpbSyjLou5/29OlnmM3i7ZuUfbrqJa6cp1LYzCdUikGwd7761XhRIZMIqsgfS8BU1q/bS2fLVsKF79OYts98upofshF/MPKihJRKRXXWDYFm78qhGEr2U0yrmZewrIlB8Hqbe3pwcHV3+RVb1/bfIUe3JpgGYOWscaVPqKfpyMr+5D265ha7Bzw/PeZKZ32QV36GPI2payuFB6pWcAnj1amhsDDpXNDYG7yebQlEG2A28FbHsBgaKiVQTYVGNRCasUmokWdvGDY4zBmKf70+2JZl077R0wfOt5WO7lpa83y6/bWs8De3t7dFfNmoIfn1QZI2kqDTyk53SyMuElallFKo+JJNBl+AVK4LLDME8hNEPFJxic1rVRzHlc1IpC6ZmXx5sW+/zzfwEFZ/lt7ExmIQlXyIBAwMV/rLSVTqNvIhUQ4FxI8PvM1ewrPETcfOeT+wgAsU8ETd8ZGr2huASFXe+LbaLJt6pStkyCSizf4JilJTVPiqIFFo/URVTbZnsix5tSV1V4hFI5jjho49KjJeo+aMq9oTpU8bqmjwU/JnaHx3uHRU5riPszNbJ+RXo7jzkTez1TC+3FrYHqVKyE3MV+ROVNLwkkYguUCIxvv9GKoxq99qaTIsCidRNpQeuZY+fYFkVMgOXt7S0jIxvaRjOt5V1YYYig4l70vbm5L3K6bWV2DryJ0ylvFrZjEv9vUruzDVF2kjqfpGvxaJAInVT7JXl+ONzPz/++Ojj5QWm8d6JNzDgLWwP96/cRdgsqElEjgq3tHtDgzt4p6U9ZT3OGN9fKO/VcDfo5ksqHkhGfXeR3XrHNbwk7N486twmwCh5BZKsRYFE6maMK0tnp3uqcVt0GvNCwSQMUPG9mQovxuDwm0qOxWixnbG1pNE1lPPHLH92ObOX6s7XEvHdRQ40HPfwkgmackWBJGtRIJG6KXBl6ex0TzblXgQz7QjDj3BSBa4ljL+tJPtuu5Nl3sS+Clx8SxtFH4xIL7x9iu5RK4t9NAbuRx01/vMZT41k3PFggg5wVCDJWhRIpG6irixhLSV4tDP62pF/kcxUakYFlaxAENzZF/eYKmrOjexj1DZPV3x5k+zx9qbveKqhd7jG1s7NRQerIrPNR2433jaSzE9ect+KCZpyRYEka1EgkZqIuoJ0dgY9fyIuEuO5YOcElYiG6GLmKmnnWzkrc6aj5YAv4SdFHquay5Av4SfjnG2x+L9lU9Po9S3Nb3tny1drO+mIaiQTf1EgkaqLqnnMmBHfvZPxt28M3zVbv3eybByPt0amtY2eeTG4iNc72WPQplKdY5sVkeG33v/9TKI2Eo1sF6mE1lbo6Slply6WcRG3s5+Z4/7alsQfeWPwYAZpLHnfJt5hP01ED2L0mPWVNNZ3VK8M7e1w663BFTufWTBxVc11dUFHR5BXbf78IG9XxYfSl0Yj20VqqUDyxaiZ9jIGyrxQ9g0eXiCIFL5JDAJY3PfXYoS8YRS6YlcviKxdGz/R4hgTMFZPOs3I9Ivdo4NISUPma0uBRKQSYq4+XSyLzFrbxTIu4yaGaKpakWbyDmMFk3pzjKCMtSlnA4Oc8c9fg64uzjorqH1kSybhrLOKv153Jb9Eq3XTYEO0WjddyS+NfDbGdb+kuJCV+Rn34N9VqyZOMCnm+ddkX9RGIlUX00YS1w5S7cbsxkav6YRPk2sZ8tm85TMSuW0wZu5LlhTRVBGmqomdjvegi72zM2giy/nPgX3DU/WW3CRSp8Z41EYyQm0kUhMRz7gblp8f3nXnMobC9RM9yaIAtFgfs+fMpLevmTnsBAjnQhn9+6XoZk9LK319EcdhJzs7f0prRzqySS2VCp5qjdLQEISOfFVu0Cm2jUSBRKSK4trgW9gReyEqjVfgGDK24v/OwU1CXKuB4zTEpsWPjQtx/yHFRp7KUGO7yAQQOZEee8NXlQoAU/9msP6K/62ClPeFf5O4tPixDf2VnJGxChRIRKoonYZ1h11Oim6MIVJ0s45L6KOlQt+g2sjE4uyhmWZ2R37aEj4WW8PVWTcUgYJxIWremqrMtDU+erQlUm35XYOARg6Ma+xHPD3imkiaeIdBGhhkRs6627iQNBuAoEdfB9fSa60TZdjIKHq0JTKB5I8lGSRR4W9QEJlI9jOTw3gjpyaaHUQA0mygO3Vm7LCRyaSSt0QiEiEzlqSfZgB6aAWG0MV/attFCzs5MnjT2Qmr7oX+rA0mUBtHuVQjEamyDq4dDiIjqv2/3tR/ZD3ReThyv5EBVv9yYrdxlEuBRKTKeqlHzg3Vduor02ZlDJLgllsIgkmhFCiVUodUKgokIlUW19VTprLRgXzdutz3RV3vSw0KdUqlol5bItV0wgl0PXdSThuJTFdOS/M77No7kznsZDeH5GR+Tja+w7r1M0kTZkiIGoDY1AQHHwy7dkVnCK7wwEWNbM+iQCI1t3p1cAs6OAgwnKSxMqPZZapKzXqd7ob3QH//2BtD0GCf3dZS4VQq6v4rUi+rV8MttwwHkYy3SaIgIoX07ps7KogUmoaA/v6g9pJRp9z4CiQilZb/MJy4nlsiufLb0wpNQzAsey6cOqVSUSARqbS8mgjUq+eW1EZc80CpzQbOWfxrzpqoG5B+mung2pEV2bWNOqVSUSARqQH13JrKCs0yWUowMW7h/8x5fBV3AzK8Pqq2MdZMi1VQtUBiZreZ2XYzeyZr3Q1mttnMnjKze8zssHB92sw2ZS1DZrY44phzzOwBM3sx/PfwapVfpJLWcDUaJDgdlR5Msh9fxWYJpndCDWqsZo028CrkAAATGUlEQVRkPbA0b90DwEJ3PxF4AbgKwN273H2xuy8GVgBb3H1TxDGvBB5y92OAh8L3IhNLYnQerTQbYjPCylQRFzBKDSYjj69iswR3tk6oBF1VCyTu/gtgV966n7n7QPj2cWBexK7LgO/HHPYvgDvC13cAn6lAUUUqa9WqyNX9zK5xQaS2CvXIK723Xg8pVtDJQfTTwo6RaQgmRiUkRz3bSC4C7o9Y/wXISpGZ60/c/bXw9R+AP4k7uJmtMrONZrZxx44d5ZVUpBRr10J7+0jNJJGA9nbms7W+5ZJJxnAa6GMub5PkTpbTnTpzwgURqFMgMbMOYADoylv/H4F+d38mcscs4cT0sfVFd1/n7m3u3jZ37txyiyxSmrVrYWAgGBw2MABr17KGq1A7yfQVMS1NlsL/XfTTTIddN2GzBdc8kJjZBcDZQNpHD6v/IvG1EYDXzexd4XHeBWyvSiFFqiCd+OfhGfJk6mppiR7KcemlI71yW1qCJdNDt33J70kltmEMERdUev3dE++ZVqimgcTMlgJXAOe4e3/eZw3A54lvHwH4EbAyfL0SuLca5RSpmK4umDEjuGIMDnITl41qPJ3BPlRTmZyCC/+IZBJu+vxjrDvoayOTWrXsYd26oJKa6ZW7c2ewZHrorn3wOLoH5jHkDaRS0VWX+THrJwR3r8pCULN4DTgAbAMuBl4CtgKbwuXWrO3PBB6POM53gbbwdQtBb60XgQeBOcWU5dRTT3WRmuvsdDdzDx5wDS+dLPMUW9wY9BRbvJNl3s7NUZtqmcBLkj3ezrdGfsuUe2f7o+7JZN6GyeC/hRL+synzEBUDbPQirrFjbjAVFgUSqYtUqvirUirl7e2RcUfLhFyGvJ1vBW+WLMn5zaNuFDyVKuk/nc7OYBez4N96BBF3LzqQKPuvSLXEZWKN0tlJa0c6MgN48bK/awI/BpkiUoltdA/kjmDosjSrWJeT1iTJXtaxirRXf4KpSlP2X5F6KyXjajqdk3uvVEn20kmaVMM2FERqo3fw6FHrOhLXR+fGSlxfq2LVhQKJSLWcdVZJm5ee6dtHBqlxCenkvfQORY3xlWpwbGTSwtWrobGR3sGjIreNCjpTiQKJSDV0dUWmk4+0ZAkQnQG8kBQ9DJGgmwWkU7+Cdesmds+eSS36EWVPD6xY7tgtN9M6+BJz6Ivcbqr/LgokIpWWmTc7Ip38KEuWwIMPAiMZwCNSdY2SZG+YCJKge3GYdyk6GE39dtDqiw8EjkE4V8huDgm7c4+InQ6k1PnYJzAFEpFK6+gobqrUVGo4iGSk03DHHaODQSMHMAYBJ8EAK7mdNBuCILJ//8j+dLHuoK/Rwg6CAOI0s5sGighqUrb9zOQQdo+MIUnFJOjN3Gz09AQdMnp6gveTNJgokIhUWrGt5jHbpdOw7vTbSNGDMRQm7HOcBGAM0sgdTZfS1ek5QYSuLrjoIujbmTWtr7GXQ0hwgCbeKffMpAi7aKGbBQwlmuIT9EbdbORPmzuJKJCIVFqxreZx261eTfqhi+mmlSESzGYvB2jK2aR/f+Poa85ll8H+/ZGz6h1gFgfzVlZNRapleA6RmCzQQPzNRjld9+pIgUSk0oppNS80j3ZeI33sLHn515y+voLb76KFnan/QEuzaibj4xDWEIOAPDQ6RQp7WWP/Ocj+vHZt/KHibiJK77o3ISiQiFRa1LzZ7e3Fz6Od10gfO0te3LWo0Kx63d3s6p9V9KlINiNFLzs5kp0ciZPgTlbk/qydzaSHOgsHEYi+2Sh0czHRFTP8fbIvSpEik0oikZOPo5NlnmRPToqOyNxLLS3x27PHOy3t7qVlbtGSuxiDuSuam8f/O0+UPCgFUGSKFNVIRCaavGfraTawjktIze4rXKG56SaYMWNk+0zPocyAxUsPAUofryIjHKOVLXSxLFjx9tux247ZuzedHkkHPIGmzR2XYqLNZF9UI5EJK+6utL19pGaSSATvSzle9l1zxP7DX8uQNzBQ9zv9ybYk2RMkY4TYn2GiZPAtB0raOEJJG2VCyowlyO4GmkwWbj8p5dgdHUGL/Pz5QTUk5pgNNoQeTpQuRTfdifcFM2DmaW0lMgFnKhVUPiYLJW0UmeiqNZagxMFu8xOvlvd901Qv82O7+E6x3r1jUiARqZdqXW0KBaiIB/drVnWPmrVx+ir+Cc382X+M7Z01xXr3jkmBRKReqnW1iQtEmZpJXk0lfUZPTuN8KRfTqcNJ0U073x6VAaCRA8zIW5dMwppbW2KPNtV6945FgUSkXqp1tYkLRIlEdE1l+XLSbKCbBdzJcmwaBpIUPXSzgLV8ldu4MKfH23pWcjsXFT0MCKKHElWi6WuiUmO7SD2V0Che0jGjGvGLSCTZyhZ6aC3v+ycUZ6yJvmawj9u5KEiCGWeytZJXiBrbRSaDaowliLsdTqXG3DUuvcrkNfY8IDbWNlP5mVSFKJCITEVRAaqIkYhzWqbfJWE/M+ng2tEfTIdnUhXSWO8CiEiNZC6Gy5dHftxlad56a/R6Y2A4hf1UNaomNk0fZY3X9Lv9EJnO0ukggWSEjuabOHBg9HoL5zWZynISXTY26lFWiRRIRKabtWuDYJKZ0zeRgPZ2evdGd2cdmmKXCcuLiTnTFs+eDevX61FWiabWfyEiUpy1a4PUHu7Bv2vXFug1PFlrI04juVWsJHu59FJGp373/xn8LXbvVhAZBwUSEQHih7WsWgXJpvx8Uj4J5oE3BmmAcO76FnawjktYu3bqJN2dKBRIRASI7zW8di2su62RlPUOD9LrJM0/sYIEEY0qdRE9Hm6kk4AF89g3z65pqaYLBRIRGZbpNXznncH75cuDtufly4H587nzsK/SzQLSbCDNBu5gJc28Rf3Tqoz9+K2fZjr2dgRRMnKCEBkvBRKRqWzM2ZWid8mk5IKRmX97emDV/m/T1enDjfVpNrAnMYeWmXuqdgrFGzuY9fLu4EVPD6xYAatXV7lM04NSpIhMVeOc7yRuLo2MqCEWDQ1BW3W5zMo5zsiOxlD4WCtXim66WZD7hXfeqYaSGEqRIjLdjXO+k7Gy2Ed9Xon06C0twTV9xozxHsGGlxkMMIN9OZ/mdPPNcC9//hdRIBGZssY538lYQSHq8zVrRo/PKNXixUHF4Pbbg6BSjv3M5JBZA6QS23LnrY9KzDhVZ5uqoaoFEjO7zcy2m9kzWetuMLPNZvaUmd1jZodlfXaimf3azJ41s6fNbFbEMa8xs1fMbFO4nFWt8otMeuOc76RQSq64/IXpNFx6aaGj+piN8o88MnKsnTtHZjvv7BzJN5kY/bQq1q53ZtN9x/9iKHnwcAeBSFN1tqkaqmaNZD2wNG/dA8BCdz8ReAG4CsDMGoFO4FJ3PwE4E2L7FX7T3ReHy33VKLjIlBAVEcyCBhCzYPnEJ0btlt0NGEYu3mPlL1y7Nr4m0cJO9nAonaSJCyaDMcNSMj3J3OGOO4pKYgyE8SGdhtNPj9+oqUnpUCqgaoHE3X8B7Mpb9zN3z4xsehyYF77+FPCUu/8u3K7P3Sf6aCeRiS1/YEhT0+iW7Iceig0mmYt3ZgB8MYP3brppdOzKzDjYwCAdXEsDQ5H7jlXbyO9NVkgyCWsOXB6c90MPxW84Y4Ya2iugnm0kFwH3h6/fD7iZ/dTMnjSzKwrs95Xw0dhtZnZ43EZmtsrMNprZxh07dlSy3CKTR3Y6+f37o7cpdKEdx9etWwep2X0YQ7SwA8fpYy5OAz20xk7nu2pV4WNH9R3IaGkJFrPg34Pe3sWKV6+nlS10sSz+oHv3jquLtORx96otQCvwTMT6DuAeRrof/x2wBTgCSAK/BpZE7PcnQIIgAK4BbiumHKeeeqqLTHsjzQ6jl0pLJNzBU2yJ/Lpm3vQEBxyGPJFwb28f+5Bm0UU3G9mms9M9mcz9PMke72RZ/LmP2iEZHEgc2OhFXGNrXiMxswuAs4F0WFCAbcAv3H2nu/cD9wGn5O/r7q+7+6C7DwHfAT5Yo2KLSCnCBo+4GRf7mc0AM/DUgkzOyDEV03cgssczzdETV0FQCxlHF2nJVdNAYmZLgSuAc8KAkfFTYJGZJcOG948Cz0Xs/66st+cCz+RvIyIxZo3qCFl4fTnCBo+ceT6yDK8voaE7Lqlk9iFiezzHTSE8FN1eoy7Bpalm998NBI+ojjWzbWZ2MXAzcDDwQNh991YAd/8j8A3gfwObgCfd/d/C43zXzDIjK//vsGvwU8DHgL+uVvlFppzvfje4A8/W0BCsL1d+O8OZZwKwhqtJsjdn0+GBgccfX1JDd1xSyexDxNZaYgJabBcwdQkuTTHPvyb7ojYSkVBnp3sqFTQspFKVaQuIbJhIui9Z4p5IeCfLPMUWNwY9xZagvWLJkvK/t9iixLWRZM4/quzt7ZX/O01CFNlGUveLfC0WBRKRKkqlRl+kMxfqOsiPle1LnveU9eQGsuwG9fb24c4BnkgEQU4N8O5efCBR0kYRKU9cxkaz+DaIGula/Rirbj2Ffh9pXElaP+sufZL02g9HJ7aMyxwZla1yilPSRhGpjbj2hIaG+o7N6Oqi49b5OUEEoN+TdNz34eBNVDevuJtrNcDHUiARkfLEJecaHAwuyj09wV1/rYNJRwe9Pi/yo+GYUEpwUAN8LAUSESlPfneqqFwn1RqbUWhUem9vfPfj+fkv8uSnMo7LVimAAomIVEJ2KpZajc3ITr4VVfOZPz+6+7H1j8SEuMEpl15auJ+x5FAgEZHKGmf6+pKNNXHXmjWkk/eyjktI0R3MS2K9QUN7JibEDU5Zu3YkMBaTrXKaU68tEamscU7xW7Jieot1dQWBpbc3CGRr1igolEC9tkSkPooZgl4JxdR8sh+5qWZRNQokIlJ5tbiAF5N8S2pCgUREJqda1XxkTI31LoCIyLil0wocE4BqJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgERGRskyLFClmtgPoqXc5shwB7Kx3IepI56/z1/lPDil3nzvWRtMikEw0ZraxmPw1U5XOX+ev859a569HWyIiUhYFEhERKYsCSX2sq3cB6kznP73p/KcYtZGIiEhZVCMREZGyKJCIiEhZFEgqyMxmmdlvzex3Zvasmf1f4XozszVm9oKZPW9mX4vZf6WZvRguK2tb+vJV4PwHzWxTuPyotqUvX4HzfzTrvF41sx/G7D9Vf/9iz3+q/v5LzOzJ8LweM7P3xex/lZm9ZGa/N7M/rW3py+TuWiq0AAbMDl/PAH4DnAZcCPwT0BB+dmTEvnOAfw//PTx8fXi9z6lW5x+u31Pvc6jG+edt8wPgr6bT71/M+U/l3x94AfhAuH41sD5i3+OB3wEzgQXAy0Ci3udU7KIaSQV5YE/4dka4ONAO/Fd3Hwq32x6x+58CD7j7Lnf/I/AAsLQGxa6YMs9/0itw/gCY2SHAx4GoO/Kp/PsDY57/pFfg/B04JFx/KPBqxO5/AXzf3d9x9y3AS8AHq1zkilEgqTAzS5jZJmA7wYXhN8B7gS+Y2UYzu9/MjonY9Whga9b7beG6SaWM8weYFW7zuJl9pmaFrqCY88/4DPCQu78VsetU/v0zCp0/TN3f/0vAfWa2DVgBXBex66T+/RVIKszdB919MTAP+KCZLSSoru7zIC3Cd4Db6lnGairz/FPhNucD/93M3luTQldQzPlnLAM21KdktVHm+U/V3/+vgbPcfR5wO/CNepaxGhRIqsTd3wAeJng8sQ34l/Cje4ATI3Z5BXh31vt54bpJaRznj7u/Ev7778AjwMlVL2iV5J0/ZnYEwaOKf4vZZSr//sWc/1T9/f8MOCmrZnYX8KGIXSb1769AUkFmNtfMDgtfHwR8EthM8Ez4Y+FmHyVofMv3U+BTZna4mR0OfCpcN2mUc/7hec8MXx8BnAE8V4tyV0qB8wf4HPCv7r4vZvep/PvDGOc/hX//54FDzez94WaZdfl+BHzRzGaa2QLgGOC3NSh2ZdS7tX8qLQR32v8f8BTwDPBfwvWHEdyJPQ38muAOBaAN+G7W/hcRNLK9BFxY7/Op5fkT3KU9TdBz5Wng4nqfT6XOP/zsEWBp3vbT4vcv5vyn8u8PnJt1bo8A7wnXn0PQCSWzfwdBb63fA39W7/MpZVGKFBERKYsebYmISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBRKQGzGzP2FsNb3ummUUNWhOZkBRIRCaeM4ke/SwyIWkciUgNmNked5+dt+7TwH8GmoA+IA0cBDwODAI7gK+6+6M1Lq5ISRRIRGogJpAcDrzh7m5mXyKYs+Jvzewagrk5bqxHWUVK1VjvAohMY/OAu8zsXQS1ki11Lo/IuKiNRKR+vgXc7O6LgC8Ds+pcHpFxUSARqZ9DGUkVnj1H+27g4NoXR2R8FEhEaiNpZtuylr8BrgH+XzN7AtiZte2PgXPNbJOZfaQehRUphRrbRUSkLKqRiIhIWRRIRESkLAokIiJSFgUSEREpiwKJiIiURYFERETKokAiIiJl+f8BHHVdx8hV+/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                51136     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 63,746\n",
      "Trainable params: 63,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597)) #1597 for X and 11 for x_original\n",
    "regressor.add(Dropout(0.25))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.25))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.25))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.05, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_standardized = np.zeros((len(Y), 2))\n",
    "Y_standardized[:,0] = (Y[:,0] - np.mean(Y[:,0]))/ np.std(Y[:,0])\n",
    "Y_standardized[:,1] = (Y[:,1] - np.mean(Y[:,1]))/ np.std(Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed dataset with dummy variables and polynomials as well as standardized outcomes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_standardized, test_size = 0.2, random_state = 0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2422 - mean_absolute_error: 0.3465\n",
      "Epoch 2/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2418 - mean_absolute_error: 0.3468\n",
      "Epoch 3/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2427 - mean_absolute_error: 0.3468\n",
      "Epoch 4/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2435 - mean_absolute_error: 0.3480\n",
      "Epoch 5/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2427 - mean_absolute_error: 0.3469\n",
      "Epoch 6/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2428 - mean_absolute_error: 0.3478\n",
      "Epoch 7/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2433 - mean_absolute_error: 0.3483\n",
      "Epoch 8/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2424 - mean_absolute_error: 0.3471\n",
      "Epoch 9/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2434 - mean_absolute_error: 0.3475\n",
      "Epoch 10/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2414 - mean_absolute_error: 0.3472\n",
      "Epoch 11/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2410 - mean_absolute_error: 0.3467\n",
      "Epoch 12/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2417 - mean_absolute_error: 0.3469\n",
      "Epoch 13/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2425 - mean_absolute_error: 0.3472\n",
      "Epoch 14/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2432 - mean_absolute_error: 0.3478\n",
      "Epoch 15/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2423 - mean_absolute_error: 0.3469\n",
      "Epoch 16/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.2420 - mean_absolute_error: 0.3472\n",
      "Epoch 17/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2423 - mean_absolute_error: 0.3469\n",
      "Epoch 18/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.2423 - mean_absolute_error: 0.3468\n",
      "Epoch 19/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2422 - mean_absolute_error: 0.3468\n",
      "Epoch 20/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2414 - mean_absolute_error: 0.3465\n",
      "Epoch 21/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2402 - mean_absolute_error: 0.3453\n",
      "Epoch 22/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2412 - mean_absolute_error: 0.3460\n",
      "Epoch 23/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.2395 - mean_absolute_error: 0.3451\n",
      "Epoch 24/250\n",
      "37342/37342 [==============================] - 2s 54us/step - loss: 0.2420 - mean_absolute_error: 0.3476\n",
      "Epoch 25/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2412 - mean_absolute_error: 0.3467\n",
      "Epoch 26/250\n",
      "37342/37342 [==============================] - 2s 40us/step - loss: 0.2398 - mean_absolute_error: 0.3452\n",
      "Epoch 27/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2408 - mean_absolute_error: 0.3461\n",
      "Epoch 28/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2428 - mean_absolute_error: 0.3474\n",
      "Epoch 29/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2419 - mean_absolute_error: 0.3471\n",
      "Epoch 30/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2411 - mean_absolute_error: 0.3463\n",
      "Epoch 31/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2412 - mean_absolute_error: 0.3462\n",
      "Epoch 32/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2425 - mean_absolute_error: 0.3470\n",
      "Epoch 33/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2423 - mean_absolute_error: 0.3466\n",
      "Epoch 34/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2414 - mean_absolute_error: 0.3467\n",
      "Epoch 35/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2404 - mean_absolute_error: 0.3450\n",
      "Epoch 36/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2416 - mean_absolute_error: 0.3461\n",
      "Epoch 37/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2414 - mean_absolute_error: 0.3469\n",
      "Epoch 38/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2404 - mean_absolute_error: 0.3462\n",
      "Epoch 39/250\n",
      "37342/37342 [==============================] - 2s 40us/step - loss: 0.2409 - mean_absolute_error: 0.3460\n",
      "Epoch 40/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2390 - mean_absolute_error: 0.3450\n",
      "Epoch 41/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2402 - mean_absolute_error: 0.3463\n",
      "Epoch 42/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2404 - mean_absolute_error: 0.3463\n",
      "Epoch 43/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2397 - mean_absolute_error: 0.3456\n",
      "Epoch 44/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2407 - mean_absolute_error: 0.3460\n",
      "Epoch 45/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2423 - mean_absolute_error: 0.3476\n",
      "Epoch 46/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2407 - mean_absolute_error: 0.3453\n",
      "Epoch 47/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2410 - mean_absolute_error: 0.3467\n",
      "Epoch 48/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2412 - mean_absolute_error: 0.3465\n",
      "Epoch 49/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2415 - mean_absolute_error: 0.3469\n",
      "Epoch 50/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2395 - mean_absolute_error: 0.3454\n",
      "Epoch 51/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2417 - mean_absolute_error: 0.3470\n",
      "Epoch 52/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2403 - mean_absolute_error: 0.3458\n",
      "Epoch 53/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2405 - mean_absolute_error: 0.3456\n",
      "Epoch 54/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2404 - mean_absolute_error: 0.3456\n",
      "Epoch 55/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2391 - mean_absolute_error: 0.3438\n",
      "Epoch 56/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2400 - mean_absolute_error: 0.3449\n",
      "Epoch 57/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2405 - mean_absolute_error: 0.3458\n",
      "Epoch 58/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2421 - mean_absolute_error: 0.3458\n",
      "Epoch 59/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2404 - mean_absolute_error: 0.3454\n",
      "Epoch 60/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2397 - mean_absolute_error: 0.3445\n",
      "Epoch 61/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2412 - mean_absolute_error: 0.3464\n",
      "Epoch 62/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2389 - mean_absolute_error: 0.3447\n",
      "Epoch 63/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2411 - mean_absolute_error: 0.3466\n",
      "Epoch 64/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2399 - mean_absolute_error: 0.3453\n",
      "Epoch 65/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2395 - mean_absolute_error: 0.3453\n",
      "Epoch 66/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2388 - mean_absolute_error: 0.3445\n",
      "Epoch 67/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2391 - mean_absolute_error: 0.3444\n",
      "Epoch 68/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2403 - mean_absolute_error: 0.3448\n",
      "Epoch 69/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2392 - mean_absolute_error: 0.3448\n",
      "Epoch 70/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2425 - mean_absolute_error: 0.3460\n",
      "Epoch 71/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2392 - mean_absolute_error: 0.3452\n",
      "Epoch 72/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2400 - mean_absolute_error: 0.3453\n",
      "Epoch 73/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2397 - mean_absolute_error: 0.3452\n",
      "Epoch 74/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2399 - mean_absolute_error: 0.3450\n",
      "Epoch 75/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2386 - mean_absolute_error: 0.3441\n",
      "Epoch 76/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2391 - mean_absolute_error: 0.3445\n",
      "Epoch 77/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2386 - mean_absolute_error: 0.3438\n",
      "Epoch 78/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2395 - mean_absolute_error: 0.3449\n",
      "Epoch 79/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2387 - mean_absolute_error: 0.3445\n",
      "Epoch 80/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2394 - mean_absolute_error: 0.3447\n",
      "Epoch 81/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2380 - mean_absolute_error: 0.3447\n",
      "Epoch 82/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2406 - mean_absolute_error: 0.3457\n",
      "Epoch 83/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2401 - mean_absolute_error: 0.3447\n",
      "Epoch 84/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2384 - mean_absolute_error: 0.3441\n",
      "Epoch 85/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2383 - mean_absolute_error: 0.3444\n",
      "Epoch 86/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2405 - mean_absolute_error: 0.3461\n",
      "Epoch 87/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2401 - mean_absolute_error: 0.3457\n",
      "Epoch 88/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2385 - mean_absolute_error: 0.3446\n",
      "Epoch 89/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2389 - mean_absolute_error: 0.3447\n",
      "Epoch 90/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2378 - mean_absolute_error: 0.3437\n",
      "Epoch 91/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2380 - mean_absolute_error: 0.3434\n",
      "Epoch 92/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2390 - mean_absolute_error: 0.3444\n",
      "Epoch 93/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2387 - mean_absolute_error: 0.3441\n",
      "Epoch 94/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2369 - mean_absolute_error: 0.3430\n",
      "Epoch 95/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2363 - mean_absolute_error: 0.3429\n",
      "Epoch 96/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2394 - mean_absolute_error: 0.3447\n",
      "Epoch 97/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2387 - mean_absolute_error: 0.3447\n",
      "Epoch 98/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2389 - mean_absolute_error: 0.3442\n",
      "Epoch 99/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2390 - mean_absolute_error: 0.3442\n",
      "Epoch 100/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2384 - mean_absolute_error: 0.3446\n",
      "Epoch 101/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2385 - mean_absolute_error: 0.3440\n",
      "Epoch 102/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2380 - mean_absolute_error: 0.3446\n",
      "Epoch 103/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2389 - mean_absolute_error: 0.3444\n",
      "Epoch 104/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2376 - mean_absolute_error: 0.3435\n",
      "Epoch 105/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2382 - mean_absolute_error: 0.3432\n",
      "Epoch 106/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2389 - mean_absolute_error: 0.3445\n",
      "Epoch 107/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2382 - mean_absolute_error: 0.3442\n",
      "Epoch 108/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2367 - mean_absolute_error: 0.3432\n",
      "Epoch 109/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2376 - mean_absolute_error: 0.3441\n",
      "Epoch 110/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2383 - mean_absolute_error: 0.3439\n",
      "Epoch 111/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2369 - mean_absolute_error: 0.3433\n",
      "Epoch 112/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2377 - mean_absolute_error: 0.3444\n",
      "Epoch 113/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2383 - mean_absolute_error: 0.3442\n",
      "Epoch 114/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2372 - mean_absolute_error: 0.3432\n",
      "Epoch 115/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2370 - mean_absolute_error: 0.3432\n",
      "Epoch 116/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2385 - mean_absolute_error: 0.3442\n",
      "Epoch 117/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2378 - mean_absolute_error: 0.3438\n",
      "Epoch 118/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2371 - mean_absolute_error: 0.3431\n",
      "Epoch 119/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2378 - mean_absolute_error: 0.3440\n",
      "Epoch 120/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2369 - mean_absolute_error: 0.3425\n",
      "Epoch 121/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2372 - mean_absolute_error: 0.3433\n",
      "Epoch 122/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2374 - mean_absolute_error: 0.3440\n",
      "Epoch 123/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2353 - mean_absolute_error: 0.3419\n",
      "Epoch 124/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2373 - mean_absolute_error: 0.3431\n",
      "Epoch 125/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2376 - mean_absolute_error: 0.3435\n",
      "Epoch 126/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2374 - mean_absolute_error: 0.3429\n",
      "Epoch 127/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2388 - mean_absolute_error: 0.3445: 0s - loss: 0.2404 - mean_absolute_error: 0.\n",
      "Epoch 128/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2360 - mean_absolute_error: 0.3427\n",
      "Epoch 129/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2373 - mean_absolute_error: 0.3433\n",
      "Epoch 130/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2368 - mean_absolute_error: 0.3427\n",
      "Epoch 131/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2372 - mean_absolute_error: 0.3433\n",
      "Epoch 132/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2387 - mean_absolute_error: 0.3441\n",
      "Epoch 133/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2379 - mean_absolute_error: 0.3429\n",
      "Epoch 134/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2374 - mean_absolute_error: 0.3440\n",
      "Epoch 135/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2373 - mean_absolute_error: 0.3428\n",
      "Epoch 136/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2373 - mean_absolute_error: 0.3427\n",
      "Epoch 137/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2368 - mean_absolute_error: 0.3434\n",
      "Epoch 138/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2378 - mean_absolute_error: 0.3439\n",
      "Epoch 139/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2391 - mean_absolute_error: 0.3458\n",
      "Epoch 140/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2380 - mean_absolute_error: 0.3440\n",
      "Epoch 141/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2362 - mean_absolute_error: 0.3423\n",
      "Epoch 142/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2365 - mean_absolute_error: 0.3428\n",
      "Epoch 143/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2366 - mean_absolute_error: 0.3428\n",
      "Epoch 144/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2387 - mean_absolute_error: 0.3449\n",
      "Epoch 145/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2367 - mean_absolute_error: 0.3427\n",
      "Epoch 146/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2351 - mean_absolute_error: 0.3414\n",
      "Epoch 147/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2367 - mean_absolute_error: 0.3441\n",
      "Epoch 148/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2358 - mean_absolute_error: 0.3426\n",
      "Epoch 149/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2367 - mean_absolute_error: 0.3438\n",
      "Epoch 150/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2354 - mean_absolute_error: 0.3422\n",
      "Epoch 151/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2351 - mean_absolute_error: 0.3419\n",
      "Epoch 152/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2367 - mean_absolute_error: 0.3433\n",
      "Epoch 153/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2368 - mean_absolute_error: 0.3428\n",
      "Epoch 154/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2349 - mean_absolute_error: 0.3415\n",
      "Epoch 155/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2371 - mean_absolute_error: 0.3438\n",
      "Epoch 156/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2366 - mean_absolute_error: 0.3428\n",
      "Epoch 157/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2367 - mean_absolute_error: 0.3435\n",
      "Epoch 158/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2356 - mean_absolute_error: 0.3425\n",
      "Epoch 159/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2359 - mean_absolute_error: 0.3424\n",
      "Epoch 160/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2364 - mean_absolute_error: 0.3440\n",
      "Epoch 161/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2354 - mean_absolute_error: 0.3418\n",
      "Epoch 162/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2352 - mean_absolute_error: 0.3427\n",
      "Epoch 163/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2360 - mean_absolute_error: 0.3427\n",
      "Epoch 164/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2351 - mean_absolute_error: 0.3423\n",
      "Epoch 165/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2362 - mean_absolute_error: 0.3425\n",
      "Epoch 166/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2360 - mean_absolute_error: 0.3423\n",
      "Epoch 167/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2363 - mean_absolute_error: 0.3429\n",
      "Epoch 168/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2369 - mean_absolute_error: 0.3432\n",
      "Epoch 169/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2353 - mean_absolute_error: 0.3424\n",
      "Epoch 170/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2371 - mean_absolute_error: 0.3431\n",
      "Epoch 171/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2355 - mean_absolute_error: 0.3415\n",
      "Epoch 172/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2359 - mean_absolute_error: 0.3426\n",
      "Epoch 173/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2354 - mean_absolute_error: 0.3416\n",
      "Epoch 174/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2353 - mean_absolute_error: 0.3418\n",
      "Epoch 175/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2362 - mean_absolute_error: 0.3424\n",
      "Epoch 176/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2357 - mean_absolute_error: 0.3419\n",
      "Epoch 177/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2351 - mean_absolute_error: 0.3421\n",
      "Epoch 178/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2344 - mean_absolute_error: 0.3411\n",
      "Epoch 179/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2355 - mean_absolute_error: 0.3419\n",
      "Epoch 180/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2356 - mean_absolute_error: 0.3421\n",
      "Epoch 181/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2357 - mean_absolute_error: 0.3424: 0s - loss: 0.2413 - mean_absolut\n",
      "Epoch 182/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2365 - mean_absolute_error: 0.3421\n",
      "Epoch 183/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2362 - mean_absolute_error: 0.3426\n",
      "Epoch 184/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2356 - mean_absolute_error: 0.3420\n",
      "Epoch 185/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2355 - mean_absolute_error: 0.3416\n",
      "Epoch 186/250\n",
      "37342/37342 [==============================] - 2s 40us/step - loss: 0.2357 - mean_absolute_error: 0.3417\n",
      "Epoch 187/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2359 - mean_absolute_error: 0.3426\n",
      "Epoch 188/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2352 - mean_absolute_error: 0.3418\n",
      "Epoch 189/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2358 - mean_absolute_error: 0.3422\n",
      "Epoch 190/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2355 - mean_absolute_error: 0.3426\n",
      "Epoch 191/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2354 - mean_absolute_error: 0.3418\n",
      "Epoch 192/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2350 - mean_absolute_error: 0.3416\n",
      "Epoch 193/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2341 - mean_absolute_error: 0.3411\n",
      "Epoch 194/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2357 - mean_absolute_error: 0.3424\n",
      "Epoch 195/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2352 - mean_absolute_error: 0.3414\n",
      "Epoch 196/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2348 - mean_absolute_error: 0.3419\n",
      "Epoch 197/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2349 - mean_absolute_error: 0.3415\n",
      "Epoch 198/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2345 - mean_absolute_error: 0.3419\n",
      "Epoch 199/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2350 - mean_absolute_error: 0.3418\n",
      "Epoch 200/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2351 - mean_absolute_error: 0.3421\n",
      "Epoch 201/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2363 - mean_absolute_error: 0.3437\n",
      "Epoch 202/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2363 - mean_absolute_error: 0.3427\n",
      "Epoch 203/250\n",
      "37342/37342 [==============================] - 2s 40us/step - loss: 0.2340 - mean_absolute_error: 0.3404\n",
      "Epoch 204/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2348 - mean_absolute_error: 0.3417\n",
      "Epoch 205/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2365 - mean_absolute_error: 0.3424\n",
      "Epoch 206/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2358 - mean_absolute_error: 0.3428\n",
      "Epoch 207/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2353 - mean_absolute_error: 0.3416\n",
      "Epoch 208/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2356 - mean_absolute_error: 0.3420\n",
      "Epoch 209/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2366 - mean_absolute_error: 0.3434\n",
      "Epoch 210/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2354 - mean_absolute_error: 0.3419\n",
      "Epoch 211/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2345 - mean_absolute_error: 0.3417\n",
      "Epoch 212/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2343 - mean_absolute_error: 0.3411\n",
      "Epoch 213/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2342 - mean_absolute_error: 0.3411\n",
      "Epoch 214/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2343 - mean_absolute_error: 0.3411\n",
      "Epoch 215/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2336 - mean_absolute_error: 0.3402\n",
      "Epoch 216/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2345 - mean_absolute_error: 0.3413\n",
      "Epoch 217/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2333 - mean_absolute_error: 0.3408\n",
      "Epoch 218/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2346 - mean_absolute_error: 0.3420\n",
      "Epoch 219/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2338 - mean_absolute_error: 0.3407\n",
      "Epoch 220/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2339 - mean_absolute_error: 0.3413\n",
      "Epoch 221/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2342 - mean_absolute_error: 0.3408\n",
      "Epoch 222/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2327 - mean_absolute_error: 0.3396\n",
      "Epoch 223/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2341 - mean_absolute_error: 0.3410\n",
      "Epoch 224/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2341 - mean_absolute_error: 0.3415\n",
      "Epoch 225/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2347 - mean_absolute_error: 0.3416\n",
      "Epoch 226/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2360 - mean_absolute_error: 0.3425\n",
      "Epoch 227/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2360 - mean_absolute_error: 0.3427\n",
      "Epoch 228/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2327 - mean_absolute_error: 0.3400\n",
      "Epoch 229/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2361 - mean_absolute_error: 0.3423\n",
      "Epoch 230/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2340 - mean_absolute_error: 0.3413\n",
      "Epoch 231/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2335 - mean_absolute_error: 0.3399\n",
      "Epoch 232/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2354 - mean_absolute_error: 0.3424\n",
      "Epoch 233/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2356 - mean_absolute_error: 0.3418\n",
      "Epoch 234/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2346 - mean_absolute_error: 0.3415\n",
      "Epoch 235/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2342 - mean_absolute_error: 0.3410\n",
      "Epoch 236/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2347 - mean_absolute_error: 0.3411\n",
      "Epoch 237/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2344 - mean_absolute_error: 0.3414\n",
      "Epoch 238/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2343 - mean_absolute_error: 0.3408\n",
      "Epoch 239/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2331 - mean_absolute_error: 0.3403\n",
      "Epoch 240/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2333 - mean_absolute_error: 0.3405\n",
      "Epoch 241/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2341 - mean_absolute_error: 0.3414\n",
      "Epoch 242/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2320 - mean_absolute_error: 0.3401\n",
      "Epoch 243/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2348 - mean_absolute_error: 0.3410\n",
      "Epoch 244/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2330 - mean_absolute_error: 0.3408\n",
      "Epoch 245/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2339 - mean_absolute_error: 0.3407\n",
      "Epoch 246/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2356 - mean_absolute_error: 0.3422\n",
      "Epoch 247/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2328 - mean_absolute_error: 0.3402\n",
      "Epoch 248/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2327 - mean_absolute_error: 0.3398\n",
      "Epoch 249/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2341 - mean_absolute_error: 0.3414\n",
      "Epoch 250/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2333 - mean_absolute_error: 0.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a1e7240>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size = 64, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37.44112015, 127.45805359],\n",
       "       [ 37.61040497, 127.05838013],\n",
       "       [ 37.52433777, 127.00444031],\n",
       "       ...,\n",
       "       [ 37.56125641, 126.96965027],\n",
       "       [ 37.57268143, 126.97666931],\n",
       "       [ 37.43837357, 126.76522827]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new = np.zeros((len(y_pred), 2))\n",
    "y_test_new = np.zeros((len(y_test), 2))\n",
    "y_pred_new[:,0] = y_pred[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_pred_new[:,1] = y_pred[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "\n",
    "y_test_new[:,0] = y_test[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_test_new[:,1] = y_test[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "y_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 1597)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test_new[:, 0],'house_lon':y_test_new[:, 1],\n",
    "                            'house_lat (pred)': y_pred_new[:,0], 'house_lon (pred)': y_pred_new[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896.4017806636928"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score to beat: 836.4854723538451\n",
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.scatter(y_test_new[:, 0], y_test_new[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred_new[:, 0], y_pred_new[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "'''\n",
    "Standard model:\n",
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "def create_model():\n",
    "    # create model\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "    # Compile model\n",
    "    regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-16c1334d8b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# # Applying Kernel PCA\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(kernel = 'rbf')\n",
    "# X_original_pca = kpca.fit_transform(x_original)\n",
    "# X_original_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification approach\n",
    "# # x - same X except using W_Zone but no X_lat and X_lon, also eliminate non-independent variables\n",
    "# # y - H_Zone\n",
    "# x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cat = np.delete(X, 6, axis = 1)\n",
    "# x_cat = np.delete(X, 7, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat = data.loc[:, [\"H_ZONE\"]]\n",
    "# Y_cat.head()\n",
    "# Y_cat = Y_cat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# binarizer = LabelBinarizer()\n",
    "# Y_cat = binarizer.fit_transform(Y_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_cat, Y_cat, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialising the ANN\n",
    "# classifier = Sequential()\n",
    "\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1596))\n",
    "# classifier.add(Dropout(0.1))\n",
    "# # Adding the second hidden layer\n",
    "# classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(units = 1278, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# # Compiling the ANN\n",
    "# classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting the ANN to the Training set\n",
    "# classifier.fit(X_train, y_train, batch_size = 50, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
