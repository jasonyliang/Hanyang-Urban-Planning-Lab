{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/jhajhajhajha1/Desktop/Hanyang Data/data_playaround.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.iloc[:, 0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "      <th>H_ZONE</th>\n",
       "      <th>H_ZONE_X</th>\n",
       "      <th>H_ZONE_Y</th>\n",
       "      <th>W_ZONE_X</th>\n",
       "      <th>W_ZONE_Y</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.511534</td>\n",
       "      <td>126.902390</td>\n",
       "      <td>37.031954</td>\n",
       "      <td>127.077127</td>\n",
       "      <td>954.0</td>\n",
       "      <td>191000.0</td>\n",
       "      <td>445000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.000396</td>\n",
       "      <td>127.106922</td>\n",
       "      <td>37.034933</td>\n",
       "      <td>127.078710</td>\n",
       "      <td>50.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.195733</td>\n",
       "      <td>127.034267</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>287.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>411000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.067362</td>\n",
       "      <td>127.056343</td>\n",
       "      <td>37.037719</td>\n",
       "      <td>127.077653</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.151695</td>\n",
       "      <td>127.078077</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>218.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.053694</td>\n",
       "      <td>127.047655</td>\n",
       "      <td>37.038303</td>\n",
       "      <td>127.082699</td>\n",
       "      <td>105.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.102160</td>\n",
       "      <td>127.021462</td>\n",
       "      <td>37.036618</td>\n",
       "      <td>127.077674</td>\n",
       "      <td>173.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>401000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.037146</td>\n",
       "      <td>127.029241</td>\n",
       "      <td>37.035418</td>\n",
       "      <td>127.074294</td>\n",
       "      <td>86.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.076516</td>\n",
       "      <td>127.064009</td>\n",
       "      <td>37.036774</td>\n",
       "      <td>127.072348</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.989866</td>\n",
       "      <td>127.090719</td>\n",
       "      <td>37.037373</td>\n",
       "      <td>127.088846</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  \\\n",
       "1000      88    4.0         3.0      1.0        5.0     1.0  40.0  1.0   \n",
       "1001      88    3.0         3.0      4.0        2.0     2.0  61.0  1.0   \n",
       "1002      88    5.0         3.0      1.0        4.0     1.0  46.0  1.0   \n",
       "1003      88    4.0         4.0      2.0        6.0     1.0  49.0  1.0   \n",
       "1004      88    4.0         2.0      1.0        3.0     1.0  37.0  1.0   \n",
       "1005      88    3.0         3.0      1.0        5.0     1.0  56.0  1.0   \n",
       "1006      88    3.0         3.0      4.0        6.0     1.0  55.0  1.0   \n",
       "1007      88    4.0         4.0      2.0        5.0     1.0  41.0  1.0   \n",
       "1008      88    1.0         1.0      2.0        4.0     1.0  49.0  1.0   \n",
       "1009      88    3.0         3.0      1.0        5.0     1.0  43.0  1.0   \n",
       "\n",
       "      job_type  house_lat   house_lon   work_lat    work_lon  H_ZONE  \\\n",
       "1000       4.0  37.511534  126.902390  37.031954  127.077127   954.0   \n",
       "1001       6.0  37.000396  127.106922  37.034933  127.078710    50.0   \n",
       "1002       4.0  37.195733  127.034267  37.039019  127.077925   287.0   \n",
       "1003       6.0  37.067362  127.056343  37.037719  127.077653   130.0   \n",
       "1004       4.0  37.151695  127.078077  37.039019  127.077925   218.0   \n",
       "1005       6.0  37.053694  127.047655  37.038303  127.082699   105.0   \n",
       "1006       6.0  37.102160  127.021462  37.036618  127.077674   173.0   \n",
       "1007       6.0  37.037146  127.029241  37.035418  127.074294    86.0   \n",
       "1008       6.0  37.076516  127.064009  37.036774  127.072348   130.0   \n",
       "1009       6.0  36.989866  127.090719  37.037373  127.088846    35.0   \n",
       "\n",
       "      H_ZONE_X  H_ZONE_Y  W_ZONE_X  W_ZONE_Y             0  \n",
       "1000  191000.0  445000.0  207000.0  393000.0  25940.567472  \n",
       "1001  209000.0  389000.0  207000.0  393000.0  25940.567472  \n",
       "1002  203000.0  411000.0  207000.0  393000.0  25940.567472  \n",
       "1003  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1004  207000.0  405000.0  207000.0  393000.0  25940.567472  \n",
       "1005  205000.0  395000.0  207000.0  393000.0  25940.567472  \n",
       "1006  201000.0  401000.0  207000.0  393000.0  25940.567472  \n",
       "1007  203000.0  393000.0  207000.0  393000.0  25940.567472  \n",
       "1008  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1009  209000.0  387000.0  207000.0  393000.0  25940.567472  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.115620</td>\n",
       "      <td>126.792747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.335447</td>\n",
       "      <td>126.677584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.975082</td>\n",
       "      <td>127.436894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.847868</td>\n",
       "      <td>127.414170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.967527</td>\n",
       "      <td>124.717824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  job_type  \\\n",
       "0       0    4.0         4.0      1.0        5.0     1.0  41.0  1.0       4.0   \n",
       "1       0    3.0         3.0      2.0        3.0     1.0  36.0  1.0       4.0   \n",
       "2       0    3.0         3.0      2.0        2.0     1.0  70.0  1.0       9.0   \n",
       "3       0    5.0         4.0      1.0        5.0     1.0  32.0  1.0       4.0   \n",
       "4       0    2.0         2.0      4.0        3.0     1.0  55.0  1.0       4.0   \n",
       "\n",
       "    work_lat    work_lon  \n",
       "0  36.115620  126.792747  \n",
       "1  37.335447  126.677584  \n",
       "2  36.975082  127.436894  \n",
       "3  36.847868  127.414170  \n",
       "4  37.967527  124.717824  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# not calculating distance, simply using latitude\n",
    "x = data.iloc[:, 0:13]\n",
    "x = x.drop([\"house_lat\", \"house_lon\"], axis= 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W_ZONE          0\n",
       "no_hh         180\n",
       "no_hh_chil    180\n",
       "hh_type       180\n",
       "hh_income     180\n",
       "no_car        180\n",
       "age           180\n",
       "sex           180\n",
       "job_type      180\n",
       "work_lat      180\n",
       "work_lon      180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(x.iloc[:, 1:10])\n",
    "# x.iloc[:, 1:10] = imputer.transform(x.iloc[:, 1:10])\n",
    "x = x.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1326</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15391</td>\n",
       "      <td>15422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>732</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3594</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>648</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3210</td>\n",
       "      <td>3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1120</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6152</td>\n",
       "      <td>6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>246</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>567</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car  age  sex  \\\n",
       "hh_type                                                                    \n",
       "1.0        1326      8           8        1          8       2   66    2   \n",
       "2.0         732      7           7        1          8       2   62    2   \n",
       "3.0         648      6           6        1          8       2   58    2   \n",
       "4.0        1120      7           6        1          8       2   60    2   \n",
       "5.0         246      6           5        1          7       2   50    2   \n",
       "6.0          93      6           5        1          6       2   47    2   \n",
       "\n",
       "         job_type  work_lat  work_lon  \n",
       "hh_type                                \n",
       "1.0             9     15391     15422  \n",
       "2.0             8      3594      3605  \n",
       "3.0             9      3210      3214  \n",
       "4.0             7      6152      6173  \n",
       "5.0             7       567       566  \n",
       "6.0             6       123       123  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()\n",
    "x.groupby('hh_type').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original data\n",
    "x_original = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category values: hh_type, hh_income (this one is fine because of the levels)\n",
    "# Encoding categorical data\n",
    "# encode variable: hh_type, sex, job_type, W_Zone\n",
    "\n",
    "# make X a numpy array of x\n",
    "X_W = x.iloc[:, 0]\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# W_Zone\n",
    "labelencoder_X_W = LabelEncoder()\n",
    "X_W = labelencoder_X_W.fit_transform(X_W)\n",
    "onehotencoder_X_W = OneHotEncoder(categorical_features = [0])\n",
    "X_W = onehotencoder_X_W.fit_transform(X_W.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_W = X_W[:, 1:]\n",
    "# print(len(X_W[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_type\n",
    "X_hh = x.iloc[:, 3]\n",
    "labelencoder_X_hh = LabelEncoder()\n",
    "X_hh = labelencoder_X_hh.fit_transform(X_hh)\n",
    "onehotencoder_hh = OneHotEncoder(categorical_features = [0])\n",
    "X_hh = onehotencoder_hh.fit_transform(X_hh.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_hh = X_hh[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_type\n",
    "X_job = x.iloc[:, 8]\n",
    "labelencoder_X_job = LabelEncoder()\n",
    "X_job = labelencoder_X_job.fit_transform(X_job)\n",
    "onehotencoder_X_job = OneHotEncoder(categorical_features = [0])\n",
    "X_job = onehotencoder_X_job.fit_transform(X_job.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_job = X_job[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the variables: \n",
    "X = x.values\n",
    "# for i, x1 in enumerate(X[0]):\n",
    "#     print(\"column %s\" %i, x1)\n",
    "# take out the three columns\n",
    "X = np.delete(X, 0, axis = 1)\n",
    "X = np.delete(X, 2, axis = 1)\n",
    "X = np.delete(X, 6, axis = 1)\n",
    "X = np.append(X, X_W, axis = 1)\n",
    "X = np.append(X, X_hh, axis = 1)\n",
    "X = np.append(X, X_job, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummary:\\ncolumn 0: no_hh\\ncolumn 1: no_hh_chil\\ncolumn 2: hh_income\\ncolumn 3: no_car\\ncolumn 4: age\\ncolumn 5: sex\\ncolumn 6: work_lat\\ncolumn 7: work_lon\\ncolumn 8~1570: W_ZONE\\ncolumn 1571~1575: hh_type\\ncolumn 1576~1584: job_type\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Summary:\n",
    "column 0: no_hh\n",
    "column 1: no_hh_chil\n",
    "column 2: hh_income\n",
    "column 3: no_car\n",
    "column 4: age\n",
    "column 5: sex\n",
    "column 6: work_lat\n",
    "column 7: work_lon\n",
    "column 8~1570: W_ZONE\n",
    "column 1571~1575: hh_type\n",
    "column 1576~1584: job_type\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher Dimensions\n",
    "# higher dimensions for continuous variables: hh_income, age, no_car, no_hh\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# no_hh\n",
    "X_no_hh = X[:, 0]\n",
    "poly_reg_no_hh = PolynomialFeatures(degree = 4)\n",
    "X_no_hh = poly_reg_no_hh.fit_transform(X_no_hh.reshape(-1, 1))\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_hh, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1585~1587: poly no_hh\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "column 1585~1587: poly no_hh\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_income\n",
    "X_hh_income = X[:, 2]\n",
    "poly_reg_hh_income = PolynomialFeatures(degree = 4)\n",
    "X_hh_income = poly_reg_hh_income.fit_transform(X_hh_income.reshape(-1, 1))\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_hh_income, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1588~1590: poly hh_income\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1588~1590: poly hh_income\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "X_age = X[:, 4]\n",
    "poly_reg_age = PolynomialFeatures(degree = 4)\n",
    "X_age = poly_reg_age.fit_transform(X_age.reshape(-1, 1))\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_age, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1591~1593: poly X_age\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1591~1593: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_car\n",
    "X_no_car = X[:, 3]\n",
    "poly_reg_car = PolynomialFeatures(degree = 4)\n",
    "X_no_car = poly_reg_car.fit_transform(X_no_car.reshape(-1, 1))\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_car, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1594~1596: poly X_age\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1594~1596: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.453952</td>\n",
       "      <td>126.716877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.465845</td>\n",
       "      <td>126.717234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.229621</td>\n",
       "      <td>127.284122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.623500</td>\n",
       "      <td>127.083187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.469676</td>\n",
       "      <td>126.644354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_lat   house_lon\n",
       "0  37.453952  126.716877\n",
       "1  37.465845  126.717234\n",
       "2  37.229621  127.284122\n",
       "3  37.623500  127.083187\n",
       "4  37.469676  126.644354"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:, [\"house_lat\", \"house_lon\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_lat    180\n",
       "house_lon    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(y)\n",
    "# y = imputer.transform(y)\n",
    "y = y.dropna()\n",
    "Y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set (original dataset for random forest and SVM)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_original, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Standardization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# Normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "# Fitting the Random Forest Regression Model to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy based on distance\n",
    "def accuracy(pred):\n",
    "    sum_error = 0\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        sum_error += error\n",
    "    return sum_error\n",
    "\n",
    "def ind_diff(pred):\n",
    "    diff = []\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        diff.append(error)\n",
    "    return pd.DataFrame({'Difference': diff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836.4854723538451"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "Svr = SVR(kernel = 'rbf')\n",
    "regressor = MultiOutputRegressor(Svr)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910.4894551538027"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Difference\n",
       "0    0.136940\n",
       "1    0.100117\n",
       "2    0.046069\n",
       "3    0.328629\n",
       "4    0.223993"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                51136     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 57,538\n",
      "Trainable params: 57,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_standardized = np.zeros((len(Y), 2))\n",
    "Y_standardized[:,0] = (Y[:,0] - np.mean(Y[:,0]))/ np.std(Y[:,0])\n",
    "Y_standardized[:,1] = (Y[:,1] - np.mean(Y[:,1]))/ np.std(Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed dataset with dummy variables and polynomials as well as standardized outcomes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_standardized, test_size = 0.2, random_state = 0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "37342/37342 [==============================] - 2s 47us/step - loss: 0.9983 - mean_absolute_error: 0.7605\n",
      "Epoch 2/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.9982 - mean_absolute_error: 0.7605\n",
      "Epoch 3/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.9981 - mean_absolute_error: 0.7606\n",
      "Epoch 4/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.9980 - mean_absolute_error: 0.7603\n",
      "Epoch 5/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.9974 - mean_absolute_error: 0.7603\n",
      "Epoch 6/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.9800 - mean_absolute_error: 0.7527\n",
      "Epoch 7/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.8697 - mean_absolute_error: 0.7002\n",
      "Epoch 8/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.7107 - mean_absolute_error: 0.6334\n",
      "Epoch 9/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.5213 - mean_absolute_error: 0.5364\n",
      "Epoch 10/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.4294 - mean_absolute_error: 0.4811\n",
      "Epoch 11/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.3860 - mean_absolute_error: 0.4511\n",
      "Epoch 12/250\n",
      "37342/37342 [==============================] - 2s 44us/step - loss: 0.3588 - mean_absolute_error: 0.4337\n",
      "Epoch 13/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.3452 - mean_absolute_error: 0.4223\n",
      "Epoch 14/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.3373 - mean_absolute_error: 0.4172\n",
      "Epoch 15/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.3293 - mean_absolute_error: 0.4111\n",
      "Epoch 16/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.3211 - mean_absolute_error: 0.4054\n",
      "Epoch 17/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.3188 - mean_absolute_error: 0.4027\n",
      "Epoch 18/250\n",
      "37342/37342 [==============================] - 2s 46us/step - loss: 0.3116 - mean_absolute_error: 0.3978\n",
      "Epoch 19/250\n",
      "37342/37342 [==============================] - 2s 51us/step - loss: 0.3083 - mean_absolute_error: 0.3957\n",
      "Epoch 20/250\n",
      "37342/37342 [==============================] - 2s 46us/step - loss: 0.3084 - mean_absolute_error: 0.3954\n",
      "Epoch 21/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.3025 - mean_absolute_error: 0.3913\n",
      "Epoch 22/250\n",
      "37342/37342 [==============================] - 2s 52us/step - loss: 0.3004 - mean_absolute_error: 0.3913\n",
      "Epoch 23/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2985 - mean_absolute_error: 0.3886\n",
      "Epoch 24/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2978 - mean_absolute_error: 0.3870\n",
      "Epoch 25/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2961 - mean_absolute_error: 0.3864\n",
      "Epoch 26/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2923 - mean_absolute_error: 0.3839\n",
      "Epoch 27/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2898 - mean_absolute_error: 0.3823\n",
      "Epoch 28/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2877 - mean_absolute_error: 0.3811\n",
      "Epoch 29/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2877 - mean_absolute_error: 0.3801\n",
      "Epoch 30/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2859 - mean_absolute_error: 0.3792\n",
      "Epoch 31/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2848 - mean_absolute_error: 0.3781\n",
      "Epoch 32/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2829 - mean_absolute_error: 0.3770\n",
      "Epoch 33/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2841 - mean_absolute_error: 0.3772\n",
      "Epoch 34/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2820 - mean_absolute_error: 0.3763\n",
      "Epoch 35/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2804 - mean_absolute_error: 0.3760\n",
      "Epoch 36/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2800 - mean_absolute_error: 0.3750\n",
      "Epoch 37/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2780 - mean_absolute_error: 0.3743\n",
      "Epoch 38/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2768 - mean_absolute_error: 0.3732\n",
      "Epoch 39/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2766 - mean_absolute_error: 0.3729\n",
      "Epoch 40/250\n",
      "37342/37342 [==============================] - 2s 48us/step - loss: 0.2757 - mean_absolute_error: 0.3720\n",
      "Epoch 41/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2745 - mean_absolute_error: 0.3698\n",
      "Epoch 42/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2747 - mean_absolute_error: 0.3711\n",
      "Epoch 43/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2717 - mean_absolute_error: 0.3689\n",
      "Epoch 44/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2721 - mean_absolute_error: 0.3693\n",
      "Epoch 45/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2733 - mean_absolute_error: 0.3704\n",
      "Epoch 46/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2727 - mean_absolute_error: 0.3695\n",
      "Epoch 47/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2711 - mean_absolute_error: 0.3686\n",
      "Epoch 48/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2702 - mean_absolute_error: 0.3674\n",
      "Epoch 49/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2714 - mean_absolute_error: 0.3687\n",
      "Epoch 50/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2697 - mean_absolute_error: 0.3667\n",
      "Epoch 51/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2690 - mean_absolute_error: 0.3663\n",
      "Epoch 52/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2664 - mean_absolute_error: 0.3658\n",
      "Epoch 53/250\n",
      "37342/37342 [==============================] - 2s 47us/step - loss: 0.2687 - mean_absolute_error: 0.3668\n",
      "Epoch 54/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2680 - mean_absolute_error: 0.3664\n",
      "Epoch 55/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2673 - mean_absolute_error: 0.3661\n",
      "Epoch 56/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2657 - mean_absolute_error: 0.3646\n",
      "Epoch 57/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2652 - mean_absolute_error: 0.3641\n",
      "Epoch 58/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2645 - mean_absolute_error: 0.3636\n",
      "Epoch 59/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2638 - mean_absolute_error: 0.3636\n",
      "Epoch 60/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2646 - mean_absolute_error: 0.3637\n",
      "Epoch 61/250\n",
      "37342/37342 [==============================] - 2s 49us/step - loss: 0.2639 - mean_absolute_error: 0.3633\n",
      "Epoch 62/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2641 - mean_absolute_error: 0.3636\n",
      "Epoch 63/250\n",
      "37342/37342 [==============================] - 2s 48us/step - loss: 0.2632 - mean_absolute_error: 0.3625\n",
      "Epoch 64/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2635 - mean_absolute_error: 0.3628\n",
      "Epoch 65/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2641 - mean_absolute_error: 0.3629\n",
      "Epoch 66/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2620 - mean_absolute_error: 0.3620\n",
      "Epoch 67/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2623 - mean_absolute_error: 0.3622\n",
      "Epoch 68/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2620 - mean_absolute_error: 0.3614\n",
      "Epoch 69/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2605 - mean_absolute_error: 0.3604\n",
      "Epoch 70/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2612 - mean_absolute_error: 0.3609\n",
      "Epoch 71/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2613 - mean_absolute_error: 0.3611\n",
      "Epoch 72/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2611 - mean_absolute_error: 0.3607\n",
      "Epoch 73/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2595 - mean_absolute_error: 0.3605\n",
      "Epoch 74/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2597 - mean_absolute_error: 0.3598\n",
      "Epoch 75/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2592 - mean_absolute_error: 0.3599\n",
      "Epoch 76/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2586 - mean_absolute_error: 0.3596\n",
      "Epoch 77/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2571 - mean_absolute_error: 0.3578\n",
      "Epoch 78/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2573 - mean_absolute_error: 0.3586\n",
      "Epoch 79/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2582 - mean_absolute_error: 0.3585\n",
      "Epoch 80/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2579 - mean_absolute_error: 0.3589\n",
      "Epoch 81/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2591 - mean_absolute_error: 0.3590\n",
      "Epoch 82/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2576 - mean_absolute_error: 0.3578\n",
      "Epoch 83/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2558 - mean_absolute_error: 0.3577\n",
      "Epoch 84/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2575 - mean_absolute_error: 0.3586\n",
      "Epoch 85/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2567 - mean_absolute_error: 0.3578\n",
      "Epoch 86/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2555 - mean_absolute_error: 0.3568\n",
      "Epoch 87/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2566 - mean_absolute_error: 0.3580\n",
      "Epoch 88/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2569 - mean_absolute_error: 0.3584\n",
      "Epoch 89/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2557 - mean_absolute_error: 0.3567\n",
      "Epoch 90/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2545 - mean_absolute_error: 0.3564\n",
      "Epoch 91/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2551 - mean_absolute_error: 0.3566\n",
      "Epoch 92/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2544 - mean_absolute_error: 0.3555\n",
      "Epoch 93/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2556 - mean_absolute_error: 0.3564\n",
      "Epoch 94/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2551 - mean_absolute_error: 0.3567\n",
      "Epoch 95/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2533 - mean_absolute_error: 0.3554\n",
      "Epoch 96/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2545 - mean_absolute_error: 0.3559\n",
      "Epoch 97/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2540 - mean_absolute_error: 0.3561\n",
      "Epoch 98/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2539 - mean_absolute_error: 0.3556\n",
      "Epoch 99/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2548 - mean_absolute_error: 0.3560\n",
      "Epoch 100/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2517 - mean_absolute_error: 0.3543\n",
      "Epoch 101/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2520 - mean_absolute_error: 0.3556\n",
      "Epoch 102/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2526 - mean_absolute_error: 0.3554\n",
      "Epoch 103/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2523 - mean_absolute_error: 0.3547\n",
      "Epoch 104/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2512 - mean_absolute_error: 0.3543\n",
      "Epoch 105/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2516 - mean_absolute_error: 0.3542\n",
      "Epoch 106/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2530 - mean_absolute_error: 0.3554\n",
      "Epoch 107/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2519 - mean_absolute_error: 0.3542\n",
      "Epoch 108/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2493 - mean_absolute_error: 0.3522\n",
      "Epoch 109/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2531 - mean_absolute_error: 0.3544\n",
      "Epoch 110/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2514 - mean_absolute_error: 0.3543\n",
      "Epoch 111/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2515 - mean_absolute_error: 0.3533\n",
      "Epoch 112/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2510 - mean_absolute_error: 0.3534\n",
      "Epoch 113/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2512 - mean_absolute_error: 0.3530\n",
      "Epoch 114/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2489 - mean_absolute_error: 0.3523\n",
      "Epoch 115/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2503 - mean_absolute_error: 0.3529\n",
      "Epoch 116/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2493 - mean_absolute_error: 0.3525\n",
      "Epoch 117/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2495 - mean_absolute_error: 0.3519\n",
      "Epoch 118/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2499 - mean_absolute_error: 0.3524\n",
      "Epoch 119/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2502 - mean_absolute_error: 0.3524\n",
      "Epoch 120/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2483 - mean_absolute_error: 0.3510\n",
      "Epoch 121/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2490 - mean_absolute_error: 0.3516\n",
      "Epoch 122/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2480 - mean_absolute_error: 0.3518\n",
      "Epoch 123/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2489 - mean_absolute_error: 0.3525\n",
      "Epoch 124/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2489 - mean_absolute_error: 0.3518\n",
      "Epoch 125/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2489 - mean_absolute_error: 0.3517\n",
      "Epoch 126/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2485 - mean_absolute_error: 0.3508\n",
      "Epoch 127/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2477 - mean_absolute_error: 0.3516\n",
      "Epoch 128/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2456 - mean_absolute_error: 0.3491\n",
      "Epoch 129/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2476 - mean_absolute_error: 0.3505\n",
      "Epoch 130/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2472 - mean_absolute_error: 0.3507\n",
      "Epoch 131/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2482 - mean_absolute_error: 0.3507\n",
      "Epoch 132/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2470 - mean_absolute_error: 0.3504\n",
      "Epoch 133/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2465 - mean_absolute_error: 0.3503\n",
      "Epoch 134/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2466 - mean_absolute_error: 0.3502\n",
      "Epoch 135/250\n",
      "37342/37342 [==============================] - 2s 48us/step - loss: 0.2461 - mean_absolute_error: 0.3493\n",
      "Epoch 136/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2474 - mean_absolute_error: 0.3506\n",
      "Epoch 137/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2466 - mean_absolute_error: 0.3501\n",
      "Epoch 138/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2446 - mean_absolute_error: 0.3490\n",
      "Epoch 139/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2457 - mean_absolute_error: 0.3486\n",
      "Epoch 140/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2469 - mean_absolute_error: 0.3498\n",
      "Epoch 141/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2452 - mean_absolute_error: 0.3496\n",
      "Epoch 142/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2468 - mean_absolute_error: 0.3497\n",
      "Epoch 143/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2444 - mean_absolute_error: 0.3480\n",
      "Epoch 144/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2444 - mean_absolute_error: 0.3484\n",
      "Epoch 145/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2446 - mean_absolute_error: 0.3487\n",
      "Epoch 146/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2470 - mean_absolute_error: 0.3498\n",
      "Epoch 147/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2451 - mean_absolute_error: 0.3489\n",
      "Epoch 148/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2446 - mean_absolute_error: 0.3482\n",
      "Epoch 149/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2446 - mean_absolute_error: 0.3481\n",
      "Epoch 150/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2441 - mean_absolute_error: 0.3489\n",
      "Epoch 151/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2446 - mean_absolute_error: 0.3490\n",
      "Epoch 152/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2456 - mean_absolute_error: 0.3494\n",
      "Epoch 153/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2466 - mean_absolute_error: 0.3491\n",
      "Epoch 154/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2437 - mean_absolute_error: 0.3473\n",
      "Epoch 155/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2421 - mean_absolute_error: 0.3467\n",
      "Epoch 156/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2433 - mean_absolute_error: 0.3473\n",
      "Epoch 157/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2430 - mean_absolute_error: 0.3475\n",
      "Epoch 158/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2437 - mean_absolute_error: 0.3478\n",
      "Epoch 159/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2451 - mean_absolute_error: 0.3493\n",
      "Epoch 160/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2447 - mean_absolute_error: 0.3485\n",
      "Epoch 161/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2433 - mean_absolute_error: 0.3474\n",
      "Epoch 162/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2441 - mean_absolute_error: 0.3475\n",
      "Epoch 163/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2433 - mean_absolute_error: 0.3478\n",
      "Epoch 164/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2433 - mean_absolute_error: 0.3469\n",
      "Epoch 165/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2419 - mean_absolute_error: 0.3469\n",
      "Epoch 166/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2419 - mean_absolute_error: 0.3467\n",
      "Epoch 167/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2427 - mean_absolute_error: 0.3470\n",
      "Epoch 168/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2446 - mean_absolute_error: 0.3481\n",
      "Epoch 169/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2430 - mean_absolute_error: 0.3473\n",
      "Epoch 170/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2426 - mean_absolute_error: 0.3470\n",
      "Epoch 171/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2417 - mean_absolute_error: 0.3468\n",
      "Epoch 172/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2438 - mean_absolute_error: 0.3474\n",
      "Epoch 173/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2409 - mean_absolute_error: 0.3464\n",
      "Epoch 174/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2416 - mean_absolute_error: 0.3460\n",
      "Epoch 175/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2422 - mean_absolute_error: 0.3466\n",
      "Epoch 176/250\n",
      "37342/37342 [==============================] - 2s 45us/step - loss: 0.2413 - mean_absolute_error: 0.3458\n",
      "Epoch 177/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2416 - mean_absolute_error: 0.3464\n",
      "Epoch 178/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2416 - mean_absolute_error: 0.3462\n",
      "Epoch 179/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2408 - mean_absolute_error: 0.3456\n",
      "Epoch 180/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2429 - mean_absolute_error: 0.3474\n",
      "Epoch 181/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2415 - mean_absolute_error: 0.3453\n",
      "Epoch 182/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2413 - mean_absolute_error: 0.3462\n",
      "Epoch 183/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2426 - mean_absolute_error: 0.3458\n",
      "Epoch 184/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2398 - mean_absolute_error: 0.3453\n",
      "Epoch 185/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2403 - mean_absolute_error: 0.3457\n",
      "Epoch 186/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2394 - mean_absolute_error: 0.3445\n",
      "Epoch 187/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2403 - mean_absolute_error: 0.3455\n",
      "Epoch 188/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2408 - mean_absolute_error: 0.3457\n",
      "Epoch 189/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2406 - mean_absolute_error: 0.3452\n",
      "Epoch 190/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2415 - mean_absolute_error: 0.3461\n",
      "Epoch 191/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2404 - mean_absolute_error: 0.3454\n",
      "Epoch 192/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2418 - mean_absolute_error: 0.3460\n",
      "Epoch 193/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2395 - mean_absolute_error: 0.3444\n",
      "Epoch 194/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2401 - mean_absolute_error: 0.3458\n",
      "Epoch 195/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2406 - mean_absolute_error: 0.3455\n",
      "Epoch 196/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2382 - mean_absolute_error: 0.3450\n",
      "Epoch 197/250\n",
      "37342/37342 [==============================] - 2s 42us/step - loss: 0.2407 - mean_absolute_error: 0.3455\n",
      "Epoch 198/250\n",
      "37342/37342 [==============================] - 2s 52us/step - loss: 0.2400 - mean_absolute_error: 0.3451\n",
      "Epoch 199/250\n",
      "37342/37342 [==============================] - 2s 46us/step - loss: 0.2379 - mean_absolute_error: 0.3435\n",
      "Epoch 200/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2395 - mean_absolute_error: 0.3441\n",
      "Epoch 201/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2408 - mean_absolute_error: 0.3455\n",
      "Epoch 202/250\n",
      "37342/37342 [==============================] - 1s 40us/step - loss: 0.2397 - mean_absolute_error: 0.3451\n",
      "Epoch 203/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2392 - mean_absolute_error: 0.3450\n",
      "Epoch 204/250\n",
      "37342/37342 [==============================] - 2s 41us/step - loss: 0.2396 - mean_absolute_error: 0.3443\n",
      "Epoch 205/250\n",
      "37342/37342 [==============================] - 2s 43us/step - loss: 0.2387 - mean_absolute_error: 0.3446\n",
      "Epoch 206/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2388 - mean_absolute_error: 0.3439\n",
      "Epoch 207/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2398 - mean_absolute_error: 0.3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2386 - mean_absolute_error: 0.3437\n",
      "Epoch 209/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2382 - mean_absolute_error: 0.3439\n",
      "Epoch 210/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2381 - mean_absolute_error: 0.3437\n",
      "Epoch 211/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2373 - mean_absolute_error: 0.3425\n",
      "Epoch 212/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2395 - mean_absolute_error: 0.3439\n",
      "Epoch 213/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2380 - mean_absolute_error: 0.3434\n",
      "Epoch 214/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2391 - mean_absolute_error: 0.3445\n",
      "Epoch 215/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2387 - mean_absolute_error: 0.3442\n",
      "Epoch 216/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2381 - mean_absolute_error: 0.3438\n",
      "Epoch 217/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2386 - mean_absolute_error: 0.3440\n",
      "Epoch 218/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2380 - mean_absolute_error: 0.3438\n",
      "Epoch 219/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2389 - mean_absolute_error: 0.3439\n",
      "Epoch 220/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2365 - mean_absolute_error: 0.3427\n",
      "Epoch 221/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2391 - mean_absolute_error: 0.3436\n",
      "Epoch 222/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2375 - mean_absolute_error: 0.3431\n",
      "Epoch 223/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2378 - mean_absolute_error: 0.3443\n",
      "Epoch 224/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2372 - mean_absolute_error: 0.3429\n",
      "Epoch 225/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2370 - mean_absolute_error: 0.3425\n",
      "Epoch 226/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2378 - mean_absolute_error: 0.3429\n",
      "Epoch 227/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2358 - mean_absolute_error: 0.3421\n",
      "Epoch 228/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2375 - mean_absolute_error: 0.3435\n",
      "Epoch 229/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2363 - mean_absolute_error: 0.3431\n",
      "Epoch 230/250\n",
      "37342/37342 [==============================] - 1s 31us/step - loss: 0.2370 - mean_absolute_error: 0.3429\n",
      "Epoch 231/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2362 - mean_absolute_error: 0.3418\n",
      "Epoch 232/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2367 - mean_absolute_error: 0.3420\n",
      "Epoch 233/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2380 - mean_absolute_error: 0.3438\n",
      "Epoch 234/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2363 - mean_absolute_error: 0.3423\n",
      "Epoch 235/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2368 - mean_absolute_error: 0.3420\n",
      "Epoch 236/250\n",
      "37342/37342 [==============================] - 2s 58us/step - loss: 0.2374 - mean_absolute_error: 0.3432\n",
      "Epoch 237/250\n",
      "37342/37342 [==============================] - 2s 44us/step - loss: 0.2369 - mean_absolute_error: 0.3424\n",
      "Epoch 238/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2361 - mean_absolute_error: 0.3422\n",
      "Epoch 239/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2367 - mean_absolute_error: 0.3416\n",
      "Epoch 240/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2360 - mean_absolute_error: 0.3428\n",
      "Epoch 241/250\n",
      "37342/37342 [==============================] - 1s 39us/step - loss: 0.2352 - mean_absolute_error: 0.3416\n",
      "Epoch 242/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2371 - mean_absolute_error: 0.3428\n",
      "Epoch 243/250\n",
      "37342/37342 [==============================] - 1s 37us/step - loss: 0.2360 - mean_absolute_error: 0.3415\n",
      "Epoch 244/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2357 - mean_absolute_error: 0.3420\n",
      "Epoch 245/250\n",
      "37342/37342 [==============================] - 1s 36us/step - loss: 0.2360 - mean_absolute_error: 0.3421\n",
      "Epoch 246/250\n",
      "37342/37342 [==============================] - 1s 38us/step - loss: 0.2356 - mean_absolute_error: 0.3422\n",
      "Epoch 247/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2358 - mean_absolute_error: 0.3412\n",
      "Epoch 248/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2367 - mean_absolute_error: 0.3424\n",
      "Epoch 249/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2352 - mean_absolute_error: 0.3412\n",
      "Epoch 250/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2358 - mean_absolute_error: 0.3415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1368ddc88>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size = 64, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37.43051147, 127.4728241 ],\n",
       "       [ 37.5795784 , 127.05845642],\n",
       "       [ 37.49308395, 127.0332489 ],\n",
       "       ...,\n",
       "       [ 37.54063034, 126.96340179],\n",
       "       [ 37.55025864, 126.96472168],\n",
       "       [ 37.37802887, 126.76939392]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new = np.zeros((len(y_pred), 2))\n",
    "y_test_new = np.zeros((len(y_test), 2))\n",
    "y_pred_new[:,0] = y_pred[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_pred_new[:,1] = y_pred[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "\n",
    "y_test_new[:,0] = y_test[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_test_new[:,1] = y_test[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "y_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 1597)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test_new[:, 0],'house_lon':y_test_new[:, 1],\n",
    "                            'house_lat (pred)': y_pred_new[:,0], 'house_lon (pred)': y_pred_new[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09474973330596216"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score to beat: 836.4854723538451\n",
    "accuracy(prediction)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.scatter(y_test_new[:, 0], y_test_new[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred_new[:, 0], y_pred_new[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "'''\n",
    "Standard model:\n",
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "def create_model():\n",
    "    # create model\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "    # Compile model\n",
    "    regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-16c1334d8b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# # Applying Kernel PCA\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(kernel = 'rbf')\n",
    "# X_original_pca = kpca.fit_transform(x_original)\n",
    "# X_original_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification approach\n",
    "# # x - same X except using W_Zone but no X_lat and X_lon, also eliminate non-independent variables\n",
    "# # y - H_Zone\n",
    "# x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cat = np.delete(X, 6, axis = 1)\n",
    "# x_cat = np.delete(X, 7, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat = data.loc[:, [\"H_ZONE\"]]\n",
    "# Y_cat.head()\n",
    "# Y_cat = Y_cat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# binarizer = LabelBinarizer()\n",
    "# Y_cat = binarizer.fit_transform(Y_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_cat, Y_cat, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialising the ANN\n",
    "# classifier = Sequential()\n",
    "\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1596))\n",
    "# classifier.add(Dropout(0.1))\n",
    "# # Adding the second hidden layer\n",
    "# classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(units = 1278, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# # Compiling the ANN\n",
    "# classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting the ANN to the Training set\n",
    "# classifier.fit(X_train, y_train, batch_size = 50, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
