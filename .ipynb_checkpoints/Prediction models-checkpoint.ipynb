{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/jhajhajhajha1/Desktop/Hanyang Data/data_playaround.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.iloc[:, 0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "      <th>H_ZONE</th>\n",
       "      <th>H_ZONE_X</th>\n",
       "      <th>H_ZONE_Y</th>\n",
       "      <th>W_ZONE_X</th>\n",
       "      <th>W_ZONE_Y</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.511534</td>\n",
       "      <td>126.902390</td>\n",
       "      <td>37.031954</td>\n",
       "      <td>127.077127</td>\n",
       "      <td>954.0</td>\n",
       "      <td>191000.0</td>\n",
       "      <td>445000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.000396</td>\n",
       "      <td>127.106922</td>\n",
       "      <td>37.034933</td>\n",
       "      <td>127.078710</td>\n",
       "      <td>50.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.195733</td>\n",
       "      <td>127.034267</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>287.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>411000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.067362</td>\n",
       "      <td>127.056343</td>\n",
       "      <td>37.037719</td>\n",
       "      <td>127.077653</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.151695</td>\n",
       "      <td>127.078077</td>\n",
       "      <td>37.039019</td>\n",
       "      <td>127.077925</td>\n",
       "      <td>218.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.053694</td>\n",
       "      <td>127.047655</td>\n",
       "      <td>37.038303</td>\n",
       "      <td>127.082699</td>\n",
       "      <td>105.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.102160</td>\n",
       "      <td>127.021462</td>\n",
       "      <td>37.036618</td>\n",
       "      <td>127.077674</td>\n",
       "      <td>173.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>401000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.037146</td>\n",
       "      <td>127.029241</td>\n",
       "      <td>37.035418</td>\n",
       "      <td>127.074294</td>\n",
       "      <td>86.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.076516</td>\n",
       "      <td>127.064009</td>\n",
       "      <td>37.036774</td>\n",
       "      <td>127.072348</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>397000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.989866</td>\n",
       "      <td>127.090719</td>\n",
       "      <td>37.037373</td>\n",
       "      <td>127.088846</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>393000.0</td>\n",
       "      <td>25940.567472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  \\\n",
       "1000      88    4.0         3.0      1.0        5.0     1.0  40.0  1.0   \n",
       "1001      88    3.0         3.0      4.0        2.0     2.0  61.0  1.0   \n",
       "1002      88    5.0         3.0      1.0        4.0     1.0  46.0  1.0   \n",
       "1003      88    4.0         4.0      2.0        6.0     1.0  49.0  1.0   \n",
       "1004      88    4.0         2.0      1.0        3.0     1.0  37.0  1.0   \n",
       "1005      88    3.0         3.0      1.0        5.0     1.0  56.0  1.0   \n",
       "1006      88    3.0         3.0      4.0        6.0     1.0  55.0  1.0   \n",
       "1007      88    4.0         4.0      2.0        5.0     1.0  41.0  1.0   \n",
       "1008      88    1.0         1.0      2.0        4.0     1.0  49.0  1.0   \n",
       "1009      88    3.0         3.0      1.0        5.0     1.0  43.0  1.0   \n",
       "\n",
       "      job_type  house_lat   house_lon   work_lat    work_lon  H_ZONE  \\\n",
       "1000       4.0  37.511534  126.902390  37.031954  127.077127   954.0   \n",
       "1001       6.0  37.000396  127.106922  37.034933  127.078710    50.0   \n",
       "1002       4.0  37.195733  127.034267  37.039019  127.077925   287.0   \n",
       "1003       6.0  37.067362  127.056343  37.037719  127.077653   130.0   \n",
       "1004       4.0  37.151695  127.078077  37.039019  127.077925   218.0   \n",
       "1005       6.0  37.053694  127.047655  37.038303  127.082699   105.0   \n",
       "1006       6.0  37.102160  127.021462  37.036618  127.077674   173.0   \n",
       "1007       6.0  37.037146  127.029241  37.035418  127.074294    86.0   \n",
       "1008       6.0  37.076516  127.064009  37.036774  127.072348   130.0   \n",
       "1009       6.0  36.989866  127.090719  37.037373  127.088846    35.0   \n",
       "\n",
       "      H_ZONE_X  H_ZONE_Y  W_ZONE_X  W_ZONE_Y             0  \n",
       "1000  191000.0  445000.0  207000.0  393000.0  25940.567472  \n",
       "1001  209000.0  389000.0  207000.0  393000.0  25940.567472  \n",
       "1002  203000.0  411000.0  207000.0  393000.0  25940.567472  \n",
       "1003  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1004  207000.0  405000.0  207000.0  393000.0  25940.567472  \n",
       "1005  205000.0  395000.0  207000.0  393000.0  25940.567472  \n",
       "1006  201000.0  401000.0  207000.0  393000.0  25940.567472  \n",
       "1007  203000.0  393000.0  207000.0  393000.0  25940.567472  \n",
       "1008  205000.0  397000.0  207000.0  393000.0  25940.567472  \n",
       "1009  209000.0  387000.0  207000.0  393000.0  25940.567472  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.115620</td>\n",
       "      <td>126.792747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.335447</td>\n",
       "      <td>126.677584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.975082</td>\n",
       "      <td>127.436894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.847868</td>\n",
       "      <td>127.414170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.967527</td>\n",
       "      <td>124.717824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car   age  sex  job_type  \\\n",
       "0       0    4.0         4.0      1.0        5.0     1.0  41.0  1.0       4.0   \n",
       "1       0    3.0         3.0      2.0        3.0     1.0  36.0  1.0       4.0   \n",
       "2       0    3.0         3.0      2.0        2.0     1.0  70.0  1.0       9.0   \n",
       "3       0    5.0         4.0      1.0        5.0     1.0  32.0  1.0       4.0   \n",
       "4       0    2.0         2.0      4.0        3.0     1.0  55.0  1.0       4.0   \n",
       "\n",
       "    work_lat    work_lon  \n",
       "0  36.115620  126.792747  \n",
       "1  37.335447  126.677584  \n",
       "2  36.975082  127.436894  \n",
       "3  36.847868  127.414170  \n",
       "4  37.967527  124.717824  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# not calculating distance, simply using latitude\n",
    "x = data.iloc[:, 0:13]\n",
    "x = x.drop([\"house_lat\", \"house_lon\"], axis= 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W_ZONE          0\n",
       "no_hh         180\n",
       "no_hh_chil    180\n",
       "hh_type       180\n",
       "hh_income     180\n",
       "no_car        180\n",
       "age           180\n",
       "sex           180\n",
       "job_type      180\n",
       "work_lat      180\n",
       "work_lon      180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(x.iloc[:, 1:10])\n",
    "# x.iloc[:, 1:10] = imputer.transform(x.iloc[:, 1:10])\n",
    "x = x.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ZONE</th>\n",
       "      <th>no_hh</th>\n",
       "      <th>no_hh_chil</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>no_car</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_type</th>\n",
       "      <th>work_lat</th>\n",
       "      <th>work_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1326</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15391</td>\n",
       "      <td>15422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>732</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3594</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>648</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3210</td>\n",
       "      <td>3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1120</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6152</td>\n",
       "      <td>6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>246</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>567</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         W_ZONE  no_hh  no_hh_chil  hh_type  hh_income  no_car  age  sex  \\\n",
       "hh_type                                                                    \n",
       "1.0        1326      8           8        1          8       2   66    2   \n",
       "2.0         732      7           7        1          8       2   62    2   \n",
       "3.0         648      6           6        1          8       2   58    2   \n",
       "4.0        1120      7           6        1          8       2   60    2   \n",
       "5.0         246      6           5        1          7       2   50    2   \n",
       "6.0          93      6           5        1          6       2   47    2   \n",
       "\n",
       "         job_type  work_lat  work_lon  \n",
       "hh_type                                \n",
       "1.0             9     15391     15422  \n",
       "2.0             8      3594      3605  \n",
       "3.0             9      3210      3214  \n",
       "4.0             7      6152      6173  \n",
       "5.0             7       567       566  \n",
       "6.0             6       123       123  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()\n",
    "x.groupby('hh_type').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original data\n",
    "x_original = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category values: hh_type, hh_income (this one is fine because of the levels)\n",
    "# Encoding categorical data\n",
    "# encode variable: hh_type, sex, job_type, W_Zone\n",
    "\n",
    "# make X a numpy array of x\n",
    "X_W = x.iloc[:, 0]\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# W_Zone\n",
    "labelencoder_X_W = LabelEncoder()\n",
    "X_W = labelencoder_X_W.fit_transform(X_W)\n",
    "onehotencoder_X_W = OneHotEncoder(categorical_features = [0])\n",
    "X_W = onehotencoder_X_W.fit_transform(X_W.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_W = X_W[:, 1:]\n",
    "# print(len(X_W[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_type\n",
    "X_hh = x.iloc[:, 3]\n",
    "labelencoder_X_hh = LabelEncoder()\n",
    "X_hh = labelencoder_X_hh.fit_transform(X_hh)\n",
    "onehotencoder_hh = OneHotEncoder(categorical_features = [0])\n",
    "X_hh = onehotencoder_hh.fit_transform(X_hh.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_hh = X_hh[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_type\n",
    "X_job = x.iloc[:, 8]\n",
    "labelencoder_X_job = LabelEncoder()\n",
    "X_job = labelencoder_X_job.fit_transform(X_job)\n",
    "onehotencoder_X_job = OneHotEncoder(categorical_features = [0])\n",
    "X_job = onehotencoder_X_job.fit_transform(X_job.reshape(-1, 1)).toarray()\n",
    "# Dummy Variable trap\n",
    "X_job = X_job[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the variables: \n",
    "X = x.values\n",
    "# for i, x1 in enumerate(X[0]):\n",
    "#     print(\"column %s\" %i, x1)\n",
    "# take out the three columns\n",
    "X = np.delete(X, 0, axis = 1)\n",
    "X = np.delete(X, 2, axis = 1)\n",
    "X = np.delete(X, 6, axis = 1)\n",
    "X = np.append(X, X_W, axis = 1)\n",
    "X = np.append(X, X_hh, axis = 1)\n",
    "X = np.append(X, X_job, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummary:\\ncolumn 0: no_hh\\ncolumn 1: no_hh_chil\\ncolumn 2: hh_income\\ncolumn 3: no_car\\ncolumn 4: age\\ncolumn 5: sex\\ncolumn 6: work_lat\\ncolumn 7: work_lon\\ncolumn 8~1570: W_ZONE\\ncolumn 1571~1575: hh_type\\ncolumn 1576~1584: job_type\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Summary:\n",
    "column 0: no_hh\n",
    "column 1: no_hh_chil\n",
    "column 2: hh_income\n",
    "column 3: no_car\n",
    "column 4: age\n",
    "column 5: sex\n",
    "column 6: work_lat\n",
    "column 7: work_lon\n",
    "column 8~1570: W_ZONE\n",
    "column 1571~1575: hh_type\n",
    "column 1576~1584: job_type\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher Dimensions\n",
    "# higher dimensions for continuous variables: hh_income, age, no_car, no_hh\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# no_hh\n",
    "X_no_hh = X[:, 0]\n",
    "poly_reg_no_hh = PolynomialFeatures(degree = 4)\n",
    "X_no_hh = poly_reg_no_hh.fit_transform(X_no_hh.reshape(-1, 1))\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "X_no_hh = np.delete(X_no_hh, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_hh, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1585~1587: poly no_hh\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "column 1585~1587: poly no_hh\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh_income\n",
    "X_hh_income = X[:, 2]\n",
    "poly_reg_hh_income = PolynomialFeatures(degree = 4)\n",
    "X_hh_income = poly_reg_hh_income.fit_transform(X_hh_income.reshape(-1, 1))\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "X_hh_income = np.delete(X_hh_income, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_hh_income, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1588~1590: poly hh_income\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1588~1590: poly hh_income\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "X_age = X[:, 4]\n",
    "poly_reg_age = PolynomialFeatures(degree = 4)\n",
    "X_age = poly_reg_age.fit_transform(X_age.reshape(-1, 1))\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "X_age = np.delete(X_age, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_age, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1591~1593: poly X_age\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1591~1593: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_car\n",
    "X_no_car = X[:, 3]\n",
    "poly_reg_car = PolynomialFeatures(degree = 4)\n",
    "X_no_car = poly_reg_car.fit_transform(X_no_car.reshape(-1, 1))\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "X_no_car = np.delete(X_no_car, 0, axis = 1)\n",
    "\n",
    "X = np.append(X, X_no_car, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn 1594~1596: poly X_age\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column 1594~1596: poly X_age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_lat</th>\n",
       "      <th>house_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.453952</td>\n",
       "      <td>126.716877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.465845</td>\n",
       "      <td>126.717234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.229621</td>\n",
       "      <td>127.284122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.623500</td>\n",
       "      <td>127.083187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.469676</td>\n",
       "      <td>126.644354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_lat   house_lon\n",
       "0  37.453952  126.716877\n",
       "1  37.465845  126.717234\n",
       "2  37.229621  127.284122\n",
       "3  37.623500  127.083187\n",
       "4  37.469676  126.644354"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:, [\"house_lat\", \"house_lon\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_lat    180\n",
       "house_lon    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking care of missing data\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(y)\n",
    "# y = imputer.transform(y)\n",
    "y = y.dropna()\n",
    "Y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set (original dataset for random forest and SVM)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_original, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Standardization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# Normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "# Fitting the Random Forest Regression Model to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy based on distance\n",
    "def accuracy(pred):\n",
    "    sum_error = 0\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        sum_error += error\n",
    "    return sum_error\n",
    "\n",
    "def ind_diff(pred):\n",
    "    diff = []\n",
    "    for i in range(len(pred)):\n",
    "        deltax = pred.iloc[i][0]-pred.iloc[i][2]\n",
    "        deltay = pred.iloc[i][1]-pred.iloc[i][3]\n",
    "        error = (deltax**2 + deltay**2)**(0.5)\n",
    "        diff.append(error)\n",
    "    return pd.DataFrame({'Difference': diff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836.4854723538451"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "Svr = SVR(kernel = 'rbf')\n",
    "regressor = MultiOutputRegressor(Svr)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test[:, 0],'house_lon':y_test[:, 1],\n",
    "                            'house_lat (pred)': y_pred[:,0], 'house_lon (pred)': y_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910.4894551538027"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = ind_diff(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Difference\n",
       "0    0.136940\n",
       "1    0.100117\n",
       "2    0.046069\n",
       "3    0.328629\n",
       "4    0.223993"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXGWd7/vPr6vTCdXhlibMS4ipjoogJBCgtxtEj2jUyTDIiCNqqGTCRSKdo7LnAgP0ni1nvyZsOHB0s8XAKyqEoXtH5uAgOgMqIGxBRXfgRK6Ry6S7E0CSdASSNCHp7t/5Y63qrqpeq7qq69aX7/v1Wq9UrVpr1bO6YP3Ws57n+T3m7oiIiIxXQ70LICIik5sCiYiIlEWBREREyqJAIiIiZVEgERGRsiiQiIhIWRRIRCYpM7vazL5b73KImMaRyHRmZt3AnwCDwB7gJ8BX3H1PPcslMpmoRiICn3b32cBi4GTgqkp/gZklKn1MkYlCgUQk5O5/AH5KEFAws5lmdqOZ9ZrZ62Z2q5kdlNnezK4ws9fM7FUz+5KZuZm9L/xsvZndYmb3mdle4GOFjmdmR5jZv5rZG2a2y8weNbOG8LO/N7NXzGy3mf3ezJaE668xs86s8pxjZs+Gx3jEzD6Q9Vm3mf2dmT1lZm+a2V1mNqsGf1aZBhRIREJmNg/4M+ClcNV1wPsJAsv7gKOB/xJuuxT4G+AT4WdnRhzyfGANcDDwWKHjAX8LbAPmEjxquxpwMzsW+ArwH9z9YOBPge6Isr8f2AD8p/AY9wE/NrOmrM0+DywFFgAnAhcU9YcRGYMCiQj80Mx2A1uB7cDXzcyAVcBfu/sud98NXAt8Mdzn88Dt7v6su/cD10Qc9153/6W7DwHvjHG8A8C7gJS7H3D3Rz1owBwEZgLHm9kMd+9295cjvusLwL+5+wPufgC4ETgI+FDWNv/D3V91913AjwlrXiLlUiARgc+Ed/tnAscBRxDc1SeBJ8JHRW8QNMTPDfc5iiDwZGS/jlo31vFuIKgJ/czM/t3MrgRw95cIahnXANvN7PtmdlTEdx0F9GTehMFrK0GtJ+MPWa/7gdkRxxEpmQKJSMjd/xewnuBufifwNnCCux8WLoeGjfIArwHzsnZ/d9Qhs14XPJ6773b3v3X39wDnAH+TaQtx9//p7h8GUuExr4/4rlfDzwEIa1TvBl4p7a8gUjoFEpFc/x34JLAI+A7wTTM7EsDMjjazPw23+2fgQjP7gJklgX8odNCwhhB7PDM728zeFwaANwkeaQ2Z2bFm9nEzmwnsIwhGQxFf8c/An5vZEjObQdDm8g7wq/H/KUSKo0AiksXddwD/RNAI/vcEj5seN7O3gAeBY8Pt7gf+B/BwZpvwEO8UOHzs8YBjwvd7gF8Da939YYL2kesIajR/AI4konuyu/8eWA58K9z20wTdmveX/EcQKZEGJIpUQNjV9hlgprsP1Ls8IrWkGonIOJnZueHYkMMJ2i1+rCAi05ECicj4fZmgu/DLBG0a7fUtjkh96NGWiIiURTUSEREpS2O9C1ALRxxxhLe2tta7GCIik8oTTzyx093njrXdtAgkra2tbNy4sd7FEBGZVMysZ+yt9GhLRETKpEAiIiJlUSAREZGyTIs2kigHDhxg27Zt7Nu3r95FmTJmzZrFvHnzmDFjRr2LIiI1NG0DybZt2zj44INpbW0lyJMn5XB3+vr62LZtGwsWLKh3cUSkhqbto619+/bR0tKiIFIhZkZLS4tqeCLT0LStkQBjB5G+PnjlFdi/H5qa4OijoaWlNoWbhBSURaanaR1ICurrg54eGAqnfti/P3gPCiYiIlmm7aOtMb3yykgQyRgaCtZX0A9/+EPMjM2bNxfcbv369bz66qvj/p5HHnmEs88+e9z7i4jEUSCJsz9mPqC49eO0YcMGPvzhD7Nhw4aC25UbSEREqkWBJE5TU+77+++HT38aPvhBaG2Frq6yv2LPnj089thjfO973+P73//+8Prrr7+eRYsWcdJJJ3HllVdy9913s3HjRtLpNIsXL+btt9+mtbWVnTt3ArBx40bOPPNMAH77299y+umnc/LJJ/OhD32I3//+92WXU0SkELWRxDn66JE2kvvvh2uvhUyPpJ4eWLUqeJ1Oj/sr7r33XpYuXcr73/9+WlpaeOKJJ9i+fTv33nsvv/nNb0gmk+zatYs5c+Zw8803c+ONN9LW1lbwmMcddxyPPvoojY2NPPjgg1x99dX84Ac/GHcZRUTGokASJ9Og/sorsHbtSBDJ6O+Hjo6yAsmGDRu47LLLAPjiF7/Ihg0bcHcuvPBCkskkAHPmzCnpmG+++SYrV67kxRdfxMw4cODAuMsnIlIMBZJCWlqC5fXXoz/v7R33oXft2sXPf/5znn76acyMwcFBzIzzzjuvqP0bGxsZCjsDZI/d+Id/+Ac+9rGPcc8999Dd3T38yEtEpFrURlKM+fNLW1+Eu+++mxUrVtDT00N3dzdbt25lwYIFHHroodx+++309/cDQcABOPjgg9m9e/fw/q2trTzxxBMAOY+u3nzzTY4++mggaKAXEak2BZJirFkD4aOmYclksH6cNmzYwLnnnpuz7i//8i957bXXOOecc2hra2Px4sXceOONAFxwwQVceumlw43tX//617nssstoa2sjkUgMH+OKK67gqquu4uSTT2ZgYGDc5RMRKda0mLO9ra3N8ye2ev755/nABz5Q/EG6uoI2kd7eoCayZk1Z7SNTVcl/VxGZsMzsCXcv3MMHtZEUL51W4BARiaBHWyIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgqaNEIsHixYtZuHAh55133vAgxPHIThP/ox/9iOuuuy522zfeeIO1a9cOv3/11Vf53Oc+N+7vFpHprWqBxMxuM7PtZvZM1robzGyzmT1lZveY2WHh+hlmdoeZPW1mz5vZVTHHXG9mW8xsU7gsrlb5a+Gggw5i06ZNPPPMMzQ1NXHrrbfmfO7uw2lQSnHOOedw5ZVXxn6eH0iOOuoo7r777pK/R0QEqlsjWQ8szVv3ALDQ3U8EXgAyAeM8YKa7LwJOBb5sZq0xx73c3ReHy6aKlzpGV1eQPb6hoWJZ5HN85CMf4aWXXqK7u5tjjz2Wv/qrv2LhwoVs3bqVn/3sZ5x++umccsopnHfeeezZsweAn/zkJxx33HGccsop/Mu//MvwsdavX89XvvIVAF5//XXOPfdcTjrpJE466SR+9atfceWVV/Lyyy+zePFiLr/8crq7u1m4cCEQ5O268MILWbRoESeffDIPP/zw8DE/+9nPsnTpUo455hiuuOKKyv4BRGTSqlogcfdfALvy1v3M3TN5Ox4H5mU+AprNrBE4CNgPvFWtspWqqyvIGt/TA+4jWeQrFUwGBga4//77WbRoEQAvvvgiq1ev5tlnn6W5uZl//Md/5MEHH+TJJ5+kra2Nb3zjG+zbt49LLrmEH//4xzzxxBP84Q9/iDz21772NT760Y/yu9/9jieffJITTjiB6667jve+971s2rSJG264IWf7b3/725gZTz/9NBs2bGDlypXDSSE3bdrEXXfdxdNPP81dd93F1q1bK/MHEJFJrZ5tJBcB94ev7wb2Aq8BvcCN7r4rZr814aOxb5rZzLiDm9kqM9toZht37NhRVkE7OoKs8dkyWeTL8fbbb7N48WLa2tqYP38+F198MQCpVIrTTjsNgMcff5znnnuOM844g8WLF3PHHXfQ09PD5s2bWbBgAccccwxmxvLlyyO/4+c//znt7e1A0CZz6KGHFizTY489Nnys4447jlQqxQsvvADAkiVLOPTQQ5k1axbHH388PZk57EVkWqtLihQz6wAGgMw9/QeBQeAo4HDgUTN70N3/PW/Xq4A/AE3AOuDvgf8a9R3uvi7chra2trISisVliy8jizww0kaSr7m5efi1u/PJT35y1FS8UftV28yZI3E7kUgoKaSIAHWokZjZBcDZQNpHMkaeD/zE3Q+4+3bgl8CoRGHu/poH3gFuJwhAVVeFLPJFO+200/jlL3/JSy+9BMDevXt54YUXOO644+ju7ubll18GiJ3zfcmSJdxyyy0ADA4O8uabb45KSZ/tIx/5CF3hM7sXXniB3t5ejj322EqflohMITUNJGa2FLgCOMfdsx8W9QIfD7dpBk4DNkfs/67wXwM+AzyTv001VCGLfNHmzp3L+vXrWbZsGSeeeCKnn346mzdvZtasWaxbt44///M/55RTTuHII4+M3P+mm27i4YcfZtGiRZx66qk899xztLS0cMYZZ7Bw4UIuv/zynO1Xr17N0NAQixYt4gtf+ALr16/PqYmIiOSrWhp5M9sAnAkcAbwOfJ3g0dRMoC/c7HF3v9TMZhPUMI4HDLjd3W8Ij3Mf8CV3f9XMfg7MDbfZBFzq7nvGKksl0sgri3xxlEZeZOqoexp5d18Wsfp7MdvuIegCHPXZWVmvP16Z0pVOWeRFRKJpZLuIiJRlWgeS6TA7ZC3p7ykyPU3bQDJr1iz6+vp08asQd6evr49Zs2bVuygiUmPTdqrdefPmsW3bNsodrCgjZs2axbx588beUESmlGkbSGbMmMGCBQvqXQwRkUlv2j7aEhGRylAgERGRsiiQiIhIWRRIRESkLAokIiJSFgUSEREpiwKJiIiURYFERETKokAiIiJlUSAREZGyKJCIiEhZFEhERKQsCiQiIlIWBRIRESmLAomIiJRFgURERMqiQCIiImVRIBERkbIokIiISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgERGRsiiQiIhIWaoaSMzsNjPbbmbPZK27wcw2m9lTZnaPmR0Wrp9hZneY2dNm9ryZXRVzzAVm9hsze8nM7jKzpmqeg4iIFFbtGsl6YGneugeAhe5+IvACkAkY5wEz3X0RcCrwZTNrjTjm9cA33f19wB+BiytfbBERKVZVA4m7/wLYlbfuZ+4+EL59HJiX+QhoNrNG4CBgP/BW9r5mZsDHgbvDVXcAn6lO6UVEpBj1biO5CLg/fH03sBd4DegFbnT3XXnbtwBvZAWibcDRtSioiIhEq1sgMbMOYADoCld9EBgEjgIWAH9rZu8p4/irzGyjmW3csWNH2eUVEZFodQkkZnYBcDaQdncPV58P/MTdD7j7duCXQFvern3AYeHjLwgei70S9R3uvs7d29y9be7cuRU/BxERCdQ8kJjZUuAK4Bx378/6qJeg/QMzawZOAzZn7xsGnYeBz4WrVgL3VrvMIiISr9rdfzcAvwaONbNtZnYxcDNwMPCAmW0ys1vDzb8NzDazZ4H/Ddzu7k+Fx7nPzI4Kt/t74G/M7CWCNpPvVfMcRESkMBt5sjR1tbW1+caNG+tdDBGRScXMnnD3/CaGUerda0tERCY5BRIRESmLAomIiJRFgURERMqiQCIiImVRIBERkbIokIiISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgEZHKOeEEMBtZTjih3iWSGlAgEZHKOOEEeO653HXPPadgMg0okIhIrq4uaG2Fhobg366u4vbLDyJjrZcpo3HsTURk2ujqglWroD+cBbunJ3gPkE7Xr1wyoalGIjJFjadi0XXZb2jtf5YGBmllC10sC4JKR8fYx2dZhc9AJgsFEpEpKFOx6OkB97BisaKfLksHV/3Vq3OjwOrVdB3xNVb1/Td6aMVpoIdWVvGdIED09o59fPtedDA5/vjyT2Y8j9qkdtx9yi+nnnqqi0wbnZ2eSmz14BKfuyQ44Magp9jinSzL+TDFlsh9Umxxb2nJ+YpUavR24J5q3DZ6ZXt7WefiyWTu8ZLJYL1UHbDRi7jGqkYiMknk35hnVyqOOCJYGsxpXfERegaPijzGII3DtY0VdLKab9HFMlrZQg+pyH16mT96XW/EhkDvwLtGr7zllqCw49HRMdJekxHzqE3qx4KgM7W1tbX5xo0b610MkXHLbwMfizFEcfeJQzQyyAAzCmzjpOhhTWfrcHt7a2vwOCtfim66WTD6g0QCBgaG33Z1BbGgtxfmz4c1a2La8hsagnpIPjMYGip0YlIBZvaEu7eNtZ1qJCKTQNSNeSFBECnmJrFhjCACYPTQykUXhbWeBtizB5qacrdKspc1XB19iMHB4SpUl6VZtaI/t31lVUzTx/zRtaGC66UuFEhEJrJwpHhvz3juvq2iRdm/H/r6got/X19QwWhpAcNJJbaxjktIsyH+ALfcAj09dLCGfk/mfBT7tGrNGkjmbksyGayXCUPjSEQmqqyR4vPppYfW+pYnz9AQsG8fQ8mWkqpLUW0uENPuknneVdRzMKkX1UhEJqqsEeFruJoke+tYmGh9e2dCf/9wg70xSCMHMAY5gu0cwfbcMSkEQTHKnDkxX5JOQ3d3ELm6uxVEJiAFEpFJ4iD6Cdo9nGbeooH99S4SAKv5Fqv4TlhjamCQRqCBPubSx9zhXmIXcTtHsJ0e5hPVfvPWWxoiMlkpkIhMQF1d0MoWGsI7+wu5jT7mErR7GE6CL7OOFN0YQ6RS0Nxcj5Iat7Kafsb+8v3MDM+hgaj2mwMHYOXKyRlMhrtmm9PauG1k4OdkPJlxKCqQmNlnzexFM3vTzN4ys91m9la1CycyHQ2PGg9HmPcxlwPMytmmn2bu42y6WcAQCbq7Ydas6ONVWyWHow0OFujBNRF1dQUZAZbvDXqhYfQMzmMV6+jq+dAkO5nxK2ociZm9BHza3Z+vfpEqT+NIZDKJG6Mx2hBOAoCuTmf58mqWqrZSqaA5ZEILI35r/7ORHSGGx9RMipOJVulxJK9P1iAiMtnEjRqP0sUyuo76u+EEvaWZuIORS/kb1DIXV85XrfwoXf1/Ed8LLbO+pJOZnIoNJBvN7C4zWxY+5vqsmX22qiUTmabmz9lT5JYNfJlbWfnadSUNVgw4xyc2Y1RydLgTH5yGCnw2WtHjDSOzR5b5OCkmMI36qsF5rOI7zKEv+hwyvdOmweDJYgPJIUA/8Cng0+FydrUKJTJtdXWx5q2vFt3Vdy8HM+iJkr5iBvto59t0D86vaPtGih4sNlgYxQ6QLGm8YSVycX3iE7nTAy9fnhuYli+Ho4+O/qqwk0H+7zU8yn+6DJ4sJrPjeBbgNmA78EzWuhuAzcBTwD3AYeH6NLApaxkCFkcc8xrglaztziqmLMr+K5NGmFa3k2WeYosbg57gQGSm3fEvQ+FSuWMm2TNc5vjvLFwmY9BTia3e2f7o2H+nzs74FMRZSzvfCv9+Q55IRCQiXrKk6JM0BiM/MgZzfq9UQ693cn5QvkmepZgis/8WGxTmhRf+7eHyA2DeGPv8H8ApeYHkU0Bj+Pp64PqI/RYBL8cc8xrg74opc/aiQCKThtmoK1Unyyp+4a9kUMpOSd/JMk+yp8QgknecsdLER6WWjwkiUd/d3Dxy+JwAEJFaP3uJTbOf2Br8blMgcOSrdCB5ALiQIKVKI3AB8EAR+7VmB5K8z84FuiLWXwusidlHgUSmtpi77LiLYvzdf/UDT6YWElVWY2BcZRg+ZipV8t8ofylUk0smg9pJftCLO6fhIGl7Rx1nisWOHJUOJJuKWRexTaFA8mNgecT6l4GFMftcA3SHj8ZuAw4v8N2rgI3Axvnz51f67ytSHQXutkceHY39mKjaQQSGvIXtDkOesAEnvKNfknjIiXkEVOySYktwhx8notYWtYz375BiS+yHnZzvqdSUrYCMUmwgKbalrc/MlptZIlyWQ0xXhSKYWQcwAHTlrf+PQL+7PxOz6y3Ae4HFwGvA/xP3He6+zt3b3L1t7ty54y2qSG2l07BuXTD2wCz4t70dUinS9n26U2eSmrW93qUEbHikfdDYH6RBeWjw45SbMKOH+YV7Oo3RCyqT92u8Mt12M8fJzhWWTv1yJO3Xmi7SHa2aAhiKrpGkgB8BOwjaSH4IvLuI/VrJq5EQPBb7NZCM2P6bwNVFlmnUseMWPdqSqWTsJoKJ2p5S7DLkqZbd8Xf7Y9TaRrfRlLZk2koiH3tlOgJMkymAqeSjrcgd4T8VsU3OxR5YCjwHzI3YtoGgR9Z7ChzvXVmv/xr4fjFlVSCRCS3TAynzvKS93cd6fjLSaSk6aMT1MKp3gChl+9jrcmdnMId8Jng0XeAp66lID7cZM0YdPjfIpMIyxE5an4oo8ORVi0DSO8bnGwgePx0AtgEXAy8BWxnpvntr1vZnAo9HHOe7QFv4+k7gaYI2kh9lB5ZCiwKJTFjF9EAqcKcbHzAGh9swJlYNpbSyjLou5/29OlnmM3i7ZuUfbrqJa6cp1LYzCdUikGwd7761XhRIZMIqsgfS8BU1q/bS2fLVsKF79OYts98upofshF/MPKihJRKRXXWDYFm78qhGEr2U0yrmZewrIlB8Hqbe3pwcHV3+RVb1/bfIUe3JpgGYOWscaVPqKfpyMr+5D265ha7Bzw/PeZKZ32QV36GPI2payuFB6pWcAnj1amhsDDpXNDYG7yebQlEG2A28FbHsBgaKiVQTYVGNRCasUmokWdvGDY4zBmKf70+2JZl077R0wfOt5WO7lpa83y6/bWs8De3t7dFfNmoIfn1QZI2kqDTyk53SyMuElallFKo+JJNBl+AVK4LLDME8hNEPFJxic1rVRzHlc1IpC6ZmXx5sW+/zzfwEFZ/lt7ExmIQlXyIBAwMV/rLSVTqNvIhUQ4FxI8PvM1ewrPETcfOeT+wgAsU8ETd8ZGr2huASFXe+LbaLJt6pStkyCSizf4JilJTVPiqIFFo/URVTbZnsix5tSV1V4hFI5jjho49KjJeo+aMq9oTpU8bqmjwU/JnaHx3uHRU5riPszNbJ+RXo7jzkTez1TC+3FrYHqVKyE3MV+ROVNLwkkYguUCIxvv9GKoxq99qaTIsCidRNpQeuZY+fYFkVMgOXt7S0jIxvaRjOt5V1YYYig4l70vbm5L3K6bWV2DryJ0ylvFrZjEv9vUruzDVF2kjqfpGvxaJAInVT7JXl+ONzPz/++Ojj5QWm8d6JNzDgLWwP96/cRdgsqElEjgq3tHtDgzt4p6U9ZT3OGN9fKO/VcDfo5ksqHkhGfXeR3XrHNbwk7N486twmwCh5BZKsRYFE6maMK0tnp3uqcVt0GvNCwSQMUPG9mQovxuDwm0qOxWixnbG1pNE1lPPHLH92ObOX6s7XEvHdRQ40HPfwkgmackWBJGtRIJG6KXBl6ex0TzblXgQz7QjDj3BSBa4ljL+tJPtuu5Nl3sS+Clx8SxtFH4xIL7x9iu5RK4t9NAbuRx01/vMZT41k3PFggg5wVCDJWhRIpG6irixhLSV4tDP62pF/kcxUakYFlaxAENzZF/eYKmrOjexj1DZPV3x5k+zx9qbveKqhd7jG1s7NRQerIrPNR2433jaSzE9ect+KCZpyRYEka1EgkZqIuoJ0dgY9fyIuEuO5YOcElYiG6GLmKmnnWzkrc6aj5YAv4SdFHquay5Av4SfjnG2x+L9lU9Po9S3Nb3tny1drO+mIaiQTf1EgkaqLqnnMmBHfvZPxt28M3zVbv3eybByPt0amtY2eeTG4iNc72WPQplKdY5sVkeG33v/9TKI2Eo1sF6mE1lbo6Slply6WcRG3s5+Z4/7alsQfeWPwYAZpLHnfJt5hP01ED2L0mPWVNNZ3VK8M7e1w663BFTufWTBxVc11dUFHR5BXbf78IG9XxYfSl0Yj20VqqUDyxaiZ9jIGyrxQ9g0eXiCIFL5JDAJY3PfXYoS8YRS6YlcviKxdGz/R4hgTMFZPOs3I9Ivdo4NISUPma0uBRKQSYq4+XSyLzFrbxTIu4yaGaKpakWbyDmMFk3pzjKCMtSlnA4Oc8c9fg64uzjorqH1kSybhrLOKv153Jb9Eq3XTYEO0WjddyS+NfDbGdb+kuJCV+Rn34N9VqyZOMCnm+ddkX9RGIlUX00YS1w5S7cbsxkav6YRPk2sZ8tm85TMSuW0wZu5LlhTRVBGmqomdjvegi72zM2giy/nPgX3DU/WW3CRSp8Z41EYyQm0kUhMRz7gblp8f3nXnMobC9RM9yaIAtFgfs+fMpLevmTnsBAjnQhn9+6XoZk9LK319EcdhJzs7f0prRzqySS2VCp5qjdLQEISOfFVu0Cm2jUSBRKSK4trgW9gReyEqjVfgGDK24v/OwU1CXKuB4zTEpsWPjQtx/yHFRp7KUGO7yAQQOZEee8NXlQoAU/9msP6K/62ClPeFf5O4tPixDf2VnJGxChRIRKoonYZ1h11Oim6MIVJ0s45L6KOlQt+g2sjE4uyhmWZ2R37aEj4WW8PVWTcUgYJxIWremqrMtDU+erQlUm35XYOARg6Ma+xHPD3imkiaeIdBGhhkRs6627iQNBuAoEdfB9fSa60TZdjIKHq0JTKB5I8lGSRR4W9QEJlI9jOTw3gjpyaaHUQA0mygO3Vm7LCRyaSSt0QiEiEzlqSfZgB6aAWG0MV/attFCzs5MnjT2Qmr7oX+rA0mUBtHuVQjEamyDq4dDiIjqv2/3tR/ZD3ReThyv5EBVv9yYrdxlEuBRKTKeqlHzg3Vduor02ZlDJLgllsIgkmhFCiVUodUKgokIlUW19VTprLRgXzdutz3RV3vSw0KdUqlol5bItV0wgl0PXdSThuJTFdOS/M77No7kznsZDeH5GR+Tja+w7r1M0kTZkiIGoDY1AQHHwy7dkVnCK7wwEWNbM+iQCI1t3p1cAs6OAgwnKSxMqPZZapKzXqd7ob3QH//2BtD0GCf3dZS4VQq6v4rUi+rV8MttwwHkYy3SaIgIoX07ps7KogUmoaA/v6g9pJRp9z4CiQilZb/MJy4nlsiufLb0wpNQzAsey6cOqVSUSARqbS8mgjUq+eW1EZc80CpzQbOWfxrzpqoG5B+mung2pEV2bWNOqVSUSARqQH13JrKCs0yWUowMW7h/8x5fBV3AzK8Pqq2MdZMi1VQtUBiZreZ2XYzeyZr3Q1mttnMnjKze8zssHB92sw2ZS1DZrY44phzzOwBM3sx/PfwapVfpJLWcDUaJDgdlR5Msh9fxWYJpndCDWqsZo028CrkAAATGUlEQVRkPbA0b90DwEJ3PxF4AbgKwN273H2xuy8GVgBb3H1TxDGvBB5y92OAh8L3IhNLYnQerTQbYjPCylQRFzBKDSYjj69iswR3tk6oBF1VCyTu/gtgV966n7n7QPj2cWBexK7LgO/HHPYvgDvC13cAn6lAUUUqa9WqyNX9zK5xQaS2CvXIK723Xg8pVtDJQfTTwo6RaQgmRiUkRz3bSC4C7o9Y/wXISpGZ60/c/bXw9R+AP4k7uJmtMrONZrZxx44d5ZVUpBRr10J7+0jNJJGA9nbms7W+5ZJJxnAa6GMub5PkTpbTnTpzwgURqFMgMbMOYADoylv/H4F+d38mcscs4cT0sfVFd1/n7m3u3jZ37txyiyxSmrVrYWAgGBw2MABr17KGq1A7yfQVMS1NlsL/XfTTTIddN2GzBdc8kJjZBcDZQNpHD6v/IvG1EYDXzexd4XHeBWyvSiFFqiCd+OfhGfJk6mppiR7KcemlI71yW1qCJdNDt33J70kltmEMERdUev3dE++ZVqimgcTMlgJXAOe4e3/eZw3A54lvHwH4EbAyfL0SuLca5RSpmK4umDEjuGIMDnITl41qPJ3BPlRTmZyCC/+IZBJu+vxjrDvoayOTWrXsYd26oJKa6ZW7c2ewZHrorn3wOLoH5jHkDaRS0VWX+THrJwR3r8pCULN4DTgAbAMuBl4CtgKbwuXWrO3PBB6POM53gbbwdQtBb60XgQeBOcWU5dRTT3WRmuvsdDdzDx5wDS+dLPMUW9wY9BRbvJNl3s7NUZtqmcBLkj3ezrdGfsuUe2f7o+7JZN6GyeC/hRL+synzEBUDbPQirrFjbjAVFgUSqYtUqvirUirl7e2RcUfLhFyGvJ1vBW+WLMn5zaNuFDyVKuk/nc7OYBez4N96BBF3LzqQKPuvSLXEZWKN0tlJa0c6MgN48bK/awI/BpkiUoltdA/kjmDosjSrWJeT1iTJXtaxirRXf4KpSlP2X5F6KyXjajqdk3uvVEn20kmaVMM2FERqo3fw6FHrOhLXR+fGSlxfq2LVhQKJSLWcdVZJm5ee6dtHBqlxCenkvfQORY3xlWpwbGTSwtWrobGR3sGjIreNCjpTiQKJSDV0dUWmk4+0ZAkQnQG8kBQ9DJGgmwWkU7+Cdesmds+eSS36EWVPD6xY7tgtN9M6+BJz6Ivcbqr/LgokIpWWmTc7Ip38KEuWwIMPAiMZwCNSdY2SZG+YCJKge3GYdyk6GE39dtDqiw8EjkE4V8huDgm7c4+InQ6k1PnYJzAFEpFK6+gobqrUVGo4iGSk03DHHaODQSMHMAYBJ8EAK7mdNBuCILJ//8j+dLHuoK/Rwg6CAOI0s5sGighqUrb9zOQQdo+MIUnFJOjN3Gz09AQdMnp6gveTNJgokIhUWrGt5jHbpdOw7vTbSNGDMRQm7HOcBGAM0sgdTZfS1ek5QYSuLrjoIujbmTWtr7GXQ0hwgCbeKffMpAi7aKGbBQwlmuIT9EbdbORPmzuJKJCIVFqxreZx261eTfqhi+mmlSESzGYvB2jK2aR/f+Poa85ll8H+/ZGz6h1gFgfzVlZNRapleA6RmCzQQPzNRjld9+pIgUSk0oppNS80j3ZeI33sLHn515y+voLb76KFnan/QEuzaibj4xDWEIOAPDQ6RQp7WWP/Ocj+vHZt/KHibiJK77o3ISiQiFRa1LzZ7e3Fz6Od10gfO0te3LWo0Kx63d3s6p9V9KlINiNFLzs5kp0ciZPgTlbk/qydzaSHOgsHEYi+2Sh0czHRFTP8fbIvSpEik0oikZOPo5NlnmRPToqOyNxLLS3x27PHOy3t7qVlbtGSuxiDuSuam8f/O0+UPCgFUGSKFNVIRCaavGfraTawjktIze4rXKG56SaYMWNk+0zPocyAxUsPAUofryIjHKOVLXSxLFjx9tux247ZuzedHkkHPIGmzR2XYqLNZF9UI5EJK+6utL19pGaSSATvSzle9l1zxP7DX8uQNzBQ9zv9ybYk2RMkY4TYn2GiZPAtB0raOEJJG2VCyowlyO4GmkwWbj8p5dgdHUGL/Pz5QTUk5pgNNoQeTpQuRTfdifcFM2DmaW0lMgFnKhVUPiYLJW0UmeiqNZagxMFu8xOvlvd901Qv82O7+E6x3r1jUiARqZdqXW0KBaiIB/drVnWPmrVx+ir+Cc382X+M7Z01xXr3jkmBRKReqnW1iQtEmZpJXk0lfUZPTuN8KRfTqcNJ0U073x6VAaCRA8zIW5dMwppbW2KPNtV6945FgUSkXqp1tYkLRIlEdE1l+XLSbKCbBdzJcmwaBpIUPXSzgLV8ldu4MKfH23pWcjsXFT0MCKKHElWi6WuiUmO7SD2V0Che0jGjGvGLSCTZyhZ6aC3v+ycUZ6yJvmawj9u5KEiCGWeytZJXiBrbRSaDaowliLsdTqXG3DUuvcrkNfY8IDbWNlP5mVSFKJCITEVRAaqIkYhzWqbfJWE/M+ng2tEfTIdnUhXSWO8CiEiNZC6Gy5dHftxlad56a/R6Y2A4hf1UNaomNk0fZY3X9Lv9EJnO0ukggWSEjuabOHBg9HoL5zWZynISXTY26lFWiRRIRKabtWuDYJKZ0zeRgPZ2evdGd2cdmmKXCcuLiTnTFs+eDevX61FWiabWfyEiUpy1a4PUHu7Bv2vXFug1PFlrI04juVWsJHu59FJGp373/xn8LXbvVhAZBwUSEQHih7WsWgXJpvx8Uj4J5oE3BmmAcO76FnawjktYu3bqJN2dKBRIRASI7zW8di2su62RlPUOD9LrJM0/sYIEEY0qdRE9Hm6kk4AF89g3z65pqaYLBRIRGZbpNXznncH75cuDtufly4H587nzsK/SzQLSbCDNBu5gJc28Rf3Tqoz9+K2fZjr2dgRRMnKCEBkvBRKRqWzM2ZWid8mk5IKRmX97emDV/m/T1enDjfVpNrAnMYeWmXuqdgrFGzuY9fLu4EVPD6xYAatXV7lM04NSpIhMVeOc7yRuLo2MqCEWDQ1BW3W5zMo5zsiOxlD4WCtXim66WZD7hXfeqYaSGEqRIjLdjXO+k7Gy2Ed9Xon06C0twTV9xozxHsGGlxkMMIN9OZ/mdPPNcC9//hdRIBGZssY538lYQSHq8zVrRo/PKNXixUHF4Pbbg6BSjv3M5JBZA6QS23LnrY9KzDhVZ5uqoaoFEjO7zcy2m9kzWetuMLPNZvaUmd1jZodlfXaimf3azJ41s6fNbFbEMa8xs1fMbFO4nFWt8otMeuOc76RQSq64/IXpNFx6aaGj+piN8o88MnKsnTtHZjvv7BzJN5kY/bQq1q53ZtN9x/9iKHnwcAeBSFN1tqkaqmaNZD2wNG/dA8BCdz8ReAG4CsDMGoFO4FJ3PwE4E2L7FX7T3ReHy33VKLjIlBAVEcyCBhCzYPnEJ0btlt0NGEYu3mPlL1y7Nr4m0cJO9nAonaSJCyaDMcNSMj3J3OGOO4pKYgyE8SGdhtNPj9+oqUnpUCqgaoHE3X8B7Mpb9zN3z4xsehyYF77+FPCUu/8u3K7P3Sf6aCeRiS1/YEhT0+iW7Iceig0mmYt3ZgB8MYP3brppdOzKzDjYwCAdXEsDQ5H7jlXbyO9NVkgyCWsOXB6c90MPxW84Y4Ya2iugnm0kFwH3h6/fD7iZ/dTMnjSzKwrs95Xw0dhtZnZ43EZmtsrMNprZxh07dlSy3CKTR3Y6+f37o7cpdKEdx9etWwep2X0YQ7SwA8fpYy5OAz20xk7nu2pV4WNH9R3IaGkJFrPg34Pe3sWKV6+nlS10sSz+oHv3jquLtORx96otQCvwTMT6DuAeRrof/x2wBTgCSAK/BpZE7PcnQIIgAK4BbiumHKeeeqqLTHsjzQ6jl0pLJNzBU2yJ/Lpm3vQEBxyGPJFwb28f+5Bm0UU3G9mms9M9mcz9PMke72RZ/LmP2iEZHEgc2OhFXGNrXiMxswuAs4F0WFCAbcAv3H2nu/cD9wGn5O/r7q+7+6C7DwHfAT5Yo2KLSCnCBo+4GRf7mc0AM/DUgkzOyDEV03cgssczzdETV0FQCxlHF2nJVdNAYmZLgSuAc8KAkfFTYJGZJcOG948Cz0Xs/66st+cCz+RvIyIxZo3qCFl4fTnCBo+ceT6yDK8voaE7Lqlk9iFiezzHTSE8FN1eoy7Bpalm998NBI+ojjWzbWZ2MXAzcDDwQNh991YAd/8j8A3gfwObgCfd/d/C43zXzDIjK//vsGvwU8DHgL+uVvlFppzvfje4A8/W0BCsL1d+O8OZZwKwhqtJsjdn0+GBgccfX1JDd1xSyexDxNZaYgJabBcwdQkuTTHPvyb7ojYSkVBnp3sqFTQspFKVaQuIbJhIui9Z4p5IeCfLPMUWNwY9xZagvWLJkvK/t9iixLWRZM4/quzt7ZX/O01CFNlGUveLfC0WBRKRKkqlRl+kMxfqOsiPle1LnveU9eQGsuwG9fb24c4BnkgEQU4N8O5efCBR0kYRKU9cxkaz+DaIGula/Rirbj2Ffh9pXElaP+sufZL02g9HJ7aMyxwZla1yilPSRhGpjbj2hIaG+o7N6Oqi49b5OUEEoN+TdNz34eBNVDevuJtrNcDHUiARkfLEJecaHAwuyj09wV1/rYNJRwe9Pi/yo+GYUEpwUAN8LAUSESlPfneqqFwn1RqbUWhUem9vfPfj+fkv8uSnMo7LVimAAomIVEJ2KpZajc3ITr4VVfOZPz+6+7H1j8SEuMEpl15auJ+x5FAgEZHKGmf6+pKNNXHXmjWkk/eyjktI0R3MS2K9QUN7JibEDU5Zu3YkMBaTrXKaU68tEamscU7xW7Jieot1dQWBpbc3CGRr1igolEC9tkSkPooZgl4JxdR8sh+5qWZRNQokIlJ5tbiAF5N8S2pCgUREJqda1XxkTI31LoCIyLil0wocE4BqJCIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZVEgERGRskyLFClmtgPoqXc5shwB7Kx3IepI56/z1/lPDil3nzvWRtMikEw0ZraxmPw1U5XOX+ev859a569HWyIiUhYFEhERKYsCSX2sq3cB6kznP73p/KcYtZGIiEhZVCMREZGyKJCIiEhZFEgqyMxmmdlvzex3Zvasmf1f4XozszVm9oKZPW9mX4vZf6WZvRguK2tb+vJV4PwHzWxTuPyotqUvX4HzfzTrvF41sx/G7D9Vf/9iz3+q/v5LzOzJ8LweM7P3xex/lZm9ZGa/N7M/rW3py+TuWiq0AAbMDl/PAH4DnAZcCPwT0BB+dmTEvnOAfw//PTx8fXi9z6lW5x+u31Pvc6jG+edt8wPgr6bT71/M+U/l3x94AfhAuH41sD5i3+OB3wEzgQXAy0Ci3udU7KIaSQV5YE/4dka4ONAO/Fd3Hwq32x6x+58CD7j7Lnf/I/AAsLQGxa6YMs9/0itw/gCY2SHAx4GoO/Kp/PsDY57/pFfg/B04JFx/KPBqxO5/AXzf3d9x9y3AS8AHq1zkilEgqTAzS5jZJmA7wYXhN8B7gS+Y2UYzu9/MjonY9Whga9b7beG6SaWM8weYFW7zuJl9pmaFrqCY88/4DPCQu78VsetU/v0zCp0/TN3f/0vAfWa2DVgBXBex66T+/RVIKszdB919MTAP+KCZLSSoru7zIC3Cd4Db6lnGairz/FPhNucD/93M3luTQldQzPlnLAM21KdktVHm+U/V3/+vgbPcfR5wO/CNepaxGhRIqsTd3wAeJng8sQ34l/Cje4ATI3Z5BXh31vt54bpJaRznj7u/Ev7778AjwMlVL2iV5J0/ZnYEwaOKf4vZZSr//sWc/1T9/f8MOCmrZnYX8KGIXSb1769AUkFmNtfMDgtfHwR8EthM8Ez4Y+FmHyVofMv3U+BTZna4mR0OfCpcN2mUc/7hec8MXx8BnAE8V4tyV0qB8wf4HPCv7r4vZvep/PvDGOc/hX//54FDzez94WaZdfl+BHzRzGaa2QLgGOC3NSh2ZdS7tX8qLQR32v8f8BTwDPBfwvWHEdyJPQ38muAOBaAN+G7W/hcRNLK9BFxY7/Op5fkT3KU9TdBz5Wng4nqfT6XOP/zsEWBp3vbT4vcv5vyn8u8PnJt1bo8A7wnXn0PQCSWzfwdBb63fA39W7/MpZVGKFBERKYsebYmISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBRKQGzGzP2FsNb3ummUUNWhOZkBRIRCaeM4ke/SwyIWkciUgNmNked5+dt+7TwH8GmoA+IA0cBDwODAI7gK+6+6M1Lq5ISRRIRGogJpAcDrzh7m5mXyKYs+Jvzewagrk5bqxHWUVK1VjvAohMY/OAu8zsXQS1ki11Lo/IuKiNRKR+vgXc7O6LgC8Ds+pcHpFxUSARqZ9DGUkVnj1H+27g4NoXR2R8FEhEaiNpZtuylr8BrgH+XzN7AtiZte2PgXPNbJOZfaQehRUphRrbRUSkLKqRiIhIWRRIRESkLAokIiJSFgUSEREpiwKJiIiURYFERETKokAiIiJl+f8BHHVdx8hV+/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test[:, 0], y_test[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred[:, 0], y_pred[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,786\n",
      "Trainable params: 6,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11)) #1597 for X and 11 for x_original\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_standardized = np.zeros((len(Y), 2))\n",
    "Y_standardized[:,0] = (Y[:,0] - np.mean(Y[:,0]))/ np.std(Y[:,0])\n",
    "Y_standardized[:,1] = (Y[:,1] - np.mean(Y[:,1]))/ np.std(Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed dataset with dummy variables and polynomials as well as standardized outcomes\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_original, Y_standardized, test_size = 0.2, random_state = 0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2974 - mean_absolute_error: 0.3838\n",
      "Epoch 2/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.3017 - mean_absolute_error: 0.3852\n",
      "Epoch 3/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.3021 - mean_absolute_error: 0.3856\n",
      "Epoch 4/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2988 - mean_absolute_error: 0.3833\n",
      "Epoch 5/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.3006 - mean_absolute_error: 0.3832\n",
      "Epoch 6/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2969 - mean_absolute_error: 0.3818\n",
      "Epoch 7/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2981 - mean_absolute_error: 0.3821\n",
      "Epoch 8/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.3006 - mean_absolute_error: 0.3836\n",
      "Epoch 9/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2971 - mean_absolute_error: 0.3820\n",
      "Epoch 10/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2957 - mean_absolute_error: 0.3815\n",
      "Epoch 11/250\n",
      "37342/37342 [==============================] - 1s 35us/step - loss: 0.2955 - mean_absolute_error: 0.3815\n",
      "Epoch 12/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2952 - mean_absolute_error: 0.3803\n",
      "Epoch 13/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.3004 - mean_absolute_error: 0.3832\n",
      "Epoch 14/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2947 - mean_absolute_error: 0.3803\n",
      "Epoch 15/250\n",
      "37342/37342 [==============================] - 1s 26us/step - loss: 0.2945 - mean_absolute_error: 0.3797\n",
      "Epoch 16/250\n",
      "37342/37342 [==============================] - 1s 26us/step - loss: 0.2936 - mean_absolute_error: 0.3797\n",
      "Epoch 17/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2939 - mean_absolute_error: 0.3801\n",
      "Epoch 18/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2934 - mean_absolute_error: 0.3794\n",
      "Epoch 19/250\n",
      "37342/37342 [==============================] - 1s 32us/step - loss: 0.2934 - mean_absolute_error: 0.3793\n",
      "Epoch 20/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2949 - mean_absolute_error: 0.3811\n",
      "Epoch 21/250\n",
      "37342/37342 [==============================] - 1s 33us/step - loss: 0.2953 - mean_absolute_error: 0.3791\n",
      "Epoch 22/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2941 - mean_absolute_error: 0.3791: 0s - loss: 0.2952 - mean_absolute_error: 0.379\n",
      "Epoch 23/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2910 - mean_absolute_error: 0.3770\n",
      "Epoch 24/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2913 - mean_absolute_error: 0.3780\n",
      "Epoch 25/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2908 - mean_absolute_error: 0.3778\n",
      "Epoch 26/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2939 - mean_absolute_error: 0.3799\n",
      "Epoch 27/250\n",
      "37342/37342 [==============================] - 1s 34us/step - loss: 0.2927 - mean_absolute_error: 0.3787\n",
      "Epoch 28/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2927 - mean_absolute_error: 0.3775\n",
      "Epoch 29/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2920 - mean_absolute_error: 0.3778\n",
      "Epoch 30/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2899 - mean_absolute_error: 0.3759\n",
      "Epoch 31/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2908 - mean_absolute_error: 0.3765\n",
      "Epoch 32/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2913 - mean_absolute_error: 0.3763\n",
      "Epoch 33/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2895 - mean_absolute_error: 0.3756\n",
      "Epoch 34/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2905 - mean_absolute_error: 0.3766: 0s - loss: 0.2908 - mean_absolute_error: 0.37\n",
      "Epoch 35/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2912 - mean_absolute_error: 0.3764\n",
      "Epoch 36/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2909 - mean_absolute_error: 0.3761\n",
      "Epoch 37/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2885 - mean_absolute_error: 0.3751\n",
      "Epoch 38/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2890 - mean_absolute_error: 0.3752\n",
      "Epoch 39/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2901 - mean_absolute_error: 0.3758\n",
      "Epoch 40/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2894 - mean_absolute_error: 0.3753\n",
      "Epoch 41/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2883 - mean_absolute_error: 0.3747\n",
      "Epoch 42/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2901 - mean_absolute_error: 0.3754\n",
      "Epoch 43/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2892 - mean_absolute_error: 0.3748\n",
      "Epoch 44/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2901 - mean_absolute_error: 0.3758\n",
      "Epoch 45/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2889 - mean_absolute_error: 0.3756: 0s - loss: 0.2859 - mean_absolute_error: 0.\n",
      "Epoch 46/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2886 - mean_absolute_error: 0.3740\n",
      "Epoch 47/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2876 - mean_absolute_error: 0.3740\n",
      "Epoch 48/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2898 - mean_absolute_error: 0.3753\n",
      "Epoch 49/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2864 - mean_absolute_error: 0.3735\n",
      "Epoch 50/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2881 - mean_absolute_error: 0.3741\n",
      "Epoch 51/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2880 - mean_absolute_error: 0.3739\n",
      "Epoch 52/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2879 - mean_absolute_error: 0.3742\n",
      "Epoch 53/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2878 - mean_absolute_error: 0.3731\n",
      "Epoch 54/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2858 - mean_absolute_error: 0.3728\n",
      "Epoch 55/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2865 - mean_absolute_error: 0.3729\n",
      "Epoch 56/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2870 - mean_absolute_error: 0.3723\n",
      "Epoch 57/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2864 - mean_absolute_error: 0.3731\n",
      "Epoch 58/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2853 - mean_absolute_error: 0.3712\n",
      "Epoch 59/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2845 - mean_absolute_error: 0.3715\n",
      "Epoch 60/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2850 - mean_absolute_error: 0.3708\n",
      "Epoch 61/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2849 - mean_absolute_error: 0.3714\n",
      "Epoch 62/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2855 - mean_absolute_error: 0.3716\n",
      "Epoch 63/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2851 - mean_absolute_error: 0.3719\n",
      "Epoch 64/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2866 - mean_absolute_error: 0.3729\n",
      "Epoch 65/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2850 - mean_absolute_error: 0.3712\n",
      "Epoch 66/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2864 - mean_absolute_error: 0.3717\n",
      "Epoch 67/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2856 - mean_absolute_error: 0.3725\n",
      "Epoch 68/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2853 - mean_absolute_error: 0.3720\n",
      "Epoch 69/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2867 - mean_absolute_error: 0.3718\n",
      "Epoch 70/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2865 - mean_absolute_error: 0.3726\n",
      "Epoch 71/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2835 - mean_absolute_error: 0.3707\n",
      "Epoch 72/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2883 - mean_absolute_error: 0.3724\n",
      "Epoch 73/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2861 - mean_absolute_error: 0.3724\n",
      "Epoch 74/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2857 - mean_absolute_error: 0.3715\n",
      "Epoch 75/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2837 - mean_absolute_error: 0.3704\n",
      "Epoch 76/250\n",
      "37342/37342 [==============================] - 1s 26us/step - loss: 0.2836 - mean_absolute_error: 0.3700\n",
      "Epoch 77/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2862 - mean_absolute_error: 0.3719\n",
      "Epoch 78/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2843 - mean_absolute_error: 0.3712\n",
      "Epoch 79/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2849 - mean_absolute_error: 0.3711\n",
      "Epoch 80/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2857 - mean_absolute_error: 0.3712\n",
      "Epoch 81/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2821 - mean_absolute_error: 0.3694\n",
      "Epoch 82/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2834 - mean_absolute_error: 0.3706\n",
      "Epoch 83/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2826 - mean_absolute_error: 0.3691\n",
      "Epoch 84/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2844 - mean_absolute_error: 0.3703\n",
      "Epoch 85/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2842 - mean_absolute_error: 0.3706\n",
      "Epoch 86/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2830 - mean_absolute_error: 0.3705\n",
      "Epoch 87/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2833 - mean_absolute_error: 0.3696\n",
      "Epoch 88/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2837 - mean_absolute_error: 0.3695\n",
      "Epoch 89/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2816 - mean_absolute_error: 0.3689\n",
      "Epoch 90/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2837 - mean_absolute_error: 0.3713\n",
      "Epoch 91/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2817 - mean_absolute_error: 0.3684\n",
      "Epoch 92/250\n",
      "37342/37342 [==============================] - 1s 27us/step - loss: 0.2825 - mean_absolute_error: 0.3694\n",
      "Epoch 93/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2808 - mean_absolute_error: 0.3683\n",
      "Epoch 94/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2815 - mean_absolute_error: 0.3688\n",
      "Epoch 95/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2832 - mean_absolute_error: 0.3694\n",
      "Epoch 96/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2825 - mean_absolute_error: 0.3692\n",
      "Epoch 97/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2835 - mean_absolute_error: 0.3694\n",
      "Epoch 98/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2833 - mean_absolute_error: 0.3701\n",
      "Epoch 99/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2817 - mean_absolute_error: 0.3686\n",
      "Epoch 100/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2819 - mean_absolute_error: 0.3684\n",
      "Epoch 101/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2829 - mean_absolute_error: 0.3696\n",
      "Epoch 102/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2808 - mean_absolute_error: 0.3674\n",
      "Epoch 103/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2807 - mean_absolute_error: 0.3681\n",
      "Epoch 104/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2811 - mean_absolute_error: 0.3677\n",
      "Epoch 105/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2808 - mean_absolute_error: 0.3675\n",
      "Epoch 106/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2792 - mean_absolute_error: 0.3676\n",
      "Epoch 107/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2795 - mean_absolute_error: 0.3669\n",
      "Epoch 108/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2805 - mean_absolute_error: 0.3677\n",
      "Epoch 109/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2812 - mean_absolute_error: 0.3683\n",
      "Epoch 110/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2801 - mean_absolute_error: 0.3679\n",
      "Epoch 111/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2810 - mean_absolute_error: 0.3691\n",
      "Epoch 112/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2817 - mean_absolute_error: 0.3681\n",
      "Epoch 113/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2796 - mean_absolute_error: 0.3668\n",
      "Epoch 114/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2819 - mean_absolute_error: 0.3681\n",
      "Epoch 115/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2813 - mean_absolute_error: 0.3676\n",
      "Epoch 116/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2804 - mean_absolute_error: 0.3674\n",
      "Epoch 117/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2798 - mean_absolute_error: 0.3667\n",
      "Epoch 118/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2800 - mean_absolute_error: 0.3680\n",
      "Epoch 119/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2798 - mean_absolute_error: 0.3673\n",
      "Epoch 120/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2813 - mean_absolute_error: 0.3688\n",
      "Epoch 121/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2819 - mean_absolute_error: 0.3684\n",
      "Epoch 122/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2788 - mean_absolute_error: 0.3666\n",
      "Epoch 123/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2781 - mean_absolute_error: 0.3662\n",
      "Epoch 124/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2776 - mean_absolute_error: 0.3658\n",
      "Epoch 125/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2796 - mean_absolute_error: 0.3665\n",
      "Epoch 126/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2818 - mean_absolute_error: 0.3677\n",
      "Epoch 127/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2817 - mean_absolute_error: 0.3674\n",
      "Epoch 128/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2812 - mean_absolute_error: 0.3678\n",
      "Epoch 129/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2796 - mean_absolute_error: 0.3666\n",
      "Epoch 130/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2787 - mean_absolute_error: 0.3665: 0s - loss: 0.2780 - mean_absolute_error: 0.36\n",
      "Epoch 131/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2815 - mean_absolute_error: 0.3672\n",
      "Epoch 132/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2811 - mean_absolute_error: 0.3679: 0s - loss: 0.2822 - mean_absolute_err\n",
      "Epoch 133/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2786 - mean_absolute_error: 0.3662\n",
      "Epoch 134/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2803 - mean_absolute_error: 0.3669\n",
      "Epoch 135/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2812 - mean_absolute_error: 0.3674\n",
      "Epoch 136/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2791 - mean_absolute_error: 0.3659\n",
      "Epoch 137/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2804 - mean_absolute_error: 0.3667\n",
      "Epoch 138/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2779 - mean_absolute_error: 0.3657\n",
      "Epoch 139/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2785 - mean_absolute_error: 0.3667\n",
      "Epoch 140/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2769 - mean_absolute_error: 0.3657\n",
      "Epoch 141/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2800 - mean_absolute_error: 0.3664\n",
      "Epoch 142/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2784 - mean_absolute_error: 0.3655\n",
      "Epoch 143/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2782 - mean_absolute_error: 0.3661\n",
      "Epoch 144/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2779 - mean_absolute_error: 0.3655\n",
      "Epoch 145/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2777 - mean_absolute_error: 0.3652\n",
      "Epoch 146/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2811 - mean_absolute_error: 0.3669\n",
      "Epoch 147/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2763 - mean_absolute_error: 0.3651\n",
      "Epoch 148/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2783 - mean_absolute_error: 0.3656\n",
      "Epoch 149/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2772 - mean_absolute_error: 0.3650\n",
      "Epoch 150/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2800 - mean_absolute_error: 0.3669: 0s - loss: 0.2805 - mean_absolute_error: 0.36\n",
      "Epoch 151/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2796 - mean_absolute_error: 0.3667\n",
      "Epoch 152/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2790 - mean_absolute_error: 0.3660\n",
      "Epoch 153/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2790 - mean_absolute_error: 0.3672\n",
      "Epoch 154/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2787 - mean_absolute_error: 0.3662\n",
      "Epoch 155/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2778 - mean_absolute_error: 0.3654\n",
      "Epoch 156/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2785 - mean_absolute_error: 0.3662\n",
      "Epoch 157/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2784 - mean_absolute_error: 0.3658\n",
      "Epoch 158/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2783 - mean_absolute_error: 0.3659\n",
      "Epoch 159/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2779 - mean_absolute_error: 0.3661\n",
      "Epoch 160/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2782 - mean_absolute_error: 0.3650\n",
      "Epoch 161/250\n",
      "37342/37342 [==============================] - 1s 26us/step - loss: 0.2782 - mean_absolute_error: 0.3647: 0s - loss: 0.2753 - mean_absolute_err\n",
      "Epoch 162/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2769 - mean_absolute_error: 0.3651\n",
      "Epoch 163/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2777 - mean_absolute_error: 0.3655\n",
      "Epoch 164/250\n",
      "37342/37342 [==============================] - 1s 29us/step - loss: 0.2771 - mean_absolute_error: 0.3643\n",
      "Epoch 165/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2772 - mean_absolute_error: 0.3654\n",
      "Epoch 166/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2793 - mean_absolute_error: 0.3664: 0s - loss: 0.2791 - mean_absolute_error: 0.3\n",
      "Epoch 167/250\n",
      "37342/37342 [==============================] - 1s 30us/step - loss: 0.2778 - mean_absolute_error: 0.3655\n",
      "Epoch 168/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2792 - mean_absolute_error: 0.3653\n",
      "Epoch 169/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2775 - mean_absolute_error: 0.3651\n",
      "Epoch 170/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2764 - mean_absolute_error: 0.3649\n",
      "Epoch 171/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2766 - mean_absolute_error: 0.3645\n",
      "Epoch 172/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2782 - mean_absolute_error: 0.3649\n",
      "Epoch 173/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2775 - mean_absolute_error: 0.3645\n",
      "Epoch 174/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2787 - mean_absolute_error: 0.3652\n",
      "Epoch 175/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2780 - mean_absolute_error: 0.3659\n",
      "Epoch 176/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2762 - mean_absolute_error: 0.3641\n",
      "Epoch 177/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2775 - mean_absolute_error: 0.3646\n",
      "Epoch 178/250\n",
      "37342/37342 [==============================] - 1s 28us/step - loss: 0.2777 - mean_absolute_error: 0.3649\n",
      "Epoch 179/250\n",
      "37342/37342 [==============================] - 1s 25us/step - loss: 0.2774 - mean_absolute_error: 0.3650\n",
      "Epoch 180/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2777 - mean_absolute_error: 0.3648\n",
      "Epoch 181/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2778 - mean_absolute_error: 0.3655\n",
      "Epoch 182/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2766 - mean_absolute_error: 0.3647\n",
      "Epoch 183/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2778 - mean_absolute_error: 0.3651\n",
      "Epoch 184/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2772 - mean_absolute_error: 0.3640\n",
      "Epoch 185/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2766 - mean_absolute_error: 0.3635\n",
      "Epoch 186/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2759 - mean_absolute_error: 0.3639\n",
      "Epoch 187/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2764 - mean_absolute_error: 0.3644\n",
      "Epoch 188/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2771 - mean_absolute_error: 0.3645\n",
      "Epoch 189/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2743 - mean_absolute_error: 0.3631\n",
      "Epoch 190/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2767 - mean_absolute_error: 0.3643\n",
      "Epoch 191/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2770 - mean_absolute_error: 0.3646\n",
      "Epoch 192/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2771 - mean_absolute_error: 0.3643\n",
      "Epoch 193/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2758 - mean_absolute_error: 0.3633\n",
      "Epoch 194/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2774 - mean_absolute_error: 0.3650\n",
      "Epoch 195/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2756 - mean_absolute_error: 0.3638\n",
      "Epoch 196/250\n",
      "37342/37342 [==============================] - 1s 24us/step - loss: 0.2767 - mean_absolute_error: 0.3641\n",
      "Epoch 197/250\n",
      "37342/37342 [==============================] - 1s 23us/step - loss: 0.2769 - mean_absolute_error: 0.3647\n",
      "Epoch 198/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2766 - mean_absolute_error: 0.3640\n",
      "Epoch 199/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2750 - mean_absolute_error: 0.3638\n",
      "Epoch 200/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2761 - mean_absolute_error: 0.3634\n",
      "Epoch 201/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2753 - mean_absolute_error: 0.3633\n",
      "Epoch 202/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2750 - mean_absolute_error: 0.3636\n",
      "Epoch 203/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2769 - mean_absolute_error: 0.3644\n",
      "Epoch 204/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2766 - mean_absolute_error: 0.3642\n",
      "Epoch 205/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2740 - mean_absolute_error: 0.3630\n",
      "Epoch 206/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2766 - mean_absolute_error: 0.3642\n",
      "Epoch 207/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2766 - mean_absolute_error: 0.3640\n",
      "Epoch 208/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2773 - mean_absolute_error: 0.3640\n",
      "Epoch 209/250\n",
      "37342/37342 [==============================] - 1s 21us/step - loss: 0.2754 - mean_absolute_error: 0.3636\n",
      "Epoch 210/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2782 - mean_absolute_error: 0.3648\n",
      "Epoch 211/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2756 - mean_absolute_error: 0.3636\n",
      "Epoch 212/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2760 - mean_absolute_error: 0.3642\n",
      "Epoch 213/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2756 - mean_absolute_error: 0.3637\n",
      "Epoch 214/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2750 - mean_absolute_error: 0.3637\n",
      "Epoch 215/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2755 - mean_absolute_error: 0.3636\n",
      "Epoch 216/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2763 - mean_absolute_error: 0.3644\n",
      "Epoch 217/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2753 - mean_absolute_error: 0.3621\n",
      "Epoch 218/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2758 - mean_absolute_error: 0.3632\n",
      "Epoch 219/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2742 - mean_absolute_error: 0.3633\n",
      "Epoch 220/250\n",
      "37342/37342 [==============================] - 1s 22us/step - loss: 0.2759 - mean_absolute_error: 0.3635\n",
      "Epoch 221/250\n",
      "37342/37342 [==============================] - 1s 17us/step - loss: 0.2770 - mean_absolute_error: 0.3650\n",
      "Epoch 222/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2796 - mean_absolute_error: 0.3652\n",
      "Epoch 223/250\n",
      "37342/37342 [==============================] - 1s 19us/step - loss: 0.2749 - mean_absolute_error: 0.3628\n",
      "Epoch 224/250\n",
      "37342/37342 [==============================] - 1s 18us/step - loss: 0.2773 - mean_absolute_error: 0.3646\n",
      "Epoch 225/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2773 - mean_absolute_error: 0.3636\n",
      "Epoch 226/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2753 - mean_absolute_error: 0.3629\n",
      "Epoch 227/250\n",
      "37342/37342 [==============================] - 1s 20us/step - loss: 0.2747 - mean_absolute_error: 0.3633\n",
      "Epoch 228/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2749 - mean_absolute_error: 0.3634\n",
      "Epoch 229/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2747 - mean_absolute_error: 0.3625\n",
      "Epoch 230/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2764 - mean_absolute_error: 0.3639\n",
      "Epoch 231/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2763 - mean_absolute_error: 0.3631\n",
      "Epoch 232/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2745 - mean_absolute_error: 0.3628\n",
      "Epoch 233/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2772 - mean_absolute_error: 0.3634\n",
      "Epoch 234/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2753 - mean_absolute_error: 0.3630\n",
      "Epoch 235/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2757 - mean_absolute_error: 0.3631\n",
      "Epoch 236/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2753 - mean_absolute_error: 0.3632\n",
      "Epoch 237/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2762 - mean_absolute_error: 0.3640\n",
      "Epoch 238/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2754 - mean_absolute_error: 0.3627\n",
      "Epoch 239/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2758 - mean_absolute_error: 0.3636\n",
      "Epoch 240/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2758 - mean_absolute_error: 0.3633\n",
      "Epoch 241/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2761 - mean_absolute_error: 0.3626\n",
      "Epoch 242/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2753 - mean_absolute_error: 0.3624\n",
      "Epoch 243/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2785 - mean_absolute_error: 0.3643\n",
      "Epoch 244/250\n",
      "37342/37342 [==============================] - 1s 16us/step - loss: 0.2744 - mean_absolute_error: 0.3626\n",
      "Epoch 245/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2751 - mean_absolute_error: 0.3634\n",
      "Epoch 246/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2741 - mean_absolute_error: 0.3624\n",
      "Epoch 247/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2753 - mean_absolute_error: 0.3626\n",
      "Epoch 248/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2752 - mean_absolute_error: 0.3636\n",
      "Epoch 249/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2755 - mean_absolute_error: 0.3628\n",
      "Epoch 250/250\n",
      "37342/37342 [==============================] - 1s 15us/step - loss: 0.2748 - mean_absolute_error: 0.3629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d836a0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size = 64, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37.51062775, 127.38492584],\n",
       "       [ 37.5580864 , 127.04589081],\n",
       "       [ 37.50587082, 127.01229095],\n",
       "       ...,\n",
       "       [ 37.54788589, 126.93301392],\n",
       "       [ 37.54504395, 126.93218994],\n",
       "       [ 37.38407135, 126.81645203]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new = np.zeros((len(y_pred), 2))\n",
    "y_test_new = np.zeros((len(y_test), 2))\n",
    "y_pred_new[:,0] = y_pred[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_pred_new[:,1] = y_pred[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "\n",
    "y_test_new[:,0] = y_test[:,0] * np.std(Y[:,0]) + np.mean(Y[:,0])\n",
    "y_test_new[:,1] = y_test[:,1] * np.std(Y[:,1]) + np.mean(Y[:,1])\n",
    "y_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'house_lat': y_test_new[:, 0],'house_lon':y_test_new[:, 1],\n",
    "                            'house_lat (pred)': y_pred_new[:,0], 'house_lon (pred)': y_pred_new[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9336, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "922.717881671499"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score to beat: 836.4854723538451\n",
    "accuracy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.scatter(y_test_new[:, 0], y_test_new[:, 1], color = \"red\", label = 'Actual')\n",
    "plt.scatter(y_pred_new[:, 0], y_pred_new[:, 1], color = \"blue\", label = 'Prediction')\n",
    "plt.title('Regression')\n",
    "plt.xlabel('Lat')\n",
    "plt.ylabel('Lon')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "'''\n",
    "Standard model:\n",
    "# Initialising the ANN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.1, nesterov = True)\n",
    "def create_model():\n",
    "    # create model\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1597))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 2, kernel_initializer = 'normal', activation = 'linear'))\n",
    "    # Compile model\n",
    "    regressor.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-16c1334d8b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# # Applying Kernel PCA\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(kernel = 'rbf')\n",
    "# X_original_pca = kpca.fit_transform(x_original)\n",
    "# X_original_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification approach\n",
    "# # x - same X except using W_Zone but no X_lat and X_lon, also eliminate non-independent variables\n",
    "# # y - H_Zone\n",
    "# x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cat = np.delete(X, 6, axis = 1)\n",
    "# x_cat = np.delete(X, 7, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat = data.loc[:, [\"H_ZONE\"]]\n",
    "# Y_cat.head()\n",
    "# Y_cat = Y_cat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# binarizer = LabelBinarizer()\n",
    "# Y_cat = binarizer.fit_transform(Y_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_cat, Y_cat, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialising the ANN\n",
    "# classifier = Sequential()\n",
    "\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1596))\n",
    "# classifier.add(Dropout(0.1))\n",
    "# # Adding the second hidden layer\n",
    "# classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(units = 1278, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# # Compiling the ANN\n",
    "# classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting the ANN to the Training set\n",
    "# classifier.fit(X_train, y_train, batch_size = 50, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
